[{"id":0,"href":"/posts/creating-a-new-theme/","title":"Creating a New Theme","section":"博客预览","content":"Introduction #  This tutorial will show you how to create a simple theme in Hugo. I assume that you are familiar with HTML, the bash command line, and that you are comfortable using Markdown to format content. I\u0026rsquo;ll explain how Hugo uses templates and how you can organize your templates to create a theme. I won\u0026rsquo;t cover using CSS to style your theme.\nWe\u0026rsquo;ll start with creating a new site with a very basic template. Then we\u0026rsquo;ll add in a few pages and posts. With small variations on that, you will be able to create many different types of web sites.\nIn this tutorial, commands that you enter will start with the \u0026ldquo;$\u0026rdquo; prompt. The output will follow. Lines that start with \u0026ldquo;#\u0026rdquo; are comments that I\u0026rsquo;ve added to explain a point. When I show updates to a file, the \u0026ldquo;:wq\u0026rdquo; on the last line means to save the file.\nHere\u0026rsquo;s an example:\n## this is a comment $ echo this is a command this is a command ## edit the file $ vi foo.md +++ date = \u0026#34;2014-09-28\u0026#34; title = \u0026#34;creating a new theme\u0026#34; +++ bah and humbug :wq ## show it $ cat foo.md +++ date = \u0026#34;2014-09-28\u0026#34; title = \u0026#34;creating a new theme\u0026#34; +++ bah and humbug $ Some Definitions #  There are a few concepts that you need to understand before creating a theme.\nSkins #  Skins are the files responsible for the look and feel of your site. It’s the CSS that controls colors and fonts, it’s the Javascript that determines actions and reactions. It’s also the rules that Hugo uses to transform your content into the HTML that the site will serve to visitors.\nYou have two ways to create a skin. The simplest way is to create it in the layouts/ directory. If you do, then you don’t have to worry about configuring Hugo to recognize it. The first place that Hugo will look for rules and files is in the layouts/ directory so it will always find the skin.\nYour second choice is to create it in a sub-directory of the themes/ directory. If you do, then you must always tell Hugo where to search for the skin. It’s extra work, though, so why bother with it?\nThe difference between creating a skin in layouts/ and creating it in themes/ is very subtle. A skin in layouts/ can’t be customized without updating the templates and static files that it is built from. A skin created in themes/, on the other hand, can be and that makes it easier for other people to use it.\nThe rest of this tutorial will call a skin created in the themes/ directory a theme.\nNote that you can use this tutorial to create a skin in the layouts/ directory if you wish to. The main difference will be that you won’t need to update the site’s configuration file to use a theme.\nThe Home Page #  The home page, or landing page, is the first page that many visitors to a site see. It is the index.html file in the root directory of the web site. Since Hugo writes files to the public/ directory, our home page is public/index.html.\nSite Configuration File #  When Hugo runs, it looks for a configuration file that contains settings that override default values for the entire site. The file can use TOML, YAML, or JSON. I prefer to use TOML for my configuration files. If you prefer to use JSON or YAML, you’ll need to translate my examples. You’ll also need to change the name of the file since Hugo uses the extension to determine how to process it.\nHugo translates Markdown files into HTML. By default, Hugo expects to find Markdown files in your content/ directory and template files in your themes/ directory. It will create HTML files in your public/ directory. You can change this by specifying alternate locations in the configuration file.\nContent #  Content is stored in text files that contain two sections. The first section is the “front matter,” which is the meta-information on the content. The second section contains Markdown that will be converted to HTML.\nFront Matter #  The front matter is information about the content. Like the configuration file, it can be written in TOML, YAML, or JSON. Unlike the configuration file, Hugo doesn’t use the file’s extension to know the format. It looks for markers to signal the type. TOML is surrounded by “+++”, YAML by “---”, and JSON is enclosed in curly braces. I prefer to use TOML, so you’ll need to translate my examples if you prefer YAML or JSON.\nThe information in the front matter is passed into the template before the content is rendered into HTML.\nMarkdown #  Content is written in Markdown which makes it easier to create the content. Hugo runs the content through a Markdown engine to create the HTML which will be written to the output file.\nTemplate Files #  Hugo uses template files to render content into HTML. Template files are a bridge between the content and presentation. Rules in the template define what content is published, where it\u0026rsquo;s published to, and how it will rendered to the HTML file. The template guides the presentation by specifying the style to use.\nThere are three types of templates: single, list, and partial. Each type takes a bit of content as input and transforms it based on the commands in the template.\nHugo uses its knowledge of the content to find the template file used to render the content. If it can’t find a template that is an exact match for the content, it will shift up a level and search from there. It will continue to do so until it finds a matching template or runs out of templates to try. If it can’t find a template, it will use the default template for the site.\nPlease note that you can use the front matter to influence Hugo’s choice of templates.\nSingle Template #  A single template is used to render a single piece of content. For example, an article or post would be a single piece of content and use a single template.\nList Template #  A list template renders a group of related content. That could be a summary of recent postings or all articles in a category. List templates can contain multiple groups.\nThe homepage template is a special type of list template. Hugo assumes that the home page of your site will act as the portal for the rest of the content in the site.\nPartial Template #  A partial template is a template that can be included in other templates. Partial templates must be called using the “partial” template command. They are very handy for rolling up common behavior. For example, your site may have a banner that all pages use. Instead of copying the text of the banner into every single and list template, you could create a partial with the banner in it. That way if you decide to change the banner, you only have to change the partial template.\nCreate a New Site #  Let\u0026rsquo;s use Hugo to create a new web site. I\u0026rsquo;m a Mac user, so I\u0026rsquo;ll create mine in my home directory, in the Sites folder. If you\u0026rsquo;re using Linux, you might have to create the folder first.\nThe \u0026ldquo;new site\u0026rdquo; command will create a skeleton of a site. It will give you the basic directory structure and a useable configuration file.\n$ hugo new site ~/Sites/zafta $ cd ~/Sites/zafta $ ls -l total 8 drwxr-xr-x 7 quoha staff 238 Sep 29 16:49 . drwxr-xr-x 3 quoha staff 102 Sep 29 16:49 .. drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $ Take a look in the content/ directory to confirm that it is empty.\nThe other directories (archetypes/, layouts/, and static/) are used when customizing a theme. That\u0026rsquo;s a topic for a different tutorial, so please ignore them for now.\nGenerate the HTML For the New Site #  Running the hugo command with no options will read all the available content and generate the HTML files. It will also copy all static files (that\u0026rsquo;s everything that\u0026rsquo;s not content). Since we have an empty site, it won\u0026rsquo;t do much, but it will do it very quickly.\n$ hugo --verbose INFO: 2014/09/29 Using config file: config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ The \u0026ldquo;--verbose\u0026rdquo; flag gives extra information that will be helpful when we build the template. Every line of the output that starts with \u0026ldquo;INFO:\u0026rdquo; or \u0026ldquo;WARN:\u0026rdquo; is present because we used that flag. The lines that start with \u0026ldquo;WARN:\u0026rdquo; are warning messages. We\u0026rsquo;ll go over them later.\nWe can verify that the command worked by looking at the directory again.\n$ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $ See that new public/ directory? Hugo placed all generated content there. When you\u0026rsquo;re ready to publish your web site, that\u0026rsquo;s the place to start. For now, though, let\u0026rsquo;s just confirm that we have what we\u0026rsquo;d expect from a site with no content.\n$ ls -l public total 16 -rw-r--r-- 1 quoha staff 416 Sep 29 17:02 index.xml -rw-r--r-- 1 quoha staff 262 Sep 29 17:02 sitemap.xml $ Hugo created two XML files, which is standard, but there are no HTML files.\nTest the New Site #  Verify that you can run the built-in web server. It will dramatically shorten your development cycle if you do. Start it by running the \u0026ldquo;server\u0026rdquo; command. If it is successful, you will see output similar to the following:\n$ hugo server --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop Connect to the listed URL (it\u0026rsquo;s on the line that starts with \u0026ldquo;Web Server\u0026rdquo;). If everything is working correctly, you should get a page that shows the following:\nindex.xml sitemap.xml That\u0026rsquo;s a listing of your public/ directory. Hugo didn\u0026rsquo;t create a home page because our site has no content. When there\u0026rsquo;s no index.html file in a directory, the server lists the files in the directory, which is what you should see in your browser.\nLet’s go back and look at those warnings again.\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] That second warning is easier to explain. We haven’t created a template to be used to generate “page not found errors.” The 404 message is a topic for a separate tutorial.\nNow for the first warning. It is for the home page. You can tell because the first layout that it looked for was “index.html.” That’s only used by the home page.\nI like that the verbose flag causes Hugo to list the files that it\u0026rsquo;s searching for. For the home page, they are index.html, _default/list.html, and _default/single.html. There are some rules that we\u0026rsquo;ll cover later that explain the names and paths. For now, just remember that Hugo couldn\u0026rsquo;t find a template for the home page and it told you so.\nAt this point, you\u0026rsquo;ve got a working installation and site that we can build upon. All that’s left is to add some content and a theme to display it.\nCreate a New Theme #  Hugo doesn\u0026rsquo;t ship with a default theme. There are a few available (I counted a dozen when I first installed Hugo) and Hugo comes with a command to create new themes.\nWe\u0026rsquo;re going to create a new theme called \u0026ldquo;zafta.\u0026rdquo; Since the goal of this tutorial is to show you how to fill out the files to pull in your content, the theme will not contain any CSS. In other words, ugly but functional.\nAll themes have opinions on content and layout. For example, Zafta uses \u0026ldquo;post\u0026rdquo; over \u0026ldquo;blog\u0026rdquo;. Strong opinions make for simpler templates but differing opinions make it tougher to use themes. When you build a theme, consider using the terms that other themes do.\nCreate a Skeleton #  Use the hugo \u0026ldquo;new\u0026rdquo; command to create the skeleton of a theme. This creates the directory structure and places empty files for you to fill out.\n$ hugo new theme zafta $ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes $ find themes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 1081 Sep 29 17:31 themes/zafta/LICENSE.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html -rw-r--r-- 1 quoha staff 93 Sep 29 17:31 themes/zafta/theme.toml $ The skeleton includes templates (the files ending in .html), license file, a description of your theme (the theme.toml file), and an empty archetype.\nPlease take a minute to fill out the theme.toml and LICENSE.md files. They\u0026rsquo;re optional, but if you\u0026rsquo;re going to be distributing your theme, it tells the world who to praise (or blame). It\u0026rsquo;s also nice to declare the license so that people will know how they can use the theme.\n$ vi themes/zafta/theme.toml author = \u0026#34;michael d henderson\u0026#34; description = \u0026#34;a minimal working template\u0026#34; license = \u0026#34;MIT\u0026#34; name = \u0026#34;zafta\u0026#34; source_repo = \u0026#34;\u0026#34; tags = [\u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34;] :wq ## also edit themes/zafta/LICENSE.md and change ## the bit that says \u0026#34;YOUR_NAME_HERE\u0026#34; Note that the the skeleton\u0026rsquo;s template files are empty. Don\u0026rsquo;t worry, we\u0026rsquo;ll be changing that shortly.\n$ find themes/zafta -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html $ Update the Configuration File to Use the Theme #  Now that we\u0026rsquo;ve got a theme to work with, it\u0026rsquo;s a good idea to add the theme name to the configuration file. This is optional, because you can always add \u0026ldquo;-t zafta\u0026rdquo; on all your commands. I like to put it the configuration file because I like shorter command lines. If you don\u0026rsquo;t put it in the configuration file or specify it on the command line, you won\u0026rsquo;t use the template that you\u0026rsquo;re expecting to.\nEdit the file to add the theme, add a title for the site, and specify that all of our content will use the TOML format.\n$ vi config.toml theme = \u0026#34;zafta\u0026#34; baseurl = \u0026#34;\u0026#34; languageCode = \u0026#34;en-us\u0026#34; title = \u0026#34;zafta - totally refreshing\u0026#34; MetaDataFormat = \u0026#34;toml\u0026#34; :wq $ Generate the Site #  Now that we have an empty theme, let\u0026rsquo;s generate the site again.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ Did you notice that the output is different? The warning message for the home page has disappeared and we have an additional information line saying that Hugo is syncing from the theme\u0026rsquo;s directory.\nLet\u0026rsquo;s check the public/ directory to see what Hugo\u0026rsquo;s created.\n$ ls -l public total 16 drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 css -rw-r--r-- 1 quoha staff 0 Sep 29 17:56 index.html -rw-r--r-- 1 quoha staff 407 Sep 29 17:56 index.xml drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 js -rw-r--r-- 1 quoha staff 243 Sep 29 17:56 sitemap.xml $ Notice four things:\n Hugo created a home page. This is the file public/index.html. Hugo created a css/ directory. Hugo created a js/ directory. Hugo claimed that it created 0 pages. It created a file and copied over static files, but didn\u0026rsquo;t create any pages. That\u0026rsquo;s because it considers a \u0026ldquo;page\u0026rdquo; to be a file created directly from a content file. It doesn\u0026rsquo;t count things like the index.html files that it creates automatically.  The Home Page #  Hugo supports many different types of templates. The home page is special because it gets its own type of template and its own template file. The file, layouts/index.html, is used to generate the HTML for the home page. The Hugo documentation says that this is the only required template, but that depends. Hugo\u0026rsquo;s warning message shows that it looks for three different templates:\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] If it can\u0026rsquo;t find any of these, it completely skips creating the home page. We noticed that when we built the site without having a theme installed.\nWhen Hugo created our theme, it created an empty home page template. Now, when we build the site, Hugo finds the template and uses it to generate the HTML for the home page. Since the template file is empty, the HTML file is empty, too. If the template had any rules in it, then Hugo would have used them to generate the home page.\n$ find . -name index.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 20:21 ./public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 ./themes/zafta/layouts/index.html $ The Magic of Static #  Hugo does two things when generating the site. It uses templates to transform content into HTML and it copies static files into the site. Unlike content, static files are not transformed. They are copied exactly as they are.\nHugo assumes that your site will use both CSS and JavaScript, so it creates directories in your theme to hold them. Remember opinions? Well, Hugo\u0026rsquo;s opinion is that you\u0026rsquo;ll store your CSS in a directory named css/ and your JavaScript in a directory named js/. If you don\u0026rsquo;t like that, you can change the directory names in your theme directory or even delete them completely. Hugo\u0026rsquo;s nice enough to offer its opinion, then behave nicely if you disagree.\n$ find themes/zafta -type d | xargs ls -ld drwxr-xr-x 7 quoha staff 238 Sep 29 17:38 themes/zafta drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes/zafta/archetypes drwxr-xr-x 5 quoha staff 170 Sep 29 17:31 themes/zafta/layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/_default drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/partials drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/static drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/css drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/js $ The Theme Development Cycle #  When you\u0026rsquo;re working on a theme, you will make changes in the theme\u0026rsquo;s directory, rebuild the site, and check your changes in the browser. Hugo makes this very easy:\n Purge the public/ directory. Run the built in web server in watch mode. Open your site in a browser. Update the theme. Glance at your browser window to see changes. Return to step 4.  I’ll throw in one more opinion: never work on a theme on a live site. Always work on a copy of your site. Make changes to your theme, test them, then copy them up to your site. For added safety, use a tool like Git to keep a revision history of your content and your theme. Believe me when I say that it is too easy to lose both your mind and your changes.\nCheck the main Hugo site for information on using Git with Hugo.\nPurge the public/ Directory #  When generating the site, Hugo will create new files and update existing ones in the public/ directory. It will not delete files that are no longer used. For example, files that were created in the wrong directory or with the wrong title will remain. If you leave them, you might get confused by them later. I recommend cleaning out your site prior to generating it.\nNote: If you\u0026rsquo;re building on an SSD, you should ignore this. Churning on a SSD can be costly.\nHugo\u0026rsquo;s Watch Option #  Hugo\u0026rsquo;s \u0026ldquo;--watch\u0026rdquo; option will monitor the content/ and your theme directories for changes and rebuild the site automatically.\nLive Reload #  Hugo\u0026rsquo;s built in web server supports live reload. As pages are saved on the server, the browser is told to refresh the page. Usually, this happens faster than you can say, \u0026ldquo;Wow, that\u0026rsquo;s totally amazing.\u0026rdquo;\nDevelopment Commands #  Use the following commands as the basis for your workflow.\n## purge old files. hugo will recreate the public directory. ## $ rm -rf public ## ## run hugo in watch mode ## $ hugo server --watch --verbose Here\u0026rsquo;s sample output showing Hugo detecting a change to the template for the home page. Once generated, the web browser automatically reloaded the page. I\u0026rsquo;ve said this before, it\u0026rsquo;s amazing.\n$ rm -rf public $ hugo server --watch --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Watching for changes in /Users/quoha/Sites/zafta/content Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop INFO: 2014/09/29 File System Event: [\u0026#34;/Users/quoha/Sites/zafta/themes/zafta/layouts/index.html\u0026#34;: MODIFY|ATTRIB] Change detected, rebuilding site WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 1 ms Update the Home Page Template #  The home page is one of a few special pages that Hugo creates automatically. As mentioned earlier, it looks for one of three files in the theme\u0026rsquo;s layout/ directory:\n index.html _default/list.html _default/single.html  We could update one of the default templates, but a good design decision is to update the most specific template available. That\u0026rsquo;s not a hard and fast rule (in fact, we\u0026rsquo;ll break it a few times in this tutorial), but it is a good generalization.\nMake a Static Home Page #  Right now, that page is empty because we don\u0026rsquo;t have any content and we don\u0026rsquo;t have any logic in the template. Let\u0026rsquo;s change that by adding some text to the template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Build the web site and then verify the results.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 21:26 public/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt; Live Reload #  Note: If you\u0026rsquo;re running the server with the --watch option, you\u0026rsquo;ll see different content in the file:\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt;document.write(\u0026#39;\u0026lt;script src=\u0026#34;http://\u0026#39; + (location.host || \u0026#39;localhost\u0026#39;).split(\u0026#39;:\u0026#39;)[0] + \u0026#39;:1313/livereload.js?mindelay=10\u0026#34;\u0026gt;\u0026lt;/\u0026#39; + \u0026#39;script\u0026gt;\u0026#39;)\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; When you use --watch, the Live Reload script is added by Hugo. Look for live reload in the documentation to see what it does and how to disable it.\nBuild a \u0026ldquo;Dynamic\u0026rdquo; Home Page #  \u0026ldquo;Dynamic home page?\u0026rdquo; Hugo\u0026rsquo;s a static web site generator, so this seems an odd thing to say. I mean let\u0026rsquo;s have the home page automatically reflect the content in the site every time Hugo builds it. We\u0026rsquo;ll use iteration in the template to do that.\nCreate New Posts #  Now that we have the home page generating static content, let\u0026rsquo;s add some content to the site. We\u0026rsquo;ll display these posts as a list on the home page and on their own page, too.\nHugo has a command to generate a skeleton post, just like it does for sites and themes.\n$ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/default.md ERROR: 2014/09/29 Unable to Cast \u0026lt;nil\u0026gt; to map[string]interface{} $ That wasn\u0026rsquo;t very nice, was it?\nThe \u0026ldquo;new\u0026rdquo; command uses an archetype to create the post file. Hugo created an empty default archetype file, but that causes an error when there\u0026rsquo;s a theme. For me, the workaround was to create an archetypes file specifically for the post type.\n$ vi themes/zafta/archetypes/post.md +++ Description = \u0026#34;\u0026#34; Tags = [] Categories = [] +++ :wq $ find themes/zafta/archetypes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 21:53 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 51 Sep 29 21:54 themes/zafta/archetypes/post.md $ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/first.md /Users/quoha/Sites/zafta/content/post/first.md created $ hugo --verbose new post/second.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/second.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/second.md /Users/quoha/Sites/zafta/content/post/second.md created $ ls -l content/post total 16 -rw-r--r-- 1 quoha staff 104 Sep 29 21:54 first.md -rw-r--r-- 1 quoha staff 105 Sep 29 21:57 second.md $ cat content/post/first.md +++ Categories = [] Description = \u0026#34;\u0026#34; Tags = [] date = \u0026#34;2014-09-29T21:54:53-05:00\u0026#34; title = \u0026#34;first\u0026#34; +++ my first post $ cat content/post/second.md +++ Categories = [] Description = \u0026#34;\u0026#34; Tags = [] date = \u0026#34;2014-09-29T21:57:09-05:00\u0026#34; title = \u0026#34;second\u0026#34; +++ my second post $ Build the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;, \u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ The output says that it created 2 pages. Those are our new posts:\n$ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 22:13 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/second/index.html $ The new files are empty because because the templates used to generate the content are empty. The homepage doesn\u0026rsquo;t show the new content, either. We have to update the templates to add the posts.\nList and Single Templates #  In Hugo, we have three major kinds of templates. There\u0026rsquo;s the home page template that we updated previously. It is used only by the home page. We also have \u0026ldquo;single\u0026rdquo; templates which are used to generate output for a single content file. We also have \u0026ldquo;list\u0026rdquo; templates that are used to group multiple pieces of content before generating output.\nGenerally speaking, list templates are named \u0026ldquo;list.html\u0026rdquo; and single templates are named \u0026ldquo;single.html.\u0026rdquo;\nThere are three other types of templates: partials, content views, and terms. We will not go into much detail on these.\nAdd Content to the Homepage #  The home page will contain a list of posts. Let\u0026rsquo;s update its template to add the posts that we just created. The logic in the template will run every time we build the site.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Hugo uses the Go template engine. That engine scans the template files for commands which are enclosed between \u0026ldquo;{{\u0026rdquo; and \u0026ldquo;}}\u0026rdquo;. In our template, the commands are:\n range .Title end  The \u0026ldquo;range\u0026rdquo; command is an iterator. We\u0026rsquo;re going to use it to go through the first ten pages. Every HTML file that Hugo creates is treated as a page, so looping through the list of pages will look at every file that will be created.\nThe \u0026ldquo;.Title\u0026rdquo; command prints the value of the \u0026ldquo;title\u0026rdquo; variable. Hugo pulls it from the front matter in the Markdown file.\nThe \u0026ldquo;end\u0026rdquo; command signals the end of the range iterator. The engine loops back to the top of the iteration when it finds \u0026ldquo;end.\u0026rdquo; Everything between the \u0026ldquo;range\u0026rdquo; and \u0026ldquo;end\u0026rdquo; is evaluated every time the engine goes through the iteration. In this file, that would cause the title from the first ten pages to be output as heading level one.\nIt\u0026rsquo;s helpful to remember that some variables, like .Data, are created before any output files. Hugo loads every content file into the variable and then gives the template a chance to process before creating the HTML files.\nBuild the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:23 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Congratulations, the home page shows the title of the two posts. The posts themselves are still empty, but let\u0026rsquo;s take a moment to appreciate what we\u0026rsquo;ve done. Your template now generates output dynamically. Believe it or not, by inserting the range command inside of those curly braces, you\u0026rsquo;ve learned everything you need to know to build a theme. All that\u0026rsquo;s really left is understanding which template will be used to generate each content file and becoming familiar with the commands for the template engine.\nAnd, if that were entirely true, this tutorial would be much shorter. There are a few things to know that will make creating a new template much easier. Don\u0026rsquo;t worry, though, that\u0026rsquo;s all to come.\nAdd Content to the Posts #  We\u0026rsquo;re working with posts, which are in the content/post/ directory. That means that their section is \u0026ldquo;post\u0026rdquo; (and if we don\u0026rsquo;t do something weird, their type is also \u0026ldquo;post\u0026rdquo;).\nHugo uses the section and type to find the template file for every piece of content. Hugo will first look for a template file that matches the section or type name. If it can\u0026rsquo;t find one, then it will look in the _default/ directory. There are some twists that we\u0026rsquo;ll cover when we get to categories and tags, but for now we can assume that Hugo will try post/single.html, then _default/single.html.\nNow that we know the search rule, let\u0026rsquo;s see what we actually have available:\n$ find themes/zafta -name single.html | xargs ls -l -rw-r--r-- 1 quoha staff 132 Sep 29 17:31 themes/zafta/layouts/_default/single.html We could create a new template, post/single.html, or change the default. Since we don\u0026rsquo;t know of any other content types, let\u0026rsquo;s start with updating the default.\nRemember, any content that we haven\u0026rsquo;t created a template for will end up using this template. That can be good or bad. Bad because I know that we\u0026rsquo;re going to be adding different types of content and we\u0026rsquo;re going to end up undoing some of the changes we\u0026rsquo;ve made. It\u0026rsquo;s good because we\u0026rsquo;ll be able to see immediate results. It\u0026rsquo;s also good to start here because we can start to build the basic layout for the site. As we add more content types, we\u0026rsquo;ll refactor this file and move logic around. Hugo makes that fairly painless, so we\u0026rsquo;ll accept the cost and proceed.\nPlease see the Hugo documentation on template rendering for all the details on determining which template to use. And, as the docs mention, if you\u0026rsquo;re building a single page application (SPA) web site, you can delete all of the other templates and work with just the default single page. That\u0026rsquo;s a refreshing amount of joy right there.\nUpdate the Template File #  $ vi themes/zafta/layouts/_default/single.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:40 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:40 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:40 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:40 public/post/second/index.html $ cat public/post/first/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;first\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my first post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ cat public/post/second/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;second\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my second post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Notice that the posts now have content. You can go to localhost:1313/post/first to verify.\nLinking to Content #  The posts are on the home page. Let\u0026rsquo;s add a link from there to the post. Since this is the home page, we\u0026rsquo;ll update its template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026#34;tag\u0026#34;:\u0026#34;tags\u0026#34;, \u0026#34;category\u0026#34;:\u0026#34;categories\u0026#34;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-r--r-- 1 quoha staff 149 Sep 29 22:44 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:44 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:44 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:44 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;/post/second/\u0026#34;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;/post/first/\u0026#34;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Create a Post Listing #  We have the posts displaying on the home page and on their own page. We also have a file public/post/index.html that is empty. Let\u0026rsquo;s make it show a list of all posts (not just the first ten).\nWe need to decide which template to update. This will be a listing, so it should be a list template. Let\u0026rsquo;s take a quick look and see which list templates are available.\n$ find themes/zafta -name list.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html As with the single post, we have to decide to update _default/list.html or create post/list.html. We still don\u0026rsquo;t have multiple content types, so let\u0026rsquo;s stay consistent and update the default list template.\nCreating Top Level Pages #  Let\u0026rsquo;s add an \u0026ldquo;about\u0026rdquo; page and display it at the top level (as opposed to a sub-level like we did with posts).\nThe default in Hugo is to use the directory structure of the content/ directory to guide the location of the generated html in the public/ directory. Let\u0026rsquo;s verify that by creating an \u0026ldquo;about\u0026rdquo; page at the top level:\n$ vi content/about.md +++ title = \u0026#34;about\u0026#34; description = \u0026#34;about this site\u0026#34; date = \u0026#34;2014-09-27\u0026#34; slug = \u0026#34;about time\u0026#34; +++ ## about us i\u0026#39;m speechless :wq Generate the web site and verify the results.\n$ find public -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:08 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 527 Sep 27 15:08 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:08 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:08 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:08 public/post/second-post/index.html Notice that the page wasn\u0026rsquo;t created at the top level. It was created in a sub-directory named \u0026lsquo;about-time/\u0026rsquo;. That name came from our slug. Hugo will use the slug to name the generated content. It\u0026rsquo;s a reasonable default, by the way, but we can learn a few things by fighting it for this file.\nOne other thing. Take a look at the home page.\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/theme/\u0026#34;\u0026gt;creating a new theme\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/about-time/\u0026#34;\u0026gt;about\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/second-post/\u0026#34;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026#34;http://localhost:1313/post/first-post/\u0026#34;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;script\u0026gt;document.write(\u0026#39;\u0026lt;script src=\u0026#34;http://\u0026#39; + (location.host || \u0026#39;localhost\u0026#39;).split(\u0026#39;:\u0026#39;)[0] + \u0026#39;:1313/livereload.js?mindelay=10\u0026#34;\u0026gt;\u0026lt;/\u0026#39; + \u0026#39;script\u0026gt;\u0026#39;)\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Notice that the \u0026ldquo;about\u0026rdquo; link is listed with the posts? That\u0026rsquo;s not desirable, so let\u0026rsquo;s change that first.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026#34;post\u0026#34;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if eq .Type \u0026#34;page\u0026#34; }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq Generate the web site and verify the results. The home page has two sections, posts and pages, and each section has the right set of headings and links in it.\nBut, that about page still renders to about-time/index.html.\n$ find public -name \u0026#39;*.html\u0026#39; | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:33 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 645 Sep 27 15:33 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:33 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:33 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:33 public/post/second-post/index.html Knowing that hugo is using the slug to generate the file name, the simplest solution is to change the slug. Let\u0026rsquo;s do it the hard way and change the permalink in the configuration file.\n$ vi config.toml [permalinks] page = \u0026#34;/:title/\u0026#34; about = \u0026#34;/:filename/\u0026#34; Generate the web site and verify that this didn\u0026rsquo;t work. Hugo lets \u0026ldquo;slug\u0026rdquo; or \u0026ldquo;URL\u0026rdquo; override the permalinks setting in the configuration file. Go ahead and comment out the slug in content/about.md, then generate the web site to get it to be created in the right place.\nSharing Templates #  If you\u0026rsquo;ve been following along, you probably noticed that posts have titles in the browser and the home page doesn\u0026rsquo;t. That\u0026rsquo;s because we didn\u0026rsquo;t put the title in the home page\u0026rsquo;s template (layouts/index.html). That\u0026rsquo;s an easy thing to do, but let\u0026rsquo;s look at a different option.\nWe can put the common bits into a shared template that\u0026rsquo;s stored in the themes/zafta/layouts/partials/ directory.\nCreate the Header and Footer Partials #  In Hugo, a partial is a sugar-coated template. Normally a template reference has a path specified. Partials are different. Hugo searches for them along a TODO defined search path. This makes it easier for end-users to override the theme\u0026rsquo;s presentation.\n$ vi themes/zafta/layouts/partials/header.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; :wq $ vi themes/zafta/layouts/partials/footer.html \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq Update the Home Page Template to Use the Partials #  The most noticeable difference between a template call and a partials call is the lack of path:\n{{ template \u0026#34;theme/partials/header.html\u0026#34; . }} versus\n{{ partial \u0026#34;header.html\u0026#34; . }} Both pass in the context.\nLet\u0026rsquo;s change the home page template to use these new partials.\n$ vi themes/zafta/layouts/index.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026#34;post\u0026#34;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if or (eq .Type \u0026#34;page\u0026#34;) (eq .Type \u0026#34;about\u0026#34;) }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026#34;{{ .Permalink }}\u0026#34;\u0026gt;{{ .Type }} - {{ .Title }} - {{ .RelPermalink }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Generate the web site and verify the results. The title on the home page is now \u0026ldquo;your title here\u0026rdquo;, which comes from the \u0026ldquo;title\u0026rdquo; variable in the config.toml file.\nUpdate the Default Single Template to Use the Partials #  $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Generate the web site and verify the results. The title on the posts and the about page should both reflect the value in the markdown file.\nAdd “Date Published” to Posts #  It\u0026rsquo;s common to have posts display the date that they were written or published, so let\u0026rsquo;s add that. The front matter of our posts has a variable named \u0026ldquo;date.\u0026rdquo; It\u0026rsquo;s usually the date the content was created, but let\u0026rsquo;s pretend that\u0026rsquo;s the value we want to display.\nAdd “Date Published” to the Template #  We\u0026rsquo;ll start by updating the template used to render the posts. The template code will look like:\n{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }} Posts use the default single template, so we\u0026rsquo;ll change that file.\n$ vi themes/zafta/layouts/_default/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Generate the web site and verify the results. The posts now have the date displayed in them. There\u0026rsquo;s a problem, though. The \u0026ldquo;about\u0026rdquo; page also has the date displayed.\nAs usual, there are a couple of ways to make the date display only on posts. We could do an \u0026ldquo;if\u0026rdquo; statement like we did on the home page. Another way would be to create a separate template for posts.\nThe \u0026ldquo;if\u0026rdquo; solution works for sites that have just a couple of content types. It aligns with the principle of \u0026ldquo;code for today,\u0026rdquo; too.\nLet\u0026rsquo;s assume, though, that we\u0026rsquo;ve made our site so complex that we feel we have to create a new template type. In Hugo-speak, we\u0026rsquo;re going to create a section template.\nLet\u0026rsquo;s restore the default single template before we forget.\n$ mkdir themes/zafta/layouts/post $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Now we\u0026rsquo;ll update the post\u0026rsquo;s version of the single template. If you remember Hugo\u0026rsquo;s rules, the template engine will use this version over the default.\n$ vi themes/zafta/layouts/post/single.html {{ partial \u0026#34;header.html\u0026#34; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026#34;Mon, Jan 2, 2006\u0026#34; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026#34;footer.html\u0026#34; . }} :wq Note that we removed the date logic from the default template and put it in the post template. Generate the web site and verify the results. Posts have dates and the about page doesn\u0026rsquo;t.\nDon\u0026rsquo;t Repeat Yourself #  DRY is a good design goal and Hugo does a great job supporting it. Part of the art of a good template is knowing when to add a new template and when to update an existing one. While you\u0026rsquo;re figuring that out, accept that you\u0026rsquo;ll be doing some refactoring. Hugo makes that easy and fast, so it\u0026rsquo;s okay to delay splitting up a template.\n"},{"id":1,"href":"/posts/migrate-from-jekyll/","title":"Migrate to Hugo from Jekyll","section":"博客预览","content":"Move static content to static #  Jekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/ ▾ images/ logo.png  should become\n▾ \u0026lt;root\u0026gt;/ ▾ static/ ▾ images/ logo.png  Additionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nCreate your Hugo configuration file #  Hugo can read your configuration as JSON, YAML or TOML. Hugo supports parameters custom configuration too. Refer to the Hugo configuration documentation for details.\nSet your configuration publish folder to _site #  The default is for Jekyll to publish to _site and for Hugo to publish to public. If, like me, you have _site mapped to a git submodule on the gh-pages branch, you\u0026rsquo;ll want to do one of two alternatives:\n  Change your submodule to point to map gh-pages to public instead of _site (recommended).\n git submodule deinit _site git rm _site git submodule add -b gh-pages git@github.com:your-username/your-repo.git public    Or, change the Hugo configuration to use _site instead of public.\n { .. \u0026quot;publishdir\u0026quot;: \u0026quot;_site\u0026quot;, .. }    Convert Jekyll templates to Hugo templates #  That\u0026rsquo;s the bulk of the work right here. The documentation is your friend. You should refer to Jekyll\u0026rsquo;s template documentation if you need to refresh your memory on how you built your blog and Hugo\u0026rsquo;s template to learn Hugo\u0026rsquo;s way.\nAs a single reference data point, converting my templates for heyitsalex.net took me no more than a few hours.\nConvert Jekyll plugins to Hugo shortcodes #  Jekyll has plugins; Hugo has shortcodes. It\u0026rsquo;s fairly trivial to do a port.\nImplementation #  As an example, I was using a custom image_tag plugin to generate figures with caption when running Jekyll. As I read about shortcodes, I found Hugo had a nice built-in shortcode that does exactly the same thing.\nJekyll\u0026rsquo;s plugin:\nmodule Jekyll class ImageTag \u0026lt; Liquid::Tag @url = nil @caption = nil @class = nil @link = nil // Patterns IMAGE_URL_WITH_CLASS_AND_CAPTION = IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;(\\s+)-\u0026gt;((https?:\\/\\/|\\/)(\\S+))(\\s*)/i IMAGE_URL_WITH_CAPTION = /((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;/i IMAGE_URL_WITH_CLASS = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))/i IMAGE_URL = /((https?:\\/\\/|\\/)(\\S+))/i def initialize(tag_name, markup, tokens) super if markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK @class = $1 @url = $3 @caption = $7 @link = $9 elsif markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION @class = $1 @url = $3 @caption = $7 elsif markup =~ IMAGE_URL_WITH_CAPTION @url = $1 @caption = $5 elsif markup =~ IMAGE_URL_WITH_CLASS @class = $1 @url = $3 elsif markup =~ IMAGE_URL @url = $1 end end def render(context) if @class source = \u0026quot;\u0026lt;figure class='#{@class}'\u0026gt;\u0026quot; else source = \u0026quot;\u0026lt;figure\u0026gt;\u0026quot; end if @link source += \u0026quot;\u0026lt;a href=\\\u0026quot;#{@link}\\\u0026quot;\u0026gt;\u0026quot; end source += \u0026quot;\u0026lt;img src=\\\u0026quot;#{@url}\\\u0026quot;\u0026gt;\u0026quot; if @link source += \u0026quot;\u0026lt;/a\u0026gt;\u0026quot; end source += \u0026quot;\u0026lt;figcaption\u0026gt;#{@caption}\u0026lt;/figcaption\u0026gt;\u0026quot; if @caption source += \u0026quot;\u0026lt;/figure\u0026gt;\u0026quot; source end end end Liquid::Template.register_tag('image', Jekyll::ImageTag)  is written as this Hugo shortcode:\n\u0026lt;!-- image --\u0026gt; \u0026lt;figure {{ with .Get \u0026quot;class\u0026quot; }}class=\u0026quot;{{.}}\u0026quot;{{ end }}\u0026gt; {{ with .Get \u0026quot;link\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt;{{ end }} \u0026lt;img src=\u0026quot;{{ .Get \u0026quot;src\u0026quot; }}\u0026quot; {{ if or (.Get \u0026quot;alt\u0026quot;) (.Get \u0026quot;caption\u0026quot;) }}alt=\u0026quot;{{ with .Get \u0026quot;alt\u0026quot;}}{{.}}{{else}}{{ .Get \u0026quot;caption\u0026quot; }}{{ end }}\u0026quot;{{ end }} /\u0026gt; {{ if .Get \u0026quot;link\u0026quot;}}\u0026lt;/a\u0026gt;{{ end }} {{ if or (or (.Get \u0026quot;title\u0026quot;) (.Get \u0026quot;caption\u0026quot;)) (.Get \u0026quot;attr\u0026quot;)}} \u0026lt;figcaption\u0026gt;{{ if isset .Params \u0026quot;title\u0026quot; }} {{ .Get \u0026quot;title\u0026quot; }}{{ end }} {{ if or (.Get \u0026quot;caption\u0026quot;) (.Get \u0026quot;attr\u0026quot;)}}\u0026lt;p\u0026gt; {{ .Get \u0026quot;caption\u0026quot; }} {{ with .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt; {{ end }} {{ .Get \u0026quot;attr\u0026quot; }} {{ if .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;/a\u0026gt; {{ end }} \u0026lt;/p\u0026gt; {{ end }} \u0026lt;/figcaption\u0026gt; {{ end }} \u0026lt;/figure\u0026gt; \u0026lt;!-- image --\u0026gt;  Usage #  I simply changed:\n{% image full http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg \u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were \u0026quot;having fun\u0026quot; and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; -\u0026gt;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/ %}  to this (this example uses a slightly extended version named fig, different than the built-in figure):\n{{% fig class=\u0026quot;full\u0026quot; src=\u0026quot;http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg\u0026quot; title=\u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were having fun and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; link=\u0026quot;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/\u0026quot; %}}  As a bonus, the shortcode named parameters are, arguably, more readable.\nFinishing touches #  Fix content #  Depending on the amount of customization that was done with each post with Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch is your friend. Test your changes and fix errors as needed.\nClean up #  You\u0026rsquo;ll want to remove the Jekyll configuration at this point. If you have anything else that isn\u0026rsquo;t used, delete it.\nA practical example in a diff #  Hey, it\u0026rsquo;s Alex was migrated in less than a father-with-kids day from Jekyll to Hugo. You can see all the changes (and screw-ups) by looking at this diff.\n"},{"id":2,"href":"/docs/19-hugo-book/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","title":"Hugo搭建博客","section":"19-hugo-book","content":"安装hugo #  brew install hugo 创建项目 #  hugo new site mlzhang_wiki  cd mlzhang_wiki git init  # 安装主题 git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book  hugo mod init github.com/repo/path   # config.toml 添加 [module] [[module.imports]] path = \u0026#39;github.com/alex-shpak/hugo-book\u0026#39;   # 拷贝示例 cp -R themes/hugo-book/exampleSite/content . 启动本地服务 #  hugo server -D "},{"id":3,"href":"/docs/19-hugo-book/github%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E6%89%98%E7%AE%A1/","title":"Github静态页面托管","section":"19-hugo-book","content":"托管到Github Pages #  参考文档：\n https://zhuanlan.zhihu.com/p/350977057  对于托管到Github Pages，官方文档写的不是那么特别清楚，实际上是非常简单的。\n因为是博客，所以遵循Github Pages的规则，项目名称就是username.github.io，建一个这样名字的库，权限设置为public，默认选项一个都不要勾选，建完了以后，就会看到这样一个界面。\n我们前文已经初始化过git库了，所以这里我们只要把远程库的地址加进来就好了。\n在这之前，先随便创建一个README.md文件，一会儿用得到它。\nstudyhugo $ echo \u0026#34;# Blog Contructing......\u0026#34; \u0026gt;\u0026gt; README.md 然后创建master分支\nstudyhugo $ git add . studyhugo $ git branch -M master studyhugo $ git commit -m \u0026#34;Initial Commit\u0026#34; studyhugo $ git remote add origin git@github.com:username/username.github.io.git 然后push上去。\nstudyhugo $ git push 到Github上看到我们Hugo站点源文件已经push上来了。\n对于username.github.io这样的项目名，Github会直接认定为Github Pages并发布。所以现在已经可以访问https://username.github.io。\n当然，因为Github Pages并不直接支持Hugo站点的发布，所以它发布了我们添加进去的README.md文件。\n接下来我们就要添加Github Action，Hugo官方已经给我们准备好了，我们自己要做的事很少，参考官方文档的这一节。\n官方提供了一个yml文件，文件应该存在.github/workflows/gh-pages.yml里。\n在项目的选项里选择Actions——\n点进去以后是这样子的——\n把这里的文件名改成gh-pages.yml，删掉当前的内容，然后把官方提供的代码拷贝进来，注意这里官方的代码部署用的分支是main，而我们的是master，要对应的改掉。\nname: github pages  on:  push:  branches:  - master  # Set a branch to deploy  jobs:  deploy:  runs-on: ubuntu-18.04  steps:  - uses: actions/checkout@v2  with:  submodules: true # Fetch Hugo themes (true OR recursive)  fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod   - name: Setup Hugo  uses: peaceiris/actions-hugo@v2  with:  hugo-version: \u0026#39;latest\u0026#39;  # extended: true   - name: Build  run: hugo --minify   - name: Deploy  uses: peaceiris/actions-gh-pages@v3  with:  github_token: ${{ secrets.GITHUB_TOKEN }}  publish_dir: ./public 然后Commit。\n再次回到Actions界面，由于Commit了一个新文件，所以会立刻触发一次构建发布的任务。\n如上所示，所有任务完成，回到Code选项里，现在会在分支中看到一个gh-pages的分支。\n在master分支里是看不到/public目录的，也看不到任何发布后的文件，但是切到gh-pages分支，就会看到发布后的文件——\n接下来还需要到Setting选项里设置Github Pages设置发布源为gh-pages。\n等一小会儿，再次访问 https://username.github.io\nYeah～\n等等，为什么没有任何post？\n因为我们的第一篇post的draft属性是true，而发布的配置里并没有带上-D这样的参数去执行。\n因为github上已经发生了变化，所以先用git pull命令把远端的库拉下来。\n$ git pull remote: Enumerating objects: 24, done. remote: Counting objects: 100% (24/24), done. remote: Compressing objects: 100% (14/14), done. remote: Total 23 (delta 6), reused 18 (delta 5), pack-reused 0 Unpacking objects: 100% (23/23), done. From github.com:nightan42643/nightan42643.github.io  f21abd4..e85fb85 master -\u0026gt; origin/master  * [new branch] gh-pages -\u0026gt; origin/gh-pages Updating f21abd4..e85fb85 Fast-forward  .github/workflows/gh-pages.yml | 30 ++++++++++++++++++++++++++++++  1 file changed, 30 insertions(+)  create mode 100644 .github/workflows/gh-pages.yml studyhugo $ 再查看所有的分支，远端现在多了一个分支gh-pages。\n$ git branch -a * master  remotes/origin/gh-pages  remotes/origin/master 不切换分支，因为gh-pages是由Action去发布操作的，我们不去动。我们修改本地的文件my-first-post.md的属性然后重新push一次。\n$ cat content/posts/my-first-post.md --- title: \u0026#34;My First Post\u0026#34; date: 2021-02-16T21:53:17+08:00 draft: false --- # My First Post Testing..... Commit并查看log\nstudyhugo $ git add content/posts/my-first-post.md studyhugo $ git commit -m \u0026#34;Published my-first-post.md\u0026#34; [master 52450d9] Published my-first-post.md  1 file changed, 3 insertions(+), 2 deletions(-) studyhugo $ git log commit 52450d9576e468addb15f5fa719fbbcae590662a (HEAD -\u0026gt; master) Author: nightan \u0026lt;nightan-pub@outlook.com\u0026gt; Date: Tue Feb 16 23:11:42 2021 +0800   Published my-first-post.md  commit e85fb8539e47784ec9bef21c4f3085e67ddf712f (origin/master) Author: nightan \u0026lt;38649296+nightan42643@users.noreply.github.com\u0026gt; Date: Tue Feb 16 22:33:30 2021 +0800   Create gh-pages.yml  commit f21abd4cabb6479c10c64f5a96f78c8febbb1809 Author: nightan \u0026lt;nightan-pub@outlook.com\u0026gt; 然后push上去。\n在Actions里能看到一个新的workflow，这个workflow结束后，再次访问页面就可以看到发布后的blog了。\n但是当我访问第一篇文档的时候，遇到了问题\n可以很容易地看出，URL错了。\n需要修改config.toml里的baseURL的参数，确保改成username.github.io\n$ cat config.toml  baseURL = \u0026#34;http://nightan42643.github.io\u0026#34; 再push一次。\n现在可以正常访问了。\n"},{"id":4,"href":"/docs/19-hugo-book/%E6%B7%BB%E5%8A%A0%E9%98%BF%E9%87%8C%E4%BA%91%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/","title":"添加阿里云域名解析","section":"19-hugo-book","content":"使用自定义域名来访问GitHub上部署的hugo博客——GitHub Pages #  参考链接\n https://cloud.tencent.com/developer/article/1834163   hugo博客搭建好了，但访问的时候只能是以固定的域名形式（用户名.github.io）进行访问。这时可以通过购买域名的方式行实现自定义域名访问。可以去国外买或者国内，国内都是需要备案的。\n https://sg.godaddy.com/zh例如这个就是国外购买域名的网站，直接购买即可。如果是国内的话需要购买域名和服务器或主机才能备案。\n购买域名后：\n第一步 #  首先是用ping命令找到存放你的github pages的主机的IP地址，在终端里面用命令ping xxx.github.io便可完成，下图中红框内的就是我们要找的IP地址：\n第二步 #  在购买域名的提供商为域名添加解析。我是在阿里云买的域名，因此我以阿里云的为例。在域名控制台选择想要绑定的域名，并点击解析：\n然后添加如下两条记录：\n 记录类型：CNAME 将一个域名指向例外一个域名，再由另一个域名提供 IP 地址，就需要添加 CNAME 记录。 主机记录：www 表示访问域名的时候以www开头为一级域名。如果是二级域名的话就在前面加上自己想要的参数，访问的时候也是以二级域名的形式访问。   记录类型：A 将域名指向一个IPv4地址，如果需要将域名指向一个 IP 地址（外网地址），就需要添加 A 记录。 主机记录：@ 表示访问的时候直接用 yunxdr.top 形式 访问，前面不加任何参数。如果是www，就要以 www.yunxdr.top 访问。这里设置的@形式与下面GitHub上自定义的域名要对应  第三步 #   在上面存放静态网站的Repository Settings里面GitHubPages Custom domain（自定义域名）填上自己的域名点击save；  设置完成后就可以通过 yunxdr.top 访问部署在GitHub上的hugo的网站了\n例外如果不太懂解析域名的可以参考如下资料：\n关于记录值www和@的区别\n 创建 www.dns-example.com 的子域名。   创建 dns-example.com 的子域名。  "},{"id":5,"href":"/posts/goisforlovers/","title":"(Hu)go Template Primer","section":"博客预览","content":"Hugo uses the excellent Go html/template library for its template engine. It is an extremely lightweight engine that provides a very small amount of logic. In our experience that it is just the right amount of logic to be able to create a good static website. If you have used other template systems from different languages or frameworks you will find a lot of similarities in Go templates.\nThis document is a brief primer on using Go templates. The Go docs provide more details.\nIntroduction to Go Templates #  Go templates provide an extremely simple template language. It adheres to the belief that only the most basic of logic belongs in the template or view layer. One consequence of this simplicity is that Go templates parse very quickly.\nA unique characteristic of Go templates is they are content aware. Variables and content will be sanitized depending on the context of where they are used. More details can be found in the Go docs.\nBasic Syntax #  Golang templates are HTML files with the addition of variables and functions.\nGo variables and functions are accessible within {{ }}\nAccessing a predefined variable \u0026ldquo;foo\u0026rdquo;:\n{{ foo }}  Parameters are separated using spaces\nCalling the add function with input of 1, 2:\n{{ add 1 2 }}  Methods and fields are accessed via dot notation\nAccessing the Page Parameter \u0026ldquo;bar\u0026rdquo;\n{{ .Params.bar }}  Parentheses can be used to group items together\n{{ if or (isset .Params \u0026quot;alt\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;) }} Caption {{ end }}  Variables #  Each Go template has a struct (object) made available to it. In hugo each template is passed either a page or a node struct depending on which type of page you are rendering. More details are available on the variables page.\nA variable is accessed by referencing the variable name.\n\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt;  Variables can also be defined and referenced.\n{{ $address := \u0026quot;123 Main St.\u0026quot;}} {{ $address }}  Functions #  Go template ship with a few functions which provide basic functionality. The Go template system also provides a mechanism for applications to extend the available functions with their own. Hugo template functions provide some additional functionality we believe are useful for building websites. Functions are called by using their name followed by the required parameters separated by spaces. Template functions cannot be added without recompiling hugo.\nExample:\n{{ add 1 2 }}  Includes #  When including another template you will pass to it the data it will be able to access. To pass along the current context please remember to include a trailing dot. The templates location will always be starting at the /layout/ directory within Hugo.\nExample:\n{{ template \u0026quot;chrome/header.html\u0026quot; . }}  Logic #  Go templates provide the most basic iteration and conditional logic.\nIteration #  Just like in Go, the Go templates make heavy use of range to iterate over a map, array or slice. The following are different examples of how to use range.\nExample 1: Using Context\n{{ range array }} {{ . }} {{ end }}  Example 2: Declaring value variable name\n{{range $element := array}} {{ $element }} {{ end }}  Example 2: Declaring key and value variable name\n{{range $index, $element := array}} {{ $index }} {{ $element }} {{ end }}  Conditionals #  If, else, with, or, \u0026amp; and provide the framework for handling conditional logic in Go Templates. Like range, each statement is closed with end.\nGo Templates treat the following values as false:\n false 0 any array, slice, map, or string of length zero  Example 1: If\n{{ if isset .Params \u0026quot;title\u0026quot; }}\u0026lt;h4\u0026gt;{{ index .Params \u0026quot;title\u0026quot; }}\u0026lt;/h4\u0026gt;{{ end }}  Example 2: If -\u0026gt; Else\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{else}} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }}  Example 3: And \u0026amp; Or\n{{ if and (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}}  Example 4: With\nAn alternative way of writing \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent.\nThe first example above could be simplified as:\n{{ with .Params.title }}\u0026lt;h4\u0026gt;{{ . }}\u0026lt;/h4\u0026gt;{{ end }}  Example 5: If -\u0026gt; Else If\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{ else if isset .Params \u0026quot;caption\u0026quot; }} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }}  Pipes #  One of the most powerful components of Go templates is the ability to stack actions one after another. This is done by using pipes. Borrowed from unix pipes, the concept is simple, each pipeline\u0026rsquo;s output becomes the input of the following pipe.\nBecause of the very simple syntax of Go templates, the pipe is essential to being able to chain together function calls. One limitation of the pipes is that they only can work with a single value and that value becomes the last parameter of the next pipeline.\nA few simple examples should help convey how to use the pipe.\nExample 1 :\n{{ if eq 1 1 }} Same {{ end }}  is the same as\n{{ eq 1 1 | if }} Same {{ end }}  It does look odd to place the if at the end, but it does provide a good illustration of how to use the pipes.\nExample 2 :\n{{ index .Params \u0026quot;disqus_url\u0026quot; | html }}  Access the page parameter called \u0026ldquo;disqus_url\u0026rdquo; and escape the HTML.\nExample 3 :\n{{ if or (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}} Stuff Here {{ end }}  Could be rewritten as\n{{ isset .Params \u0026quot;caption\u0026quot; | or isset .Params \u0026quot;title\u0026quot; | or isset .Params \u0026quot;attr\u0026quot; | if }} Stuff Here {{ end }}  Context (aka. the dot) #  The most easily overlooked concept to understand about Go templates is that {{ . }} always refers to the current context. In the top level of your template this will be the data set made available to it. Inside of a iteration it will have the value of the current item. When inside of a loop the context has changed. . will no longer refer to the data available to the entire page. If you need to access this from within the loop you will likely want to set it to a variable instead of depending on the context.\nExample:\n {{ $title := .Site.Title }} {{ range .Params.tags }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026quot;{{ $baseurl }}/tags/{{ . | urlize }}\u0026quot;\u0026gt;{{ . }}\u0026lt;/a\u0026gt; - {{ $title }} \u0026lt;/li\u0026gt; {{ end }}  Notice how once we have entered the loop the value of {{ . }} has changed. We have defined a variable outside of the loop so we have access to it from within the loop.\nHugo Parameters #  Hugo provides the option of passing values to the template language through the site configuration (for sitewide values), or through the meta data of each specific piece of content. You can define any values of any type (supported by your front matter/config format) and use them however you want to inside of your templates.\nUsing Content (page) Parameters #  In each piece of content you can provide variables to be used by the templates. This happens in the front matter.\nAn example of this is used in this documentation site. Most of the pages benefit from having the table of contents provided. Sometimes the TOC just doesn\u0026rsquo;t make a lot of sense. We\u0026rsquo;ve defined a variable in our front matter of some pages to turn off the TOC from being displayed.\nHere is the example front matter:\n--- title: \u0026#34;Permalinks\u0026#34; date: \u0026#34;2013-11-18\u0026#34; aliases: - \u0026#34;/doc/permalinks/\u0026#34; groups: [\u0026#34;extras\u0026#34;] groups_weight: 30 notoc: true --- Here is the corresponding code inside of the template:\n {{ if not .Params.notoc }} \u0026lt;div id=\u0026quot;toc\u0026quot; class=\u0026quot;well col-md-4 col-sm-6\u0026quot;\u0026gt; {{ .TableOfContents }} \u0026lt;/div\u0026gt; {{ end }}  Using Site (config) Parameters #  In your top-level configuration file (eg, config.yaml) you can define site parameters, which are values which will be available to you in chrome.\nFor instance, you might declare:\nparams:  CopyrightHTML: \u0026#34;Copyright \u0026amp;#xA9; 2013 John Doe. All Rights Reserved.\u0026#34;  TwitterUser: \u0026#34;spf13\u0026#34;  SidebarRecentLimit: 5 Within a footer layout, you might then declare a \u0026lt;footer\u0026gt; which is only provided if the CopyrightHTML parameter is provided, and if it is given, you would declare it to be HTML-safe, so that the HTML entity is not escaped again. This would let you easily update just your top-level config file each January 1st, instead of hunting through your templates.\n{{if .Site.Params.CopyrightHTML}}\u0026lt;footer\u0026gt; \u0026lt;div class=\u0026#34;text-center\u0026#34;\u0026gt;{{.Site.Params.CopyrightHTML | safeHtml}}\u0026lt;/div\u0026gt; \u0026lt;/footer\u0026gt;{{end}} An alternative way of writing the \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent:\n{{with .Site.Params.TwitterUser}}\u0026lt;span class=\u0026#34;twitter\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;https://twitter.com/{{.}}\u0026#34; rel=\u0026#34;author\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;/images/twitter.png\u0026#34; width=\u0026#34;48\u0026#34; height=\u0026#34;48\u0026#34; title=\u0026#34;Twitter: {{.}}\u0026#34; alt=\u0026#34;Twitter\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt;{{end}} Finally, if you want to pull \u0026ldquo;magic constants\u0026rdquo; out of your layouts, you can do so, such as in this example:\n\u0026lt;nav class=\u0026#34;recent\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Recent Posts\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt;{{range first .Site.Params.SidebarRecentLimit .Site.Recent}} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{.RelPermalink}}\u0026#34;\u0026gt;{{.Title}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {{end}}\u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; "},{"id":6,"href":"/posts/hugoisforlovers/","title":"Getting Started with Hugo","section":"博客预览","content":"Step 1. Install Hugo #  Go to Hugo releases and download the appropriate version for your OS and architecture.\nSave it somewhere specific as we will be using it in the next step.\nMore complete instructions are available at Install Hugo\nStep 2. Build the Docs #  Hugo has its own example site which happens to also be the documentation site you are reading right now.\nFollow the following steps:\n Clone the Hugo repository Go into the repo Run hugo in server mode and build the docs Open your browser to http://localhost:1313  Corresponding pseudo commands:\ngit clone https://github.com/spf13/hugo cd hugo /path/to/where/you/installed/hugo server --source=./docs \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Press ctrl+c to stop  Once you\u0026rsquo;ve gotten here, follow along the rest of this page on your local build.\nStep 3. Change the docs site #  Stop the Hugo process by hitting Ctrl+C.\nNow we are going to run hugo again, but this time with hugo in watch mode.\n/path/to/hugo/from/step/1/hugo server --source=./docs --watch \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Watching for changes in /Users/spf13/Code/hugo/docs/content \u0026gt; Press ctrl+c to stop  Open your favorite editor and change one of the source content pages. How about changing this very file to fix the typo. How about changing this very file to fix the typo.\nContent files are found in docs/content/. Unless otherwise specified, files are located at the same relative location as the url, in our case docs/content/overview/quickstart.md.\nChange and save this file.. Notice what happened in your terminal.\n\u0026gt; Change detected, rebuilding site \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 26 ms  Refresh the browser and observe that the typo is now fixed.\nNotice how quick that was. Try to refresh the site before it\u0026rsquo;s finished building. I double dare you. Having nearly instant feedback enables you to have your creativity flow without waiting for long builds.\nStep 4. Have fun #  The best way to learn something is to play with it.\n"},{"id":7,"href":"/docs/19-hugo-book/hidden/","title":"Hidden","section":"19-hugo-book","content":"This page is hidden in menu #  Quondam non pater est dignior ille Eurotas #  Latent te facies #  Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\n Pater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor  Cum honorum Latona #  O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); }  Fronde cetera dextrae sequens pennis voce muneris #  Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired)); "},{"id":8,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/00-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D/","title":"00-Python设计模式介绍","section":"11-Python设计模式","content":"简介 #  Python的设计模式可以分为三大类，创建型模式，结构型模式，行为型模式\n创建型模式 #  介绍处理对象创建的设计模式，具体有：\n 工厂模式 建造者模式 原型模式  结构型模式 #  介绍处理一个系统中不同实体（类、对象等）之间的关系，具体有：\n 适配器模式 修饰器模式 外观模式 享元模式 模型-视图-控制器模式 代理模式  行为型模式 #  介绍处理系统实体之间通信的设计模式，具体有：\n 责任链模式 命令模式 解释器模式 观察者模式 状态模式 策略模式 模板模式  "},{"id":9,"href":"/docs/14-docker/01-centos7%E5%AE%89%E8%A3%85docker/","title":"01-CentOS7安装docker","section":"14-docker","content":"CentOS 7 安装docker #  yum update\nvim /etc/yum.repos.d/docker.repo\n[dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/7/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg yum install docker-engine 安装docker包\nsystemctl start docker 启动docker服务\nmkdir /etc/systemd/system/docker.service.d\nvim /etc/sysytemd/system/docker.service.d/http-proxy.conf # 添加代理\n[Service] Enviroment=”HTTP_PROXY=http://用户名：密码@代理地址：端口号”   例子 [Service] Environment=\u0026#34;HTTP_PROXY=http://proxy.ip.com:80\u0026#34; "},{"id":10,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/01-git_flow%E5%B7%A5%E4%BD%9C%E6%B5%81%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","title":"01-git_flow工作流使用指南","section":"15-集成开发","content":"Git Flow使用方法 #  git flow是一个git的扩展集。Git flow 可以工作在 OSX, Linux 和 Windows之下。 本文主要列举一些常用的git flow命令。以及git flow从无到有的步骤；\n 安装。 初始化。  git flow init 最后就一路回车选择默认的就ok了，，接下来就是使用了    常用命令以及分支：\n分支介绍：\n master。  只有一个，并且不会在master上进行代码的操作。   develop。  只有一个，新特性的开发是基于develop开发的，但是不能直接在develop上进行开发，而是在基于develop上创建feature分支进行新特性的开发。   feature。  可以同时存在多个，基于develop分支被创建。对于每一个新的功能可以创建一个新的feature分支，开发结束之后，合并到develop分支即可。 创建一个新的feature分支，命令：git flow feature start name 执行之后，feature/name分支就会被创建。 当新特性开发完成过后，需要合并到develop上，命令:git flow feature finish name 执行之后，feature/name分支的内容就会合并到develop，，并且删除feature/name分支。   release分支。  release分支是为了发布而存在的分支，基于develop分支被创建。在同一时间只能有一个release分支，在此分支上仅仅是较少代码的修复。否则，容易引起release分支不稳定。当release分支被创建之后，develop分支可能在准备另一个版本的，因此，当release分支merge回develop分支时候可能会出现冲突，需要手工解决冲突。 创建一个release分支，命令：git flow release start v.1.0 当完成release分支功能之后，执行命令：git flow release finish v.1.0。这个命令会执行一下的操作：（1.分支merge回master分支；2.使用release分支名称打tag；3.release分支merge回develop分支；4.删除release分支。）   hotfix分支。  当发现master分支出现一个需要紧急修复的bug，这个时候就需要使用hotfix。基于master分支被创建。同一时间只有一个hotfix分支，生命周期比较短。 创建hotfix分支。命令：git flow hotfix start v.1.0   结束hotfix分支。  命令：git flow hotfix finish v.1.0。会把hotfix分支merge到master和develop分支，并且删除此分支。（⚠️注意，如果bug修复时，存在release分支，那么hotfix会merge到release分支，不是develop了。）    通过下图大致了解一下基本命令：\n以下这些是我在使用过程中遇到的一些解决方法：\nissue2以及version2都是feature分支，同时间在开发，但是功能并为结束，仅仅进入测试阶段，最后都需要合并到develop上，（这里不合适，不应该在develop上进行开发测试）这个时候，我们可以直接切到develop上，进行　git merge feature/issue2 这里也是可以的，但是最保险并且分支图美观的做法就是现在issue2分支上fetch和rebase，，\n命令：git fetch  git rebase develop issue2.\n 直接把目前develop上最新的代码合并到issue2 上，如果有冲突的话可以可以直接在issue2上进行修改，不会影响到develop分支。  "},{"id":11,"href":"/docs/03-git/01-git%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%E5%92%8C%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/","title":"01-Git基本用法和工作流程","section":"03-Git","content":"windows git操作 #    主要流程 #    windows本地操作 git init (第一次要设置user.name, user.email) git add . git status git commit -m \u0026#34;修改说明\u0026#34; git remote add origin \u0026lt;远端仓库url\u0026gt; git push origin master 同步到远端 git pull 从远端下载版本到本地  远端克隆到本地 git clone \u0026lt;远端仓库的url\u0026gt; cd 仓库名 进入克隆下的仓库 git branch \u0026lt;分支名\u0026gt; 创建自己的分支修改文件 git branch -d \u0026lt;分支名\u0026gt; 删除分支 git checkout \u0026lt;分支名\u0026gt; 切换分支 修改本地文件 git add . git status (查看一下状态) git commit -m \u0026#34;修改描述\u0026#34; git remote add origin \u0026lt;远端的url\u0026gt; git push origin master \u0026lt;上传\u0026gt; \t一般是以分支提交的,以master提交会覆盖主分支 git pull \u0026lt;下载远端同步\u0026gt;  合并分支, 合并前先切换到 master 里 git merge \u0026lt;分支名\u0026gt; 默认的会将分支合并道 master里  日志 git log --online \t用 --graph 选项，查看历史中什么时候出现了分支、合并  git init 将文件夹变文本地仓库 notepad test.txt 创建文件 git add + filename/git add . 将当前文件目录的所有文件添加版本控制 初次要设置用户名和邮箱  git config --global user.name 'zhang' git config --global user.email 'zhang.email'    本地仓库 #   初始化git  git init 将文件夹变为本地仓库   git add + filename/git add . 将当前文件目录的所有文件添加版本控制 git commit -m \u0026quot;修改的内容,提交的原因\u0026quot; 提交本地的修改后的版本 git status 查看暂存区状态, 有没有修改文件 -commit 提交 git log 查看日志  版本控制 #   git reset --hard 版本号的前六位 回到版本 git reflog 查看历史日志 log --pretty=oneline 单行查看日志  撤回暂存区内容, 撤回错误的操作 #   git checkout--文件名(不加表示撤掉所有)  修改之后重新提交   Gitlab 可以自己搭建服务器  添加到远端仓库, 具体操作 #   本地建仓库提交到远端  makdir hello cd hello git init git add . git status git commit -m \u0026quot;\u0026quot;说明\u0026quot; git log    链接远程仓库  git remote add origin url   提交  git push -u origin master 第一次使用加 -u    从远程仓库克隆 #   git clone url 在桌面克隆一个远程仓库 add .  commit -m git push origin master (origin 项目的别名) 将项目提交到主干上面 git pull 从远端同步到本地  重置版本 #   git reset --hard id git reflog git remote add origin (url) git push -u origin master git pull (url)  远端已存在的项目,克隆到本地 #   git clone (url) cd hello  git add . git checkout -- git commit -m \u0026quot;说明\u0026quot; git push origin master git pull  git 使用流程 #   git cone \u0026lt;url\u0026gt; cd \u0026lt;dir\u0026gt; git branch 分支名  创建 git checkout 分支名  切换 合并 切换到master 分支  git merge cool-function 将分支合并到master git push origin master    "},{"id":12,"href":"/docs/02-%E5%89%8D%E7%AB%AFhtml-js-css/01-html%E6%A0%87%E7%AD%BE%E5%92%8Ccss%E6%A0%B7%E5%BC%8F%E8%A1%A8/","title":"01-HTML标签和CSS样式表","section":"02-前端HTML-js-css","content":"1.常用的标签 #    文本\n h1 - h6 / p / hr / br / sup / sub / em / strong    列表\n ul-li / ol-li / dl/ dt / dd table-th-tr-td-caption(rowspan/colspan)    图像\n image(src=\u0026rsquo;\u0026rsquo; alt=\u0026rsquo;')    音频视屏\n audio/source controls autoplay loop vidieo / source \u0026lt;audio controls autoplay loop\u0026gt;    区域\n div / span    表单\n  form 外框-fieldset 表单标题-lengenda 标签label 输入框 input\n  input 文本-text 密码-password 占位提示符-placeholder\n 单选框 type=radio 多选 checkbox 上传文件 type=file 指定名字name 提交 submit 重填 reset    下拉菜单 select\u0026gt;option*5 selected默认选中, value发送到服务器的值name是发送的名字\n  文本\n  textarea rows/cols 日历 type=\u0026lsquo;data\u0026rsquo;\n    2.层叠样式表 #   优先级排序  id选择器(#) \u0026gt; 类选择器(.) \u0026gt; 标签选择器 (div)\u0026gt; 通配符选择器(*)   样式冲突  就近原则: 离得近的优先级高 具体性原则: 选择的器写的更加具体优先 重要性原则: !important在标签后加    关键词组命令\n background: 背景色 背景图 平铺选择(repead) 偏移 字体  font-size font-family font-style font-weight   文本  color text-align letter-spacing text-decorator   盒子  padding margin border background display visibility   列表  list-style(列表前的小圆点的样式) list-style-position border-collapse    padding-top:50px; 块内上部间距 50px text-align: center; 文本居中 text-decoration:underline; 文本装饰 加下划线 none background-color:pink; 背景颜色 background: 背景色 背景图片 平铺选择 偏移选择 margin: 上 右 下 左; 块外所留的大小 border:none; 去边框 cursor:pointer: 鼠标指针变化 :havor 鼠标悬停变化 :active 激活 点击变色 也可display  # login input[type=\u0026#34;text\u0026#34;], #login input[type=\u0026#34;password\u0026#34;] { border:none; border-collapse:collapse; 表格合并边框 border-bottom:1px solid green; outline: none; 输入框边线取消 }  font: font_style size font_family; background:bk-color bk-image bk-repead/no-repead -position 10px;  display:none; 隐藏 所占的位置也消失 visibility:hiden; 隐藏 但占据的空间任然在  在css中使用自定义字体  /*传输别人没有的字体*/ css文件加载 乱码 加一行 @charset \u0026#34;utf-8\u0026#34; 引用css文件 link (不用style)  @font-face { \tfont-family: 命名字体的别名; /* 在引用字体格式时可以 引用别名 最好使用期自身的名字*/ \tsrc: url();/* ./ 表示当前路径 将字体文件放在指定的文件夹 添加字体路径*/ }  浮动和定位  float 浮动, 清除浮动, clear    浮动 folat:right/left 定位:不适合用margin padding 清除浮动 clear: 使后面的内容脱离文档流 /* right left both*/ #foo{\t\tclear:right; \t} 相对定位; poisition : relative \t没有脱离文档流 对兄弟元素没有影响 相对于元素原来的位置进行定位 /*块级元素 (block) 行级元素(内联元素 inline)*/ \t/*static 正常文档流 (默认模式) folat */ \t/* relative 相对定位 相对原来的位置偏离位置 没有脱离文档流*/ abslout 绝对定位:相对于父元素来说设定位置 脱离的正常的文档流 \t对兄弟元素有影响(相当于其不存在的情况下其兄弟元素进行补位了) fixed 固定定位:相对于浏览器窗口来设定元素原来的位置 脱离了文档流 Z-index: num; 数字越大 最后出现 数字小的会被大的覆盖  处理塌陷问题 \u0026lt;div style=\u0026#34;clear: both;\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 空白 div 用于方便计算 div高度 ovreflow: auto; 设置自动溢出文档 #foo { /* 在设置最外层块时添加 overflow:auto; */ \toverflow: auto; /* css hack 使外框显示出来*/ \t} "},{"id":13,"href":"/docs/05-linux/01-linux%E6%93%8D%E4%BD%9C%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%BB%E6%9C%BA/","title":"01-Linux操作,阿里云主机","section":"05-Linux","content":"Linux命令和操作方法 #  linux介绍 #   Linux 的内核是开源的 下载 kernel.org 网站下载 开源内核 第二位(中间)是偶数是稳定版本 linux \u0026ndash;\u0026gt; 基于 MINIX \u0026ndash; \u0026gt; 基于 UniX  Linux 是通用操作系统 第一台计算机 \u0026ndash;\u0026gt; 帕斯卡发明的 Pascal 17岁 第一台数字计算机 \u0026mdash;差分机\u0026mdash;没有软件只有硬件 \u0026ndash; 第一个程序员Ada 第一台电子数字计算机 - ENIAC - 图灵 程序员 \u0026ndash;死于一个毒苹果 \u0026ndash;苹果Logo 纪念它   内核是Linux Linux发行版本 Redhat Linux Ubantu Nginx -可以把阿里云变为 Web 服务器 MySQL -关系型数据库 -持久化数据\nRedis - 非关系型数据库 FTP Mail 防火墙 iptables /filewalls  1.操作命令介绍 #    root 提示符是 #, 普通用户是 $\n  who 查看哪些用户登录了系统\n  whoami 查看自己是谁\n  w 查看详细信息\n  clear 清屏 windows系统 cls\n  ps 查看内核 查看 shell 种类 (bash zsh csh)\n  adduser 创建用户 + 用户名\n  passwd + 用户名 回车 输入密码\n  logout 断开服务器连接\n  reboot 重启服务器 也可以使用 init 6 \n  shutdown 关闭服务器 也可以使用 init 0 \n  uname 查看操作系统名称\n  hostname 主机名\n  tab tab 自动补全功能,给与提示\n  查看帮助\n man shutdown 查看命令的使用手册 man + 命令 info + 命令 专业角度详细解释命令 命令 \u0026ndash;help 查看帮助 whatis + 命令名 查看简短的秒数 apropos    which python 那个是python 找到python解释器的位置\n  whereis 文件/应用 查看文件/应用所在的目录\n  Ctrl + c 终止命令\n  jobs 查看有没有后台程序\n fg %1 将一号任务放在前台使用 bg %1 将任务放回后台 ctrl + z 停止任务    2.身份切换 #    sudo 扮演超级管理员身份\n  su + 用户名 切换用户\n  usrdel删除用户\n  ssh root@IP地址 远程连接其他服务器 wall 超级管理员发警告\n scp 安全拷贝 可以从其他服务器里拷贝东西  scp 原文件 目标文件 hellokitty@ip :/home/hellokitty      3.文件操作 #   文件参数  修改参数修改内容 访问权限 最后访问时间    1.查看文件\n ls   查看文件夹 list directory contents ls -l  查看完整的文件目录详情 列表开头是d 开始的都是文件目录 ls -a  查看所有文件 以 . 开头的文件和文件夹都是隐藏文件 ls -la 查看所有信息 长格式所有文件 ls --help | less 少显示 ls -d 显示问价夹 ls -r reverse  反转显示 按首字母反序显示 ls -R 平铺式显示文件 所有文件夹都展开显示 reucrsive  ()递归)   cd  回到上级目录 cd .. 相对路径 也可以用绝对路径 cd /home/目录名  cd ~ 回到用户主目录 cd /  系统根目录    2.文件权限\n rw- 不能执行文件 +x ./文件名 执行文件 rex r-x r-x 文件所有者可以读 写 执行(execute) 其他能读和执行 chmod u+x + 文件名 加执行权限 chmod o+x,g+x 文件名 给同组用户 其他用户添加执行权限 chmod 777 + 文件名 所有人都有读写权限 二进制  * rwx rwx rwx rwx rw- rw- rwx r-- r-- rw- -wx -wx * 111 111 111 111 110 110 111 100 100 110 011 011 * 7 7 7 7 6 6 7 4 4 6 3 3 * 4 只读 5 读 执行 6 读写 7 读写执行 2.文件创建删除\n pwd 查看当前用户主目录 mkdir 创建文件夹 make directory rmdir 删除文件夹 touch 创建空文件, 修改文件的访问时间戳 (访问时间改变)  touch 可以修改每个文件的最后访问时间   mv 移动文件 也可原文件改名 复制文件 cp cp 文件名 要复制到文件目录 / 复制后的文件名  3.cat\n 查看文件内容 concatenate cat + 文件名   cat 文件名 | less / more 分页查看 | 添加管道 cat + meminfo 内存信息 cat + cpuinfo cpu信息 head 查看文件开头 head 文件名 - n 查看开头多少行 tail 文件结尾 -n find -name *.html查找文件 在当前路径下查找文  4.grep\n grep 查找字符串 在一段字符串中 cat 文件名 | grep 查找内容 可加正则表达式 grep + 查找的内容 + 文件名 -n 出现在多少行 grep 查找内容 . / -n 当前路径下是所有文件下查找 grep 查找内容 \u0026gt; 文件名 \u0026amp; 将查找的内容输出重定向 后台执行 在在后面加 2\u0026gt; error.txt 将错误输出写入到error.txt中 (f覆盖模式) \u0026lt; 输入重定向 \u0026gt;\u0026gt; 文件名 追加模式  4.压缩归档文件 #  1、*.tar 用 tar –xvf 解压 2、*.gz 用 gzip -d或者gunzip 解压 3、*.tar.gz和*.tgz 用 tar –xzf 解压 4、*.bz2 用 bzip2 -d或者用bunzip2 解压 5、*.tar.bz2用tar –xjf 解压 6、*.Z 用 uncompress 解压 7、*.tar.Z 用tar –xZf 解压 8、*.rar 用 unrar e解压 9、*.zip 用 unzip 解压  压缩  gzip压缩文件 压缩比 gunzip +文件名解压缩文件 后缀是.gz 的文件 gz 解压缩 xz 将 后缀是 .xz格式的文件解压缩  -z  压缩 后面 加 - 8 指定压缩比  -d 解压缩     归档  tar -tf  查看归档文件的内容  **tar -cvf all.tar * **归档文件 将文件归档到all.tar 中 * 表示将所有文件归档到一个文件中 也可以写文件路径   tar -xvf 解归档 把一个文件 拆成多个文件  -v 列出过程 不加也可以 -f 指定文件名      5.链接(备份) #   硬链接 ln 更改之后所有的都改变了  没有拷贝文件 ,不消耗内存, 只是创建一个链接引用文件 给文件创建引用 ln 文件名 要备份到的位置和新的文件名 只要对象有引用 垃圾回收不会回收文件,文件不会被删除 ls -l 文件名查看文件的状态 链接的个数 链接为 1 rm会被删除 硬链接数表示文件被备份多少份 链接数是 1 时删除会被删除   软链接 ln -s  ln -s 文件位置 软链接名  给文件创建软链接 history 输入命令记录 !num 再次输入 HISTSIZE=2000设置保存的历史指令的条数 **echo **回声命令 可以创建文件并写入内容  echo ' print(\u0026quot;hello\u0026quot;)' \u0026gt; hello.py  创建文件 并写入内容 echo $a 取变量 a 的值 已设置 a = 2 echo $((a + b)) 计算 a + b 的值 echo $HISTSIZE查看历史记录条数      6.网络下载 #   wget + 网址 网络下载文件  wget -O +文件目录/ 文件名 + 地址 将文件放在哪个位置   top 查看CPU占 用率  "},{"id":14,"href":"/docs/13-tensorflow/01-tensorflow%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"01-tensorflow环境搭建","section":"13-tensorflow","content":"01-tensorflow环境搭建 #  tf 的主要依赖 #  1. Protocol Buffer #   一款谷歌开发的处理结构化数据的工具，处了Protocol Buffer 外还有 XML / JSON等结构化数据处理工具 其序列化后的数据是二进制流，需要先定义数据的格式（schema） 数据占用空间小，解析时间快 文件格式 .proto，每个 message 代表了一类结构化的数据  message user{ optional string name = 1; required int32 id = 2; repeated string email = 3;}如上：message 里定义了每一个属性的类型和名字。\nBazel #   谷歌开源的自动化构建工具，谷歌内部绝大部分的应用都是通过它来编译的  安装\npip install tensorflow\n建议使用 anaconda\nconda install tensorflow\n"},{"id":15,"href":"/docs/08-tornado/01-%E5%9F%BA%E7%A1%80%E5%BC%80%E5%A7%8Btornado/","title":"01-基础开始tornado","section":"08-Tornado","content":"Tornado简介 #  Tornado全称Tornado Web Server，是一个用Python语言写成的Web服务器兼Web应用框架，由FriendFeed公司在自己的网站FriendFeed中使用，被Facebook收购以后框架在2009年9月以开源软件形式开放给大众。\n特点：\n 作为Web框架，是一个轻量级的Web框架，类似于另一个Python web框架Web.py，其拥有异步非阻塞IO的处理方式。 作为Web服务器，Tornado有较为出色的抗负载能力，官方用nginx反向代理的方式部署Tornado和其它Python web应用框架进行对比，结果最大浏览量超过第二名近40%。  Tornado的特性 #  HTTP服务器 #  Tornado为了高效实现Comet/后端异步调用HTTP接口，是直接内嵌了HTTP服务器。\n前端无需加apache / lighttpd / nginx等也可以供浏览器访问；但它并没有完整实现HTTP 1.1的协议，所以官方文档是推荐用户在生产环境下在前端使用nginx，后端反向代理到多个Tornado实例。\nTornado本身是单线程的异步网络程序，它默认启动时，会根据CPU数量运行多个实例；充分利用CPU多核的优势。\n单线程异步 #  网站基本都会有数据库操作，而Tornado是单线程的，这意味着如果数据库查询返回过慢，整个服务器响应会被堵塞。\n数据库查询，实质上也是远程的网络调用；理想情况下，是将这些操作也封装成为异步的；但Tornado对此并没有提供任何支持。\n这是Tornado的设计，而不是缺陷。\n一个系统，要满足高流量；是必须解决数据库查询速度问题的！\n数据库若存在查询性能问题，整个系统无论如何优化，数据库都会是瓶颈，拖慢整个系统！\n异步并不能从本质上提到系统的性能；它仅仅是避免多余的网络响应等待，以及切换线程的CPU耗费。\n如果数据库查询响应太慢，需要解决的是数据库的性能问题；而不是调用数据库的前端Web应用。\n对于实时返回的数据查询，理想情况下需要确保所有数据都在内存中，数据库硬盘IO应该为0；这样的查询才能足够快；而如果数据库查询足够快，那么前端web应用也就无将数据查询封装为异步的必要。\n就算是使用协程，异步程序对于同步程序始终还是会提高复杂性；需要衡量的是处理这些额外复杂性是否值得。\n如果后端有查询实在是太慢，无法绕过，Tornaod的建议是将这些查询在后端封装独立封装成为HTTP接口，然后使用Tornado内置的异步HTTP客户端进行调用。\n开始 tornado 项目 #  # -*-coding: utf-8 -*-   import tornado.web import tornado.ioloop  # 引入 httpserver 模块 import tornado.httpserver   class IndexHandler(tornado.web.RequestHandler):   def get(self, *args, **kwargs):  self.write(\u0026#34;Hello Tornado!\u0026#34;)   if __name__ == \u0026#39;__main__\u0026#39;:  app = tornado.web.Application([  (r\u0026#39;/\u0026#39;, IndexHandler),  ])  # 直接使用 app 监听端口，最简单的写法，只能在单进程模式中使用  # app.listen(8000)   # 实例化一个 http 服务器对象, 匹配 app 中的路由  httpServer = tornado.httpserver.HTTPServer(app)  # 绑定端口，默认启动一个进程  # httpServer.listen(8000)   # 绑定端口  httpServer.bind(8000)  # 启动的进程的个数，默认开启一个进程，为 None 或者负数，也会开启对应的cpu核数个进程  httpServer.start(num_processes=5)  # 一般不使用 tornado 提供的方法启动多个进程，使用手动方法启动进程，绑定不同的端口  # 1.每个子进程都会复制一份 ioloop 的实列，如果创建子进程前修改了 ioloop 会影响到多有的子进程  # 2.所有的进程都是一个命令启动的，无法做到在不停止服务的情况下修改代码  # 3.所有进程共享一个端口，很难进行分别监控   # 开始监听, 监听 epoll 中的请求  tornado.ioloop.IOLoop.current().start() "},{"id":16,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/01-%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C-os%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C-%E6%97%B6%E9%97%B4%E6%97%A5%E6%9C%9F%E5%AF%B9%E8%B1%A1-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E8%BF%99%E6%AD%A3%E5%88%99/","title":"01-字符串操作-os文件操作-时间日期对象-面向对象-这正则","section":"01-python基础","content":"1. str 字符串操作 #  常见的字符串函数 zip  l = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39;]  b = zip(l[:-1], l[1:])  print(dict(b)) # 可以映射成字典,元组,列表  {\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;: \u0026#39;c\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;, \u0026#39;d\u0026#39;: \u0026#39;e\u0026#39;, \u0026#39;e\u0026#39;: \u0026#39;f\u0026#39;} str1.split()： \t过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串  str1.splitlines(): \t按照行(\u0026#39;\\r\u0026#39;, \u0026#39;\\r\\n\u0026#39;, \\n\u0026#39;)分隔，返回一个包含各行作为元素的列表，如果参数 keepends 为 False，不包含换行符，如果为 True，则保留换行符。  str1.join():  用于将序列中的元素以指定的字符连接生成一个新的字符串。  max():  返回给定参数的最大值，参数可以为序列  min():  返回字符串中最小的字母。  str1.replace(old, new[, max]):  把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。  str1.maketrans():  返回字符串转换后生成的新字符串。  str47.translate(table[, delete]): \tintable = \u0026#39;adsda \touttable = \u0026#39;12345 \ttrantab = str.marketrans(intable, outtable) \tst1 = \u0026#39;*********\u0026#39; \tresult = st1.translate(trantab[,delate]) \tresult 是翻译后的结果 delate 可 正则删除  返回翻译后的字符串,若给出了 delete 参数，则将原来的bytes中的属于delete的字符删除，剩下的字符要按照table中给出的映射来进行映射 。  str1.startswith(str, beg=0,end=len(string)):  方法用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。  str1.endswith(suffix[, start[, end]]):  方法用于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回True，否则返回False。可选参数\u0026#34;start\u0026#34;与\u0026#34;end\u0026#34;为检索字符串的开始与结束位置  s str1.encode():  指定的编码格式编码字符串  bytes.decode():  以指定的编码格式解码 bytes 对象。默认编码为 \u0026#39;utf-8\u0026#39;。  str1.isalpha():  方法检测字符串是否只由字母组成。  str1.isalnum():  检测字符串是否由字母和数字组成。  str1.isupper():  检测字符串中所有的字母是否都为大写。  str1.islower():  检测字符串是否由小写字母组成。  str1.istitle():  检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。  str1.isdigit():  检测字符串是否只由数字组成。  str1.isnumeric():  检测字符串是否只由数字组成。这种方法是只针对unicode对象  str1.isdecimal():  检查字符串是否只包含十进制字符。这种方法只存在于unicode对象  str1.isspace():  检测字符串是否只由空白字符组成  len():  返回对象（字符、列表、元组等）长度或项目个数。  lower():  转换字符串中所有大写字符为小写。  upper():  将字符串中的小写字母转为大写字母。  swapcase():  用于对字符串的大小写字母进行转换。  capitalize():  将字符串的第一个字母变成大写,其他字母变小写  title():  返回\u0026#34;标题化\u0026#34;的字符串,就是说所有单词都是以大写开始  center(width[, fillchar]): ?????  返回一个指定的宽度 width 居中的字符串，fillchar 为填充的字符，默认为空格。  ljust(width[, fillchar]):  返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串。  rjust(width[, fillchar]):  回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串。如果指定的长度小于字符串的长度则返回原字符串。  zfill(width):  返回指定长度的字符串，原字符串右对齐，前面填充0。  count():  统计字符串里某个字符出现的次数。可选参数为在字符串搜索的开始与结束位置  find():  方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果指定范围内如果包含指定索引值，返回的是索引值在字符串中的起始位置。如果不包含索引值，返回-1。  rfind():  返回字符串最后一次出现的位置，如果没有匹配项则返回-1。  index():  方法检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。  rindex(str, beg=0 end=len(string)):  返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数[beg:end]设置查找的区间。 strip():  用于移除字符串头尾指定的字符（默认为空格）  lstrip():  方法用于截掉字符串左边的空格或指定字符。 rstrip():  删除 string 字符串末尾的指定字符（默认为空格）. 2. OS模块 文件操作 #  1.获取当前操作系统 os.name 2.查看当前操作系统的详细信息 os.uname() 3.获取当前操作系统的环境变量 ** os.environ 返回为一个dict 4.获取指定的环境变量 os.environ.get(\u0026#39;path\u0026#39;) ** 5.获取当前目录 os.curdir 6.获取当前工作目录 os.getcwd() 7.在当前目录下创建新的目录 os.mkdir(\u0026#39;path\u0026#39;) 8.删除目录 os.rmdir() 9.删除文件 os.remove() 10.文件重命名 os.rename(old, new) 11.获取文件属性 os.stat(\u0026#39;path\u0026#39;) 12.路径拼接 os.path.join() 13.拆分文件扩展名 os.path.split() os.path.splitext() ************ 14.判断目录是否存在 os.path.exists() 15.判断是否是目录 os.path.isdir() 16.判断是否是文件 os.path.isfile() 17.获取文件的大小\tos.path.getsize() 18.获取当前文件目录所在的目录 os.path.dirname() 19.获取当前文件的文件名 os.path.basename() 文件打开 open() #  模式\t描述 r\t以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 rb\t以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。 r+\t打开一个文件用于读写。文件指针将会放在文件的开头。 rb+\t以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。 w\t打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb\t以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 w+\t打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 wb+\t以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 a\t打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 ab\t以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 a+\t打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 ab+\t以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 file() 对象方法 #  file.read([size]) size未指定则返回整个文件,如果文件大小\u0026gt;2倍内存则有问题.f.read()读到文件尾时返回\u0026#34;\u0026#34;(空字串)  file.readline() 返回一行  file.readlines([size]) 返回包含size行的列表,size 未指定则返回全部行  for line in f: print line #通过迭代器访问  f.write(\u0026#34;hello\\n\u0026#34;) #如果要写入字符串以外的数据,先将他转换为字符串.  f.tell() 返回一个整数,表示当前文件指针的位置(就是到文件头的比特数).  f.seek(偏移量,[起始位置]) 用来移动文件指针.  偏移量:单位:比特,可正可负 起始位置:0-文件头,默认值;1-当前位置;2-文件尾 f.close() 关闭文件 3.time datetime calendar #  time.time() 时间戳,从1970-1-1 0时开始计算时间 秒 time.gmtime() 时间戳转换为UTC时间 time.localtime() 获取本地时间 time.mktime() 将时间转化为时间戳函数 time.asctime() 将时间转化为用户可读的字符串格式 time.ctime() 将时间戳转化为用户可读的时间 time.strftime() 将时间字符串格式化输出给用户看 time.strptime() 将时间转化为元组时间的格式 datetime.datetime.now() datetime.datetime() .strftime() datetime.datetime.strptime(date, \u0026#39;%Y-%m-%d\u0026#39;) calendar.month() calendar.calendar() calendar.monthrange() calendar.monthcalendar() 格式化时间字符串 #  %y 两位数的年份表示（00-99） %Y 四位数的年份表示（000-9999） %m 月份（01-12） %d 月内中的一天（0-31） %H 24小时制小时数（0-23） %I 12小时制小时数（01-12） %M 分钟数（00=59） %S 秒（00-59） %a 本地简化星期名称 %A 本地完整星期名称 %b 本地简化的月份名称 %B 本地完整的月份名称 %c 本地相应的日期表示和时间表示 %j 年内的一天（001-366） %p 本地A.M.或P.M.的等价符 %U 一年中的星期数（00-53）星期天为星期的开始 %w 星期（0-6），星期天为星期的开始 %W 一年中的星期数（00-53）星期一为星期的开始 %x 本地相应的日期表示 %X 本地相应的时间表示 %Z 当前时区的名称 %% %号本身 4.面向对象 #  @property # 属性包装器 @ .setter # 修改属性 @classmethod # 类方法 @staticmethod # 抽象方法 MethodType # 动态添加  抽象方法 from abc import abstractmethod, ABCMeta \tmetaclass=ABCmeta # 默认的类参数  @abstractmethod # 定义抽象方法  super().__init__()  from enum import Enum # 枚举 class Color(Enum):  red = 1 运算符重载 #  在类中，对内置对象（例如，整数和列表）所能做的事，几乎都有相应的特殊名称的重载方法。下表列出其中一些最常用的重载方法。 方法 重载 调用 init 构造函数 对象建立：X = Class(args) del 析构函数 X对象收回 add 运算符+ 如果没有iadd,X+Y,X+=Y or 运算符\\|(位OR)\t如果没有ior,X\\|Y,X\\|=Y repr,str 打印、转换 print（X）、repr(X),str(X) call 函数调用 X(*args,**kargs) getattr 点号运算 X.undefined setattr 属性赋值语句 X.any = value delattr 属性删除 del X.any getattribute\t属性获取 X.any getitem 索引运算 X[key],X[i:j],没iter时的for循环和其他迭代器 setitem 索引赋值语句 X[key] = value,X[i:j] = sequence delitem 索引和分片删除 del X[key],del X[i:j] len 长度 len(X),如果没有bool,真值测试 bool 布尔测试 bool(X),真测试 lt,gt, 特定的比较 X \u0026lt; Y,X \u0026gt; Y le,ge, X\u0026lt;=Y,X \u0026gt;= Y eq,ne X == Y,X != Y radd 右侧加法 Other+X iadd 实地（增强的）加法 X += Y （or else add） iter,next 迭代环境 I = iter(X),next(I) contains 成员关系测试 item in X （任何可迭代的） index 整数值 hex(X),bin(X),oct(X),O[X],O[X:] enter,exit 环境管理器 with obj as var: get,set 描述符属性 X.attr,X.attr = value,del X.attr new 创建 在init之前创建对象 5.正则表达式 #  finditer() 迭代器 用 next() 方法进行迭代器操作 sub() 返回被替换后的字符串 subn() 返回一个元组, 第一个为被替换是字符串, 第二个是替换的次数  分组; \t除了简单的判断是否匹配外, 还能提取子串  用() 表示提取出的分组 \tstr2 = \u0026#39;01053247654\u0026#39;  m = re.match((r\u0026#39;(\\d{3})(\\d{8})\u0026#39;), str2)  m = re.match((r\u0026#39;(?P\u0026lt;name1\u0026gt;\\d{3})-(?P\u0026lt;name2\u0026gt;\\d{8})\u0026#39;), str2)   group(0) 原始字符串  group(1)  group(2)  m = m.groups()  print(m)   compile(pattern ,flags=0) pattern 正则表达式    正则常用字符 #  \\w匹配字母数字及下划线  \\W匹配非字母数字及下划线  \\s匹配任意空白字符，等价于 [\\t\\n\\r\\f].  \\S匹配任意非空字符  \\d匹配任意数字，等价于 [0-9]  \\D匹配任意非数字  \\A匹配字符串开始  \\Z匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串  \\z匹配字符串结束  \\G匹配最后匹配完成的位置  \\n匹配一个换行符  \\t匹配一个制表符  ^匹配字符串的开头  $匹配字符串的末尾。  .匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。  [...]用来表示一组字符,单独列出：[amk] 匹配 \u0026#39;a\u0026#39;，\u0026#39;m\u0026#39;或\u0026#39;k\u0026#39;  [^...]不在[]中的字符：abc 匹配除了a,b,c之外的字符。  *匹配0个或多个的表达式。  +匹配1个或多个的表达式。  ?匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式  {n}精确匹配n个前面表达式。  {n, m}匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式  a|b匹配a或b  ( )匹配括号内的表达式，也表示一个组 正则匹配模式 #  re.match() 开头开始匹配 一个 re.search() 整个查找 一个 re.findall() 全局查找,匹配所有 re.sub(\u0026#39;查找要替换的 表达式\u0026#39;, \u0026#39;替换的字符\u0026#39;, str) re.compile() compile()还可以传入修饰符，例如re.S等修饰符，这样在search()、findall()等方法中就不需要额外传了。所以compile()方法可以说是给正则表达式做了一层封装，以便于我们更好地复用。 常用的表达式 #  一、校验数字的表达式 数字：^[0-9]*$ n位的数字：^\\d{n}$ 至少n位的数字：^\\d{n,}$ m-n位的数字：^\\d{m,n}$ 零和非零开头的数字：^(0|[1-9][0-9]*)$ 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(\\.[0-9]{1,2})?$ 带1-2位小数的正数或负数：^(\\-)?\\d+(\\.\\d{1,2})$ 正数、负数、和小数：^(\\-|\\+)?\\d+(\\.\\d+)?$ 有两位小数的正实数：^[0-9]+(\\.[0-9]{2})?$ 有1~3位小数的正实数：^[0-9]+(\\.[0-9]{1,3})?$ 非零的正整数：^[1-9]\\d*$ 或 ^([1-9][0-9]*){1,3}$ 或 ^\\+?[1-9][0-9]*$ 非零的负整数：^\\-[1-9][]0-9\u0026#34;*$ 或 ^-[1-9]\\d*$ 非负整数：^\\d+$ 或 ^[1-9]\\d*|0$ 非正整数：^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$ 非负浮点数：^\\d+(\\.\\d+)?$ 或 ^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0$ 非正浮点数：^((-\\d+(\\.\\d+)?)|(0+(\\.0+)?))$ 或 ^(-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*))|0?\\.0+|0$ 正浮点数：^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*$ 或 ^(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*))$ 负浮点数：^-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*)$ 或 ^(-(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*)))$ 浮点数：^(-?\\d+)(\\.\\d+)?$ 或 ^-?([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0)$ 校验字符的表达式 汉字：^[\\u4e00-\\u9fa5]{0,}$ 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$ 长度为3-20的所有字符：^.{3,20}$ 由26个英文字母组成的字符串：^[A-Za-z]+$ 由26个大写英文字母组成的字符串：^[A-Z]+$ 由26个小写英文字母组成的字符串：^[a-z]+$ 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 由数字、26个英文字母或者下划线组成的字符串：^\\w+$ 或 ^\\w{3,20}$ 中文、英文、数字包括下划线：^[\\u4E00-\\u9FA5A-Za-z0-9_]+$ 中文、英文、数字但不包括下划线等符号：^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]{2,20}$ 可以输入含有^%\u0026amp;\u0026#39;,;=?$\\\u0026#34;等字符：[^%\u0026amp;\u0026#39;,;=?$\\x22]+ 禁止输入含有~的字符：[^~\\x22]+   三、特殊需求表达式 Email地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$ 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? InternetURL：[a-zA-z]+://[^\\s]* 或 ^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%\u0026amp;=]*)?$ 手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\d{8}$ 电话号码(\u0026#34;XXX-XXXXXXX\u0026#34;、\u0026#34;XXXX-XXXXXXXX\u0026#34;、\u0026#34;XXX-XXXXXXX\u0026#34;、\u0026#34;XXX-XXXXXXXX\u0026#34;、\u0026#34;XXXXXXX\u0026#34;和\u0026#34;XXXXXXXX)：^(\\(\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$ 国内电话号码(0511-4405222、021-87888822)：\\d{3}-\\d{8}|\\d{4}-\\d{7} 电话号码正则表达式（支持手机号码，3-4位区号，7-8位直播号码，1－4位分机号）: ((\\d{11})|^((\\d{7,8})|(\\d{4}|\\d{3})-(\\d{7,8})|(\\d{4}|\\d{3})-(\\d{7,8})-(\\d{4}|\\d{3}|\\d{2}|\\d{1})|(\\d{7,8})-(\\d{4}|\\d{3}|\\d{2}|\\d{1}))$) 身份证号(15位、18位数字)，最后一位是校验位，可能为数字或字符X：(^\\d{15}$)|(^\\d{18}$)|(^\\d{17}(\\d|X|x)$) 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\\w{5,17}$ 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ 日期格式：^\\d{4}-\\d{1,2}-\\d{1,2} 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$ 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 钱的输入格式： 有四种钱的表示形式我们可以接受:\u0026#34;10000.00\u0026#34; 和 \u0026#34;10,000.00\u0026#34;, 和没有 \u0026#34;分\u0026#34; 的 \u0026#34;10000\u0026#34; 和 \u0026#34;10,000\u0026#34;：^[1-9][0-9]*$ 这表示任意一个不以0开头的数字,但是,这也意味着一个字符\u0026#34;0\u0026#34;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧。下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 必须说明的是,小数点后面至少应该有1位数,所以\u0026#34;10.\u0026#34;是不通过的,但是 \u0026#34;10\u0026#34; 和 \u0026#34;10.2\u0026#34; 是通过的：^[0-9]+(.[0-9]{2})?$ 这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]{1,2})?$ 这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$ 1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$ 备注：这就是最终结果了,别忘了\u0026#34;+\u0026#34;可以用\u0026#34;*\u0026#34;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\\\.[x|X][m|M][l|L]$ 中文字符的正则表达式：[\\u4e00-\\u9fa5] 双字节字符：[^\\x00-\\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1)) 空白行的正则表达式：\\n\\s*\\r (可以用来删除空白行) HTML标记的正则表达式：\u0026lt;(\\S*?)[^\u0026gt;]*\u0026gt;.*?|\u0026lt;.*? /\u0026gt; ( 首尾空白字符的正则表达式：^\\s*|\\s*$或(^\\s*)|(\\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式) 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始) 中国邮政编码：[1-9]\\d{5}(?!\\d) (中国邮政编码为6位数字) IP地址：((?:(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d)\\\\.){3}(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d)) "},{"id":17,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/01-%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","title":"01-工厂模式","section":"11-Python设计模式","content":"01-工厂模式\n介绍 #  在工厂模式中，客户端可以请求一个对象，而无需知道这个对象来自哪里，也就是，使用那个类来生成这个对象，共仓背后的思想是简化对象的创建，与客户端自己基于类实例化直接创建对象相比，基于一个中心化函数来实现，更易于追踪创建了那些对象，通过将创建对象的代码和使用对象的代码解耦，工厂能够降低应用维护的复杂度。\n工厂通常由两种方式，一种是工厂方法，它是一个方法，对不同的输入参数返回不同的对象，第二种是抽象工厂，它是一组用于创建一系列相关事务的工厂方法\n1. 工厂方法 #  案例：Django框架工厂方法来创建表单字段，Django的forms模块支持不同类型的字段（CharField, EmailField）的创建和定制（max_length, required）。\n何时使用 #  如果因为应用创建对象的代码分布在多个不同的地方，而不是仅在一个函数/方法中，你发现没法跟踪这些对象，那么因该考虑使用工厂方法模式\n代码示例 https://github.com/lanms/Python_design_pattern/blob/master/01_factory_pattern/factory_method.py\n2. 抽象工厂 #  抽象工厂设计模式是抽象方法的一种泛化\n抽象工厂有一个有点，在使用工厂方法时从用户的视角通常是看不到的，那么就是抽象工厂能够通过改变激活的工厂方法动态的改变应用行为。\n何时使用 #  通常一开始使用的是工厂方法，因为它更加简单，如果后来发现应用需要许多工厂方法，那么将创建一系列对象的过程合并在一起，而最终引入抽象方法。\n代码示例https://github.com/lanms/Python_design_pattern/blob/master/01_factory_pattern/abstract_factory.py\n"},{"id":18,"href":"/docs/14-docker/02-docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"02-Docker常用命令","section":"14-docker","content":"常用命令\nservice docker start / stop / restart # 启动 停止 重启 docker images #　查看多有的镜像 docker ps # 查看已启动的容器列表 docker ps -a # 查看docker创建的所有容器 docker创建一个容器\ndocker run -it -v /docker_test:/yufei --name docker_name -i: 允许对容器内的（STDIN)进行交互 -t: 在新容器内指定一个伪终端或终端 -v: 挂载宿主机的目录， /docker_test是宿机目录，/yufei是当前docker容器的目录，宿机必须是绝对的 --name: 容器的名称，如果省略将会随机产生一个名字 docker启动、停止、重启某个容器\ndocker start container_name dcoker stop container_name dcokre restart container_name 查看指定容器的日志记录\ndocker logs -f container_name 删除某个容器\ndocker rm container_name 删除全部容器\ndocker rm $(docker ps -a -q) 删除镜像\ndocker rmi image_name dcoker rmi -f $(docker images) 指定端口映射启动镜像\ndocker run -d -p 91:80 nginx -d 表示后台运行 -P 随机映射端口 -p 指定端口有四种形式 \t- ip:hostPort:containerPort \t- ip::containerPort \t- hostPort：containerPort \t- containerPort 强行停止容器\ndocker kill 容器ID/容器名称 进入容器\n 某些场景下，可能需要进入运行终端容器尽享一些操作  docker exec [OPTIONS] CONTAINER COMMAND [ARG ...]  docker exec -it ofe2f388c80ad /bin/bash # 进入该容器并开启一个bash 暂停容器\ndocker pause CONTAINER 开启运行暂停的容器\ndocker unpause CONTAINER 查看容器或者镜像的详细信息\ndocker inspect [OPTIONS] NAME|ID [NAME|ID ...] docker inspect NAME|ID docker inspect --format \u0026#34;{{.State.Pid}}\u0026#34; Name|ID docker inspect --format \u0026#34;{{ .NetworkSetting.IPAddress }}\u0026#34; NAME|ID "},{"id":19,"href":"/docs/03-git/02-git%E8%BF%9B%E9%98%B6/","title":"02-Git进阶","section":"03-Git","content":"1.git push -u origin master #   由于远程仓库是空的,第一次推送master分支时, 加上 -u , git 不但会把本地的master分支内容推送到远程的新的master分支,还会把本地的master分支和远程的master分支关联起来, 在以后推送或者拉取时就可以简化命令  git checkout -b zhang # 创建分支并切换到分支 \tgit branch zhang \tgit checkout zhang git branch -d zhang # 删除分支 zhang git merge zhang # 合并分支 2.分支合并冲突 #  git log --graph #查看分支合并图 3.撤销缓存区的内容 #  git rm --cached \u0026lt;file\u0026gt;\n4.暂存分支任务 #  git branch # 当前在zhang分支工作 git stash # 将当前分支暂时\u0026#39;储藏起来\u0026#39;, 等完成别的分支任务之后对其进行恢复 git checkout master # 切换到master分支 git checkout -b bug-101 # 创建新的修复bug的分支 完成修复任务后 git add . git commit -m \u0026#34;bug修复\u0026#34; git checkout master git merge --no-ff -m \u0026#34;bug修复\u0026#34; bug-101 git checkout zhang git status # 查看工作区状态还是干净的 git stash list #查看暂时储藏起来的分支 git apply stash@{0} #恢复前面储藏的内容 git stash drop 也可以使用一个命令 \tgit stash pop # 恢复的同时也删除了原先储藏的内容 5.强行删除分支 #  git branch -D \u0026lt;name\u0026gt; 强行删除分支\n6.推送分支 #  git push origin \u0026lt;name\u0026gt; # 推送本地分支 7.标签 #  切换到分支,然后打标签 git checkout zhang git tag v1.0 git tag #查看标签  命令git tag \u0026lt;name\u0026gt;用于新建一个标签，默认为HEAD，也可以指定一个commit id； 创建带有说明的标签，用-a指定标签名，-m指定说明文字 git tag -a \u0026lt;tagname\u0026gt; -m \u0026quot;blablabla...\u0026quot;可以指定标签信息； git tag -s \u0026lt;tagname\u0026gt; -m \u0026quot;blablabla...\u0026quot;可以用PGP签名标签； 命令git tag可以查看所有标签。 命令git push origin \u0026lt;tagname\u0026gt;可以推送一个本地标签； 命令git push origin --tags可以推送全部未推送过的本地标签； 命令git tag -d \u0026lt;tagname\u0026gt;可以删除一个本地标签； 命令git push origin :refs/tags/\u0026lt;tagname\u0026gt;可以删除一个远程标签。  如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除： $ git tag -d v0.9 Deleted tag \u0026#39;v0.9\u0026#39; (was 6224937) 然后，从远程删除。删除命令也是push，但是格式如下： $ git push origin :refs/tags/v0.9 To git@github.com:michaelliao/learngit.git  - [deleted] v0.9 8.查看远程库的信息. #  git remote -v # 显示详细信息  删除本地已经连接的远程库的 链接  git remote rm origin   然后再次关联另外一个远程库  git remote add origin \u0026lt;链接\u0026gt;    9.关联多个远程库 #   我们先删除已关联的名为origin的远程库：  git remote rm origin  然后，先关联GitHub的远程库：  git remote add github git@github.com:michaelliao/learngit.git  注意，远程库的名称叫github，不叫origin了。 接着，再关联码云的远程库：  git remote add gitee git@gitee.com:liaoxuefeng/learngit.git  同样注意，远程库的名称叫gitee，不叫origin。 现在，我们用git remote -v查看远程库信息，可以看到两个远程库：  git remote -v gitee git@gitee.com:liaoxuefeng/learngit.git (fetch) gitee git@gitee.com:liaoxuefeng/learngit.git (push) github git@github.com:michaelliao/learngit.git (fetch) github git@github.com:michaelliao/learngit.git (push)  如果要推送到GitHub，使用命令：  git push github master  如果要推送到码云，使用命令：  git push gitee master 这样一来，我们的本地库就可以同时与多个远程库互相同步\n使用Git忽略某些特殊的文件 #  给Git指令设置别名 #   设置简短 的别名  git config --global alias.st status    搭建Git服务器 #  本文主要是通过廖雪峰的博客学习记的笔记,学习更多上请廖雪峰Git教程的博客, 也感谢博主的文章让我受益匪浅!!\n"},{"id":20,"href":"/docs/02-%E5%89%8D%E7%AB%AFhtml-js-css/02-javascript-jquary-ajax/","title":"02-Javascript-JQuary-Ajax","section":"02-前端HTML-js-css","content":"浏览器对象模型-BOM(Browser Object Model)\n文档对象模型-DOM(Document Object Model)\n语法规范 ECMScripts - 主要使用 ES 5.1 (最新是ES 8)\n1.Javascript常用的命令 #  示例代码可在这篇笔记中查找, 这里是整理过后的一些总结\n windonw  alter / promote / confirm location href / reload() / replace() history go() / forward() / back() setTimeout()/setInterval() clearTiameout()/clearInterval()   document  getElementById() / TagName() / ClassName() querySelector() / querySelectorAll() textContent (文本)/ innerHTML(文本+标签) / nodeValue(节点)   图片处理, 抠图  background: url(img/url.jpg) norepeat -95px -15px;位置  事件冒泡和事件捕获  事件冒泡: child \u0026ndash;\u0026gt; parent 从下往上传播 (IE) 事件捕获: parent \u0026ndash;\u0026gt; child 从上往下传播   阻止事件的传播  evt.stop.Propagation(), 事件到此为止, 不再继续传播   evt参数  evt参数表示的是时间对象, 绑定了和事件有关的所有信息, 如果事件回调函数中要用到事件相关的属性和方法, 最好就是指定evt参数 this 时间源, 谁调用函数谁就是事件源    J S 中的三元条件运算\nfunction getStyle(elem) { \treturn window.getComputedStyle ? window.getComputedStyle(elem) : elem.currentStyle } 2.JQuery框架 #   基本命令  在window.jQuery = function () {}绑定 var $ = window.jQuary; jQuary(\u0026#39;#id\u0026#39;) = $(\u0026#39;#id\u0026#39;) jQuery.noConflict(); //将 $ 函数不用 用 jQuery 代替 解决引入多个库的 $ 冲突, 将原来使用 $ 的地方换为 jQuery  $(\u0026#39;#id\u0026#39;) 选择elem 转化为 jqelem jqelem.fadeIn(1000) 淡入 jqelem.fadeOut(1000) 淡出 jqelem.on(\u0026#39;click\u0026#39;, function () {}) 绑定事件 jqelem.attr(\u0026#39;class/type/\u0026#39;, \u0026#39;设置值\u0026#39;); 设置 属性 jqelem.css(\u0026#39;\u0026#39;, \u0026#39;\u0026#39;) 设置 css style $(\u0026#39;#id\u0026#39;).one(\u0026#39;click\u0026#39;, function () {}) 只点击一次 执行函数 $(\u0026#39;#id\u0026#39;).each(function (){}) 对选中的div 的每一个执行操作 $(\u0026#34;#id\u0026#34;).text(\u0026#39;abc\u0026#39;) 将字符串作为 #id 标签的的内容写入  .html(\u0026#39;\u0026#39;) 加标签 $(\u0026#34;id\u0026#34;).val() 读取该标签里面的值   // 链式编程开火车式编程 可以对一个 elem 进行多种方法一次顺序操作 元素还是原来的这个元素   事件传播 ??????????????????????????????????? jQuary对象 \t不需要考虑浏览器兼容性问题 \tjQuary 的本质是一个数组 包含着所有的获得的元素 \t如果需要将jQuary 还原成原生的JS对象 - 下标运算可以得到 或 get(index) $(item) 1. $(function()) 绑定该函数是页面加载完成后进行的回调函数 2. $(selector) 传入的参数是一个选择器 通过选择器获得对应的元素,并将其处理成 3. $(elem) 传入的参数是一个原生 JS 对象 event.target / this \t将原生 JS 对象转变为 jQyary 对象 jQuary 有更多的属性和方法 4. $(tag) 传入的是标签 创建标签对应的元素 并处理成 jQuary 对象   查找元素  - 选择器  - * / element / #id / .class / selector1, selector2  - ancestor descendant / parent\u0026gt;child / previous+next / previous~siblings - 筛选器  - 基本筛选器：:not(selector) / :first / :last / :even / :odd / :eq(index) / :gt(index) / :lt(index) / :animated / :focus  - 内容筛选器：:contains(\u0026#39;…\u0026#39;) / :empty / :parent / :has(selector)  - 可见性筛选器：:hidden / :visible  - 子节点筛选器：:nth-child(expr) / :first-child / :last-child / :only-child  - 属性筛选器：[attribute] / [attribute=\u0026#39;value\u0026#39;] / [attribute!=\u0026#39;value\u0026#39;] / [attribute^=\u0026#39;value\u0026#39;] / [attribute$=\u0026#39;value\u0026#39;] / [attribute|=\u0026#39;value\u0026#39;] / [attribute~=\u0026#39;value\u0026#39;] - 表单：:input / :text / :password / :radio / :checkbox / :submit / :image / :reset / :button / :file / :selected / :enabled / :disabled / :checked  执行操作  - 内容操作  - 获取/修改内容：html() / text() / replaceWith() / remove()  - 获取/设置元素：before() / after() / prepend() / append() / remove() / clone() / unwrap() / detach() / empty() / add()  - 获取/修改属性：attr() / removeAttr() / addClass() / removeClass() / css()  - 获取/设置表单值：val() - 查找操作  - 查找方法：find() / parent() / children() / siblings() / next() / nextAll() / prev() / prevAll()  - 筛选器：filter() / not() / has() / is() / contains()  - 索引编号：eq() - 尺寸和位置  - 尺寸相关：height() / width() / innerHeight() / innerWidth() / outerWidth() / outerHeight()  - 位置相关：offset() / position() / scrollLeft() / scrollTop() - 特效和动画  - 基本动画：show() / hide() / toggle()  - 消失出现：fadeIn() / fadeOut() / fadeTo() / fadeToggle()  - 滑动效果：slideDown() / slideUp() / slideToggle()  - 自定义：delay() / stop() / animate() - 事件  - 文档加载：ready() / load()  - 用户交互：on() / off()   css() 和 attr() 区别\n 但css()是用来操纵元素style{}的，而attr()是用来操作元素固有的属性的，且attr()的权重比css()要大，它会覆盖css()的样式。  $(\u0026#34;#txt\u0026#34;).css(\u0026#34;display\u0026#34;,\u0026#34;none\u0026#34;) $(\u0026#34;#txt\u0026#34;).css({\u0026#34;display\u0026#34;:\u0026#34;none\u0026#34;,\u0026#34;width\u0026#34;:\u0026#34;5px\u0026#34;,....}) $(\u0026#34;#txt\u0026#34;).attr(\u0026#34;title\u0026#34;,\u0026#34;zz\u0026#34;)   3.Ajax异步IO技术 #    异步获取服务器数据\n ( 异步 -不阻塞 ) (同步 - 阻塞 排队等待)    服务器取得相应数据 (Json/XML) , 就可以对页面进行局部刷新,就可以在不中断用户体验的前提下刷新页面\n  瀑布式加载\n  JavaScript 发送HTTP请求默认只支持同源策略, 只能取自己网站的数据\n  如果要跨域取数据 是需要对方提供数据的服务器是支持的\n  如果对方支持模式 JSONP\n  服务器设置 Cross-Origin: * ; 支持跨域取数据\n    代码示例, 原生, 无JQuary\n\t\u0026lt;body\u0026gt; \t\u0026lt;div id=\u0026#34;mm\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \t\u0026lt;button id=\u0026#34;loadBtn\u0026#34;\u0026gt;加载\u0026lt;/button\u0026gt; \t\u0026lt;script src=\u0026#34;js/jquery1.12.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \t\u0026lt;script\u0026gt;\t\t//JavaScript 发送HTTP请求默认只支持同源策略 \t$(function() { \t$(\u0026#39;#loadBtn\u0026#39;).on(\u0026#39;click\u0026#39;, function() { \tvar url = \u0026#39;http://api.tianapi.com/meinv/?key=30cb00f0e0f6c2f605ba1ebca41c3282\u0026amp;num=2\u0026#39;; \t$.getJSON(url, function(obj) { \tfor(var i = 0; i \u0026lt; obj.newslist.length; i += 1) { \t// $ 就是 jQuary \t$(\u0026#39;#mm\u0026#39;).append( \t$(\u0026#39;\u0026lt;img\u0026gt;\u0026#39;).attr(\u0026#39;src\u0026#39;, obj.newslist[i].picUrl).attr(\u0026#39;width\u0026#39;, \u0026#39;300\u0026#39;) \t); \t}; \t}); \t}); \t}); \t\u0026lt;/script\u0026gt; \t\u0026lt;/body\u0026gt; jQuery-Ajax代码\n1. $.getJSON(url, function() {}) // 请求成功执行function函数  2. $.Ajax({  \u0026#39;url\u0026#39;:\u0026#39;\u0026#39;,  \u0026#39;type\u0026#39;: \u0026#39;\u0026#39; ,  \u0026#39;data\u0026#39;: {  \u0026#39;key\u0026#39;: \u0026#39;\u0026#39;,  \u0026#39;num\u0026#39;: \u0026#39;\u0026#39;  },  \u0026#39;dataType\u0026#39;: \u0026#39;json\u0026#39;, //默认为json 也可以使用 XML 其他格式  \u0026#39;success\u0026#39;: function(){} //请求成功 进行的函数  \u0026#39;error\u0026#39;: function(){} //失拜 执行的函数  }) Ajax 加载图片 瀑布式  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt;  \t\u0026lt;head\u0026gt; \t\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \t\u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; \t\u0026lt;/head\u0026gt;  \t\u0026lt;body\u0026gt; \t\u0026lt;div id=\u0026#34;mm\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \t\u0026lt;button id=\u0026#34;loadBtn\u0026#34;\u0026gt;加载\u0026lt;/button\u0026gt;  \t\u0026lt;script src=\u0026#34;js/jquery1.12.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \t\u0026lt;script\u0026gt; \t$(function() { \t$(\u0026#39;#loadBtn\u0026#39;).on(\u0026#39;click\u0026#39;, function() { \tvar url = \u0026#39;http://api.tianapi.com/meinv/?key=30cb00f0e0f6c2f605ba1ebca41c3282\u0026amp;num=2\u0026#39;; \t$.getJSON(url, function(obj) { // obj 通过url 是得到的 jQuery对象数组 \tfor(var i = 0; i \u0026lt; obj.newslist.length; i += 1) { \t$(\u0026#39;#mm\u0026#39;).append( \t$(\u0026#39;\u0026lt;img\u0026gt;\u0026#39;).attr(\u0026#39;src\u0026#39;, obj.newslist[i].picUrl).attr(\u0026#39;width\u0026#39;, \u0026#39;300\u0026#39;) \t); \t}; \t}); \t}); \t}); \t\u0026lt;/script\u0026gt; \t\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; #  "},{"id":21,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/02-jenkins%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%9701/","title":"02-jenkins配置指南01","section":"15-集成开发","content":"一、Windows环境中安装Jenkins #  在最简单的情况下，Jenkins 只需要两个步骤：\n1、下载最新的版本（一个 WAR 文件）。Jenkins官方网址: http://Jenkins-ci.org/\n2、命运行运行 java -jar jenkins.war　（默认情况下端口是8080，如果要使用其他端口启动，可以通过命令行”java –jar Jenkins.war \u0026ndash;httpPort=80”的方式修改）\n注意：Jenkins 需要运行 Java 5以及以上的版本。\n还有一种安装方式就是将下载的war包文件部署到 servlet 容器，然后启动容器，在浏览器的URL地址栏中输入类似http://localhost:8080/jenkins/这样的地址即可。下图是安装成功后的界面（使用的是Linux+Tomcat6+Java6环境）：\n二、Jenkins配置 #  在配置前的一些话：Jenkins的配置不可能全部都说到的，大部分配置是有英文说明的，点击输入框后面的问号就可以看见了。英文不会用翻译工具，多测试几次，你就懂了。\n2.1 系统管理 #  在已运行的Jenkins主页中，点击左侧的系统管理进入如下界面：\n2.1.1 提示信息 #  Ps：版本不同提示的消息有可能不同\n2.1.1.1 Utf-8编码 #  Your container doesn\u0026rsquo;t use UTF-8 to decode URLs. If you use non-ASCII characters as a job name etc, this will cause problems. See Containers and Tomcat i18n for more details.\nJenkins建议在tomcat中使用utf-8编码，配置tomcat下conf目录的server.xml文件\nPs：如果Job的控制台中文输出乱码，请将URIEncoding=”utf-8”更改为useBodyEncodingForURI=\u0026ldquo;true\u0026rdquo;\n2.1.1.2 新的版本 #  New version of Jenkins (1.518.JENKINS-14362-jzlib) is available for download (changelog).\n提示有新的版本可以下载了,喜欢更新的点击download去下载吧！\n2.1.1.3 安全设置 #  詹金斯允许网络上的任何人代表您启动进程。考虑至少启用身份验证来阻止滥用。点击Dismiss忽略该消息,点击Setup Security进入设置界面.详细设置请参考 Configure Global Security(安全设置) 章节\n2.1.2 系统设置 #  在已运行的Jenkins主页中，点击左侧的系统管理—\u0026gt;系统设置进入如下界面：\nps：jenkins的根目录，默认地在C:\\Documents and Settings\\AAA.hudson。\n2.1.2.1 JDK、Maven、Ant配置(图为Windows环境) #  配置一个JDK、Ant、Maven实例，请在每一节下面单击Add(新增) 按钮，这里将添加实例的名称和绝对地址。下图描述了这两个部分。\n点击“安装”，添加相应的设置，如下图：\nJDK别名：给你看的，随便你自己\nJAVA_HOME：这个是本机JDK的安装路径（错误的路径会有红字提示你的）\n自动安装：不推荐这个选项\n注：Ant、Maven的配置是一样的（JDK去oracle官网下载，Ant与Maven去apache官网下载）\nPs：每个文本框后面都有个问号，点击问号就会出现帮助信息\n2.1.2.2 邮件通知配置（默认） #  2.1.2.2.1 配置发件人地址 #  系统管理员邮件地址（System Admin e-mail address）：Jenkins邮件发送地址，切记，必须设置。\n2.1.2.2.2 配置邮件通知 #  设置：SMTP服务器，勾选\u0026quot;使用SMTP认证\u0026quot;，输入用户名与密码\nPs：小技巧：用户默认邮件后缀配置了后，以后你填写邮件地址只需要@之前的就行了\n2.1.2.3 Subversion配置 #  Subversion Workspace Version：Subversion 的版本号，选择你对应的版本号就行了\n2.1.3 Configure Global Security(安全设置) #  在已运行的Jenkins主页中，点击左侧的系统管理—\u0026gt;Configure Global Security进入如下界面：\n设置如上图，保存后系统管理中就出现管理用户的选项。页面右上角也会出现登录/注册的选项。\n此设置：只有登录用户可以做任何事\n2.1.4 管理用户设置 #  在右上角点击注册\n点击sign up按钮，提示你现在已经登录.返回首页.\n登录后和匿名账号看到的首页有几点不同，如下图红框所示：\n2.1.5 管理插件设置 #  建议先阅读Jenkins插件章节，在回来安装如下所示的插件。\n需求：这个插件将生成的构件（war或者ear）部署到主流的服务器上。\n插件名称：Deploy Plugin\n插件介绍：This plugin takes a war/ear file and deploys that to a running remote application server at the end of a build\n2.2 项目构建设置 #  2.2.1 构建自由风格的Job #  2.2.1.1 新建自由风格构建任务 #  在已运行的Jenkins主页中，点击左侧的新建Job进入如下界面：\n这时，需要为新的构建任务指定一个名称。（这里输入的任务名称为：Ant_test）这里有几种的任务类型可供选择，鉴于初步介绍，先选择构建一个自由风格的软件项目。对于其他的类型,经常使用的是拷贝已存在任务;这主要为了能在现有的任务基础上新建任务。点击OK按钮.\n需要注意的是： 1.Job名称千万不要用中文名称（不作死就不会死）。 2.创建Job名称时最好有个规划，因为我们最后会通过正则匹配自动将Job归类，比如我喜欢 “项目前缀_一些说明-Job类型”这种方式。\n2.2.1.2 构建任务配置 #  2.2.1.2.1 源码管理配置 #  演示是使用Subversion的链接，在Repository URL中输入你的项目链接，如果没有权限则会提示如下图：\n设置成功后，就直接从SVN此目录获取文件到本地。Ps:要先添加Credentials。添加的方法如下操作：\n点击Jenkins首页左侧Credentials，进入页面\n下一步：一般都是使用的用户名和密码登陆的\nPs：svn的用户名和密码设置了是没有办法在web界面修改的。如果要修改则先去Jenkins目录删除hudson.scm.SubversionSCM.xml文件\n2.2.1.2.2 构建触发器 #  在其他项目构建完成后才执行构建：指定的项目完成构建后，触发此项目的构建。\nPoll SCM ：这是CI 系统中常见的选项。当您选择此选项，您可以指定一个定时作业表达式来定义Jenkins每隔多久检查一下您源代码仓库的变化。如果发现变化，就执行一次构建。例如，表达式中填写0,15,30,45 * * * *将使Jenkins每隔15分钟就检查一次您源码仓库的变化。\nBuild periodically ：此选项仅仅通知Jenkins按指定的频率对项目进行构建，而不管SCM是否有变化。如果想在这个Job中运行一些测试用例的话，它就很有帮助。\n2.2.1.2.3 Ant构建配置 #  因为我的项目是用ant脚本实现的编译和打包，所以我选择的是Invoke Ant，Ant Version选择你Ant配置的那个名字，注意不要选择default喔，那个选择了没有用。\nPs：如果你的构建脚本build.xml不在workspace根目录、或者说你的构建脚本不叫build.xml。那么需要在高级里设置Build File选项的路径，指明你的脚本。注意：是相对路径\n2.2 监控 #  当任务一旦运行，您将会看到这个任务正在队列中的仪表板和当前工作主页上运行。这两种显示如下。\n一旦构建完成后，完成后的任务将会有三个地方进行显示。\n你可以在Jenkins的控制面板上看到它，如下图。\n在上面展示的截图中，您将注意到有两个图标描述当前作业的状态。S栏目代表着“最新构建状态”，W栏目代表着“构建稳定性”。Jenkins使用这两个概念来介绍一个作业的总体状况：\n构建状态:下图中分级符号概述了一个Job新近一次构建会产生的四种可能的状态：\nSuccessful:完成构建，且被认为是稳定的。\nUnstable:完成构建，但被认为不稳定。\nFailed:构建失败。\nDisabled:构建已禁用。\n构建稳定性: 当一个Job中构建已完成并生成了一个未发布的目标构件，如果您准备评估此次构建的稳定性，Jenkins会基于一些后处理器任务为构建发布一个稳健指数 (从0-100 )，这些任务一般以插件的方式实现。它们可能包括单元测试(JUnit)、覆盖率(Cobertura )和静态代码分析(FindBugs)。分数越高，表明构建越稳定。下图中分级符号概述了稳定性的评分范围。任何构建作业的状态(总分100)低于80分就是不稳定的。\n你也可以在当前Job主界面上看到它，如下图左下部分\n当前作业主页上还包含了一些有趣的条目。左侧栏的链接主要控制Job的配置、删除作业、构建作业。右边部分的链接指向最新的项目报告和构件。\n通过点击构建历史（Build History）中某个具体的构建链接，您就能跳转到Jenkins为这个构建实例而创建的构建主页上。如下图\n如果你想通过视图输出界面来监控当前任务的进展情况。你可以单击Console Output（控制台输出）。如果工作已完成，这将显示构建脚本产生的静态输出；如果作业仍然在运行中，Jenkins将不断刷新网页的内容，以便您可以看到它运行时的输出。如下图：\n#  三、Jenkins插件 #  从Jenkins现有的功能扩展或开发者们为Jenkins提供的新功能都可以称之为Jenkins插件。有些插件可以无缝添加到您的构建过程，而其它，诸如除CVS和Subversion的SCM插件则需要源代码控制系统的支持。\n3.1 Jenkins插件安装 #  Jenkins 插件管理器允许您安装新的插件，和更新您Jenkins服务器上的插件。管理者将连接到联机资料库，检索可用的和已更新的插件。如果您的Jenkins服务器 无法直接连接到外部资源，您可以从Jenkins网站上下载。\n在已运行的Jenkins主页中，点击左侧的系统管理—\u0026gt;管理插件进入如下界面：\n它包含四个标签：\n更新:清单中列示了Jenkins为某些插件搜索到了可用的更新。列出的每个插件可以被选择并应用更新。\n可选安装:清单中列示了可用于安装（而不是目前已安装的）的所有插件。列出的每个插件都可以被选择并安装。\n已安装:清单中列示了已经安装的插件。\n高级:允许您通过设定HTTP代理的方式使Jenkins与在线插件库建立连接。此外，还提供了一个上传设备，可以安装你在Jenkins以外已下载的那些插件。\n由上图可知，Jenkins缺省集成了maven2插件，并且一旦插件有新版本，会提示更新新版本插件。\n如果想安装新的插件，可以点击tab分页中的可选插件。如下图：\n从图可知，各种Jenkins插件根据之前所记述的类型进行分门别类。可勾选任意想安装的Jenkins插件，点击Install without restart按钮进行安装。安装后，所有插件以hpi作为后缀名放置在plugins文件夹下。如果是高级用户还可以自行开发插件方便具体项目使用。\n注意：安装完成后需要重启Jenkins部署的容器。这样才能使用新装的插件。\n3.2 Jenkins插件安装示例 #  Jenkins运行自动部署war包到servlet容器内，要实现这个功能必须安装一个插件。\n好了，到此Deploy Plugin插件安装完成！\n"},{"id":22,"href":"/docs/05-linux/02-linux%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%98%B2%E7%81%AB%E5%A2%99/","title":"02-Linux安装软件服务器,防火墙","section":"05-Linux","content":"在Linux系统下使用 npm yum rpm nginx Linux防火墙 firewall 去IOE运动\n注册软链接， 和添加系统环境变量 #  yum / rpm 压缩文件安装tar.gz / tar.xz -src 源代码构建安装 make \u0026amp;\u0026amp; make install - bin 注册环境变量安装 重启服务器会失效 解压后有 bin 文件有二进制程序可以跑 但是韩式要注册path环境变量将 bin 复制到path环境变量中 echo $PATH(查看环境变量) root: export PATH=$PATH:+bin的目录 增加 永久有效 查看 ~ 所有文件 隐藏文件.bash_profile文件 vim .bash_profile 在 PATH 里添加 bin文件目录 hell.sh shell 脚本格式文件 实现自动化操作 写入命令 更改为可执行格式 +x 然后执行 安装软件\nyum #   yum yellowdog upgrade modified 包管理工具  前身 rpm redhat package manager yum 服务器仓库   yum list insatlled | grep Nginx yum search Nginx 找网络有没有资源 yum install nginx yum update 更新 反向代理  rpm #   红帽子包管理工具 rpm -i 安装 +vh rpm -e 移除 + vh rpm -vh 查看安装过程 rpm -qa 查询所有 搜索软件包 -rpm -e 移除 xargs 参数化  rpm -qa | grep jdk | xargs rmp -e 将grep 搜索到的结果 xargs(作为参数用来) 进行后面的操作    服务开机自启\n systemctl enable mariadb 停止开机自启   systemctl disable mariadb 或者 删除符号链接    Linux系统防火墙firewall #   systemctl start firewalld/ iptables启动防火墙 firewall -cmd 配置防火墙 开端口--add-port=80/tcp -- permanent -zone=public 企业级防火墙 两层防火墙 DMZ -Demilitary zone  nginx HTTP服务器 #  1.介绍 #    Apache LAMP Linux Apache MySQL PHP 做网站黄金组合\n Apache HTTP Server（简称Apache）是Apache软件基金会的一个开放源码的网页服务器，可以在大多数计算机操作系统中运行，由于其多平台和安全性被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩展，将Perl/Python等解释器编译到服务器中。    Nginx LNMP LInux Apache MySQLO Python 现在最快组合\n  Nginx 是一个很强大的高性能Web和反向代理服务器，它具有很多非常优越的特性：\n在连接高并发的情况下，Nginx是Apache服务器不错的替代品：Nginx在美国是做虚拟主机生意的老板们经常选择的软件平台之一。能够支持高达 50,000 个并发连接数的响应，感谢Nginx为我们选择了 epoll and kqueue作为开发模型。\n    DNS 将域名翻译成IP地址\n 停机  nginx -s stop 停止    2. 阿里云防火墙处理 #    实例 -\u0026gt; 管理 -\u0026gt; 实例安全组 -\u0026gt; 内网入方向规则\n 安全组列表 -\u0026gt;配置规则 -\u0026gt; 入方向 -\u0026gt; 容许 -\u0026gt; HTTP(80)  授权对象 0.0.0.0      替换页面\n /usr/share/nginx/html  进入页面目录 404 /50x config文件 server 连接端口  cd /etc/nginx/  下面的 nginx.config 配置文件 页面路径 root ..      上传文件\n 先安装Xftp.exe 点击上传到/usr/share/nginx/html   苹果下: 打开终端 输入命令: sftp root@公网IP\n 连接成功  sftp\u0026gt; ls  列出目录 get + 文件 下载文件 put 上传 put + 文件名    去IOE运动 #  2008 阿里巴巴 去IOE运动 多台小型机器 组装可以构成性能好的服务器\nIBM 小型机\nOracle 数据库\n GFS/TFS/Tair  自制 的数据存储系统  EMC(HP) 存储设备\nJava Spring框架\n集群技术 分摊请求 负载均衡\n LVS + keepalice 将普通服务器改为负载均衡服务器  "},{"id":23,"href":"/docs/08-tornado/02-options%E5%8F%82%E6%95%B0%E8%8E%B7%E5%8F%96/","title":"02-options参数获取","section":"08-Tornado","content":"02-\noptions 参数获取 #  tornado.options 经行全局的参数定义，转换，存储\ntornado.options.define() # 参数 name 变量名,唯一性 default 设置选项变量的默认值 type 设置选项变量的类型,进行输入的值的转换， str int float 等 multiple 设置选项变量是否可以为多个值，默认为False help 选项变量的帮助体视信息   # 例如 tornado.options.define(name=\u0026#34;port\u0026#34;,default=8000,type=int) tornado.options.options 全局的options 对象，多有定义的选项变量都会成为其的属性 如 ： tornado.options.options.port\n命令行获取参数 #  tornado.options.parse_command_line() 获取命令行参数，转化为 tornado 的参数\n# -*-coding: utf-8 -*-   import tornado.web import tornado.ioloop  # 引入 httpserver 模块 import tornado.httpserver  import tornado.options   # 定义 options 的变量的方法，定义参数 tornado.options.define(\u0026#39;port\u0026#39;, default=8000)   class IndexHandler(tornado.web.RequestHandler):   def get(self, *args, **kwargs):  self.write(\u0026#34;Hello Tornado!\u0026#34;)   if __name__ == \u0026#39;__main__\u0026#39;:  # 将命令行参数转换为 tornado 的参数并保存到 tornado.options.options 中  app = tornado.web.Application([  (r\u0026#39;/\u0026#39;, IndexHandler),  ])  # 实例化一个 http 服务器对象, 匹配 app 中的路由  httpServer = tornado.httpserver.HTTPServer(app)  # 绑定端口，使用变量的值  httpServer.listen(tornado.options.options.port)  print(tornado.options.options)  # 开始监听, 监听 epoel 中的请求  tornado.ioloop.IOLoop.current().start() 命令行启动\n从配置文件导入参数 #  tornado.options.parse_config_file(path)\nconfig 文件中指定参数\n日志 #  使用parse_command_line() 或者 parse_config_file() 时，会默认开启日志，在终端输出日志信息\n关闭日志 #  在程序的第一行加入如下代码\ntornado.options.options.logging = None "},{"id":24,"href":"/docs/13-tensorflow/02-tf%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%92%8C%E6%A8%A1%E6%8B%9F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","title":"02-tf基础知识和模拟线性回归","section":"13-tensorflow","content":"TensorFlow #    Tensor（张量）， 意味着N维数组，Flow（流）意味着基于数据流图的计算，TensorFlow即为张量从图的一端流动到另一端\n  支持 CNN（卷积神经网络）、RNN（循环神经网络）和 LSTM（长短期记忆网络）算法，\n是目前在 Image,NLP最流行的深度学习神经网络模型\n  对比传统深度学习，为什么使用TensorFlow #   深度学习意味着建立具有很多层的大规模神经网络 除了输入 X，函数还使用一系列的参数，其中包括标量值、向量以及最昂贵的矩阵和高级张量 在训练网络之前，需要定义一个代价函数，常见的代价函数包括回归问题的方差以及分类时候的交叉熵 训练时，需要连续将多批新输入投入网络，对所有的参数求导后，代入代价函数，从而更新整个网络模型 这个过程中有两个主要问题：  较大的数字或者张量在一起相乘百万次的处理使整个模型代价非常大 手动求导耗时非常久    所以，TensorFlow 的对函数的自动求导和分布式计算，可以帮助我们节省很多时间。\nTensorFlow优点 #   基于Python，写的很快并且具有高可读性 在多GPU系统上运行更为顺畅 代码编译效率较高 社区发展非常迅速并且很活跃 能够生成显示网络拓扑结构和性能的可视化图  原理 #   TensorFlow是用数据流图（data flow graphs）技术来进行数值计算的 数据流图是描述有向图中数值计算过程 有向图中，节点通常代表数学运算，边表示节点之间的某种联系，它负责传输多为数据（Tensors） 节点可以被分配到多个计算设备上，可以异步合并地执行操作。因为是有向图，所以只有等到之前的节点们的计算状态完成后，当前节点才能执行操作  使用 #   使用（graph）来表示任务 在被称为会话（Session）的上下文（context）中执行图 使用 tensor 表示数据 通过变量（Variable） 维护状态 使用 feed 和 fetch 可以为任意操作（arbitray operation）赋值或者从中获取数据  实例：hello TensorFlow\n import tensorflow as tf  # 定义常量 hello = tf.constant(\u0026#34;Hello TensorFlow\u0026#34;) # 使用tf创建会话 sess = tf.Session() # 运行 print(sess.run(hello)) # 关闭会话 sess.close() TensorFlow 模拟进行线性回归 #   import numpy as np import tensorflow as tf import matplotlib.pyplot as plt  rng = np.random  # 参数设定 learning_rate = 0.01 training_ecochs = 1000 display_step = 50  # 生成训练数据 train_X = np.linspace(0,10, num=20) + np.random.randn(20) train_Y = np.linspace(1,4, num=20) + np.random.randn(20) n_samples = train_X.shape[0] # 查看数据的关系， 线性关系 plt.scatter(train_X, train_Y) plt.title(\u0026#34;Origin data\u0026#34;)  # 定义 tensorflow 参数，  # 输入 X = tf.placeholder(\u0026#34;float\u0026#34;) Y = tf.placeholder(\u0026#34;float\u0026#34;) # 定义变量参数，斜率和截距 W = tf.Variable(rng.randn(), name=\u0026#34;weight\u0026#34;) b = tf.Variable(rng.randn(), name=\u0026#34;bias\u0026#34;)  # 创建线性模型 y_pred = tf.add(tf.multiply(X, W), b)  # 创建TensorFlow均方误差 cost,以及梯度下降优化器 optimizer # 均方误差,平局误差， 比较真实数据和预测数据的差距， 以求和的方式来降低维度 cost = tf.reduce_sum(tf.pow(y_pred - Y, 2)) / n_samples  # 梯度下降，每次下降learning_rate,寻找最小的均方误差 optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)  # tensorflow 初始化 init = tf.global_variables_initializer() # 训练开始 with tf.Session() as sess:  sess.run(init)  w_list = []  b_list = []  # 训练所有数据, 1000次  for epoch in range(training_ecochs):  for (x, y) in zip(train_X, train_Y):  sess.run(optimizer, feed_dict={X:x, Y:y})   # 每执行 50 次显示结果  if (epoch + 1) % display_step == 0:  c = sess.run(cost, feed_dict={X: train_X, Y: train_Y})  w_ = sess.run(W)  b_ = sess.run(b)  w_list.append(w_)  b_list.append(b_)  print(\u0026#34;Epoch: %04d\u0026#34; % (epoch + 1), \u0026#34;cost={:.9f}\u0026#34;.format(c),  \u0026#34;W=\u0026#34;, w_, \u0026#34;b=\u0026#34;, b_)   print(\u0026#34;执行结束！\u0026#34;)  training_cost =sess.run(cost, feed_dict={X: train_X, Y:train_Y})  print(\u0026#34;结果： cost=\u0026#34;, training_cost, \u0026#34;W=\u0026#34;, sess.run(W), \u0026#34;b=\u0026#34;, sess.run(b), \u0026#39;\\n\u0026#39;)   # 可视化  plt.figure(figsize=(5,15))  plt.subplot(311)  plt.plot(train_X, train_Y, \u0026#39;ro\u0026#39;, label=\u0026#34;Origin data\u0026#34;)  plt.plot(train_X, sess.run(W)*train_X+sess.run(b), label=\u0026#34;Fittied line\u0026#34;)  plt.legend()  plt.title(\u0026#34;Fitted Linear\u0026#34;)   plt.subplot(312)  plt.plot(w_list)  plt.title(\u0026#34;W\u0026#34;)   plt.subplot(313)  plt.plot(b_list)  plt.title(\u0026#34;b\u0026#34;)  "},{"id":25,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/02-%E5%87%BD%E6%95%B0-reduce-map-nonloca/","title":"02-函数-reduce()-map()-nonloca","section":"01-python基础","content":"  介绍 #    主要讲述了一些函数的用法\n reduce() map() nonlocal  1. reduce() #  reduce 把一个函数作用在一个序列上, 这个函数必须接受两个参数, reduce 把结果和序列的写一个元素做累积计算 # 运用的是递归的思想 不同之处在于 它是将第一次调用函数的结果作为了第二次调用函数的第一个参数,  reduce(f, [x1, x2, x3, x4, x5]) = f(f(f( f(x1, x2), x3),x4), x5) 2. map() #  map() 得到的是一个 object 需要进行其他的实体化操作才能得需要的值 \u0026gt;\u0026gt;\u0026gt;def square(x) : # 计算平方数 ... return x ** 2 ... # 传入的是函数名 不带() \u0026gt;\u0026gt;\u0026gt; map(square, [1,2,3,4,5]) # 计算列表各个元素的平方 [1, 4, 9, 16, 25]  # 传入的时候一个匿名函数  \u0026gt;\u0026gt;\u0026gt; map(lambda x: x ** 2, [1, 2, 3, 4, 5]) # 使用 lambda 匿名函数 [1, 4, 9, 16, 25]  # 提供了两个列表，对相同位置的列表数据进行相加, map 会自动查找需要是参数 \u0026gt;\u0026gt;\u0026gt; map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10]) [3, 7, 11, 15, 19] 3. nonlocal #  nonlocal:  用来在函数或其他作用域中使用外层(非全局)变量  def scope_test():  def do_local():  spam = \u0026#34;local spam\u0026#34; #此函数定义了另外的一个spam字符串变量，并且生命周期只在此函数内。此处的spam和外层的spam是两个变量，如果写出spam = spam + “local spam” 会报错  def do_nonlocal():  nonlocal spam #使用外层的spam变量  spam = \u0026#34;nonlocal spam\u0026#34;  def do_global():  global spam  spam = \u0026#34;global spam\u0026#34; # 输出为nonlocal中的spam???  spam = \u0026#34;test spam\u0026#34;  do_local()  print(\u0026#34;After local assignmane:\u0026#34;, spam) # test spam  do_nonlocal()  print(\u0026#34;After nonlocal assignment:\u0026#34;,spam) #nonlocal spam  do_global()  print(\u0026#34;After global assignment:\u0026#34;,spam) # nonlocal spam  scope_test() print(\u0026#34;In global scope:\u0026#34;,spam)  ########################################2222 def make_counter():  count = 0  def counter():  nonlocal count  count += 1  return count  return counter  def make_counter_test():  mc = make_counter()  print(mc())  print(mc())  print(mc())  make_counter_test()  output: 1 2 3  #  集合:\t nolocal:  上一层函数中的变量引用申明 闭包:  延长了参数的生命周期 时期参数值变化\t def make_counter():  count = 0  def counter():  nonlocal count  count += 1  return count  return counter   mc = make_counter()  print(mc()) #1  print(mc()) #2  print(mc()) #3   config: (中文释义:配置,布局,显示配置信息)  assert:  只有满足其后面的条件程序才能向下执行  应用:  通常情况传递参数不会有误，但编写大量的参数检查影响编程效率，而且不需要检查参数的合法性。  排除非预期的结果。  _ str _  randrange(num):  在0 - num 范围内随机去值 相当于 randint(range(num))   enumerate():  将一个可以遍历的数据对象(列表,元组 , 字符串 ) 组合成一个索引序列 , 同时给出数据和下标 默认下标为0 开始  可设置start=num 规定其开始的下标  在写 for 循环是增加一个参数 i   \u0026gt;\u0026gt;\u0026gt;seq = [\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;]  \u0026gt;\u0026gt;\u0026gt;for i, element in enumerate(seq):  ... print(i, seq[i])  ...  0 one  1 two  2 three  \u0026gt;\u0026gt;\u0026gt;  \u0026gt;\u0026gt;\u0026gt;seasons = [\u0026#39;Spring\u0026#39;, \u0026#39;Summer\u0026#39;, \u0026#39;Fall\u0026#39;, \u0026#39;Winter\u0026#39;]  \u0026gt;\u0026gt;\u0026gt;list(enumerate(seasons))  [(0, \u0026#39;Spring\u0026#39;), (1, \u0026#39;Summer\u0026#39;), (2, \u0026#39;Fall\u0026#39;), (3, \u0026#39;Winter\u0026#39;)]  \u0026gt;\u0026gt;\u0026gt;list(enumerate(seasons, start=1)) # 小标从 1 开始  [(1, \u0026#39;Spring\u0026#39;), (2, \u0026#39;Summer\u0026#39;), (3, \u0026#39;Fall\u0026#39;), (4, \u0026#39;Winter\u0026#39;)] #  "},{"id":26,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/02-%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"02-建造者模式","section":"11-Python设计模式","content":"建造者模式对比工厂模式 #  建造者模式对比工厂模式两者之间的差别并不明确，主要的区别在于工厂模式以单个步骤创建对象，而建造者模式以多个步骤创建对象，并且几乎始终会使用一个指挥者。另外一个区别是，在工厂模式中会立即返回一个创建好的对象，而在建造模式下，仅在需要客户端代码显示是才会请求指挥者返回最终的对象，可类比Django对数据库的操作\n适用场景 #   想要创建一个复杂对象，对象由多个部分构成，且对象的创建要经过多个不同的步骤，这些步骤也许还需要遵从特定的顺序 要求一个对象能有不同的表现，并希望对象的构造与表现解耦 想要在某个时间点创建对象，但是在稍后的时间再做访问，延时生产  代码示例 https://github.com/lanms/Python_design_pattern/blob/master/02_builder_pattern/builder_pizza.py\n"},{"id":27,"href":"/docs/14-docker/03-docker-compose.yaml%E9%85%8D%E7%BD%AE/","title":"03-docker-compose","section":"14-docker","content":"docker compose 在 Docker 容器运用中具有很大的学习意义，docker compose 是一个整合发布应用的利器。而使用 docker compose 时，懂得如何编排 docker compose 配置文件是很重要的。\n一. 前言 #  关于 docker compose 技术可以查看官方文档 Docker Compose\n以下的内容是确立在已经下载好 Docker 以及 Docker Compose，可参看 Docker Compose 的官方安装教程 Install Docker Compose\n二. Docker Compose 配置文件的构建参数说明\n首先，官方提供了一个 yaml Docker Compose 配置文件的标准例子\nversion: \u0026ldquo;3\u0026rdquo; services:\nredis: image: redis:alpine ports: - \u0026ldquo;6379\u0026rdquo; networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure\ndb: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager]\nvote: image: dockersamples/examplevotingapp_vote:before ports: - 5000:80 networks: - frontend depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 restart_policy: condition: on-failure\nresult: image: dockersamples/examplevotingapp_result:before ports: - 5001:80 networks: - backend depends_on: - db deploy: replicas: 1 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure\nworker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 1 labels: [APP=VOTING] restart_policy: condition: on-failure delay: 10s max_attempts: 3 window: 120s placement: constraints: [node.role == manager]\nvisualizer: image: dockersamples/visualizer:stable ports: - \u0026ldquo;8080:8080\u0026rdquo; stop_grace_period: 1m30s volumes: - \u0026ldquo;/var/run/docker.sock:/var/run/docker.sock\u0026rdquo; deploy: placement: constraints: [node.role == manager]\nnetworks: frontend: backend:\nvolumes: db-data:\n此文件配置了多个服务，关于此配置文件的各个语句含义就需要弄懂配置选项的含义了\n文件配置 compose 文件是一个定义服务、 网络和卷的 YAML 文件 。Compose 文件的默认路径是 ./docker-compose.yml\n提示：可以是用 .yml 或 .yaml 作为文件扩展名\n服务定义包含应用于为该服务启动的每个容器的配置，就像传递命令行参数一样 docker container create。同样，网络和卷的定义类似于 docker network create 和 docker volume create。\n正如 docker container create 在 Dockerfile 指定选项，如 CMD、 EXPOSE、VOLUME、ENV，在默认情况下，你不需要再次指定它们docker-compose.yml。\n可以使用 Bash 类 ${VARIABLE} 语法在配置值中使用环境变量。\n配置选项 #  １.bulid 服务除了可以基于指定的镜像，还可以基于一份 Dockerfile，在使用 up 启动之时执行构建任务，这个构建标签就是 build，它可以指定 Dockerfile 所在文件夹的路径。Compose 将会利用它自动构建这个镜像，然后使用这个镜像启动服务容器\nbuild: /path/to/build/dir\n也可以是相对路径\nbuild: ./dir\n设定上下文根目录，然后以该目录为准指定 Dockerfile\nbuild: context: ../ dockerfile: path/of/Dockerfile\n例子\nversion: \u0026lsquo;3\u0026rsquo; services: webapp: build: ./dir\n如果 context 中有指定的路径，并且可以选定 Dockerfile 和 args。那么 arg 这个标签，就像 Dockerfile 中的 ARG 指令，它可以在构建过程中指定环境变量，但是在构建成功后取消，在 docker-compose.yml 文件中也支持这样的写法：\nversion: \u0026lsquo;3\u0026rsquo; services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1\n与 ENV 不同的是，ARG 可以为空值\nargs:\n buildno password  如果要指定 image 以及 build ，选项格式为\nbuild: ./dir image: webapp:tag\n这会在 ./dir 目录生成一个名为 webaapp 和标记为 tag 的镜像\nNote:当用(Version 3) Compose 文件在群集模式下部署堆栈时，该选项被忽略。因为 docker stack 命令只接受预先构建的镜像\ncontext context 选项可以是 Dockerfile 的文件路径，也可以是到链接到 git 仓库的 url  当提供的值是相对路径时，它被解析为相对于撰写文件的路径，此目录也是发送到 Docker 守护进程的 context\nbuild: context: ./dir\n３. dockerfile 使用此 dockerfile 文件来构建，必须指定构建路径\nbuild: context: . dockerfile: Dockerfile-alternate\n４. args 添加构建参数，这些参数是仅在构建过程中可访问的环境变量\n首先， 在Dockerfile中指定参数：\nARG buildno ARG password\nRUN echo \u0026ldquo;Build number: $buildno\u0026rdquo; RUN script-requiring-password.sh \u0026ldquo;$password\u0026rdquo;\n然后指定 build 下的参数,可以传递映射或列表\nbuild: context: . args: buildno: 1 password: secret\n或\nbuild: context: . args:\n- buildno=1 - password=secret  指定构建参数时可以省略该值，在这种情况下，构建时的值默认构成运行环境中的值\nargs:\n buildno password  Note： YAML 布尔值（true，false，yes，no，on，off）必须使用引号括起来，以为了能够正常被解析为字符串\n５. cache_from 编写缓存解析镜像列表\nbuild: context: . cache_from: - alpine:latest - corp/web_app:3.14\nlabels 使用 Docker标签 将元数据添加到生成的镜像中，可以使用数组或字典。  建议使用反向 DNS 标记来防止签名与其他软件所使用的签名冲突\nbuild: context: . labels: com.example.description: \u0026ldquo;Accounting webapp\u0026rdquo; com.example.department: \u0026ldquo;Finance\u0026rdquo; com.example.label-with-empty-value: \u0026quot;\u0026quot;\n或\nbuild: context: . labels:\n- \u0026quot;com.example.description=Accounting webapp\u0026quot; - \u0026quot;com.example.department=Finance\u0026quot; - \u0026quot;com.example.label-with-empty-value\u0026quot;  7.shm_size 设置容器 /dev/shm 分区的大小，值为表示字节的整数值或表示字符的字符串\nbuild: context: . shm_size: \u0026lsquo;2gb\u0026rsquo;\n或\nbuild: context: . shm_size: 10000000\ntarget 根据对应的 Dockerfile 构建指定 Stage  build: context: . target: prod\ncap_add、cap_drop 添加或删除容器功能，可查看 man 7 capabilities  cap_add:\n ALL  cap_drop:\n NET_ADMIN SYS_ADMIN  Note:当用(Version 3) Compose 文件在群集模式下部署堆栈时，该选项被忽略。因为 docker stack 命令只接受预先构建的镜像\ncommand 覆盖容器启动后默认执行的命令  command: bundle exec thin -p 3000\n该命令也可以是一个列表，方法类似于 dockerfile:\ncommand: [\u0026ldquo;bundle\u0026rdquo;, \u0026ldquo;exec\u0026rdquo;, \u0026ldquo;thin\u0026rdquo;, \u0026ldquo;-p\u0026rdquo;, \u0026ldquo;3000\u0026rdquo;]\nconfigs 使用服务 configs 配置为每个服务赋予相应的访问权限，支持两种不同的语法。  Note: 配置必须存在或在 configs 此堆栈文件的顶层中定义，否则堆栈部署失效\n1.SHORT 语法 SHORT 语法只能指定配置名称，这允许容器访问配置并将其安装在 /\u0026lt;config_name\u0026gt; 容器内，源名称和目标装入点都设为配置名称。\nversion: \u0026ldquo;3.3\u0026rdquo; services: redis: image: redis:latest deploy: replicas: 1 configs:\n - my_config - my_other_config  configs: my_config: file: ./my_config.txt my_other_config: external: true\n以上实例使用 SHORT 语法将 redis 服务访问授予 my_config 和 my_other_config ,并被 my_other_config 定义为外部资源，这意味着它已经在 Docker 中定义。可以通过 docker config create 命令或通过另一个堆栈部署。如果外部部署配置都不存在，则堆栈部署会失败并出现 config not found 错误。\nNote: config 定义仅在 3.3 版本或在更高版本的撰写文件格式中受支持，YAML 的布尔值（true, false, yes, no, on, off）必须要使用引号引起来（单引号、双引号均可），否则会当成字符串解析。\nLONG 语法 LONG 语法提供了创建服务配置的更加详细的信息  source:Docker 中存在的配置的名称 target:要在服务的任务中装载的文件的路径或名称。如果未指定则默认为 /uid 和 gid:在服务的任务容器中拥有安装的配置文件的数字 UID 或 GID。如果未指定，则默认为在Linux上。Windows不支持。 mode:在服务的任务容器中安装的文件的权限，以八进制表示法。例如，0444 代表文件可读的。默认是 0444。如果配置文件无法写入，是因为它们安装在临时文件系统中，所以如果设置了可写位，它将被忽略。可执行位可以设置。如果您不熟悉 UNIX 文件权限模式，Unix Permissions Calculator 下面示例在容器中将 my_config 名称设置为 redis_config，将模式设置为 0440（group-readable）并将用户和组设置为 103。该　｀redis　服务无法访问 my_other_config 配置。\nversion: \u0026ldquo;3.3\u0026rdquo; services: redis: image: redis:latest deploy: replicas: 1 configs:\n - source: my_config target: /redis_config uid: '103' gid: '103' mode: 0440  configs: my_config: file: ./my_config.txt my_other_config: external: true\n18 可以同时授予多个配置的服务相应的访问权限，也可以混合使用 LONG 和 SHORT 语法。定义配置并不意味着授予服务访问权限。\ncgroup_parent 可以为容器选择一个可选的父 cgroup  cgroup_parent: m-executor-abcd\n注意：当 使用（Version 3）Compose 文件在群集模式下部署堆栈时，忽略此选项\ncontainer_name 为自定义的容器指定一个名称，而不是使用默认的名称  container_name: my-web-container\n因为 docker 容器名称必须是唯一的，所以如果指定了一个自定义的名称，不能扩展一个服务超过 1 个容器\ncredential_spec 为托管服务账户配置凭据规范，此选项仅适用于 Windows 容器服务  在 credential_spec 上的配置列表格式为 file://或 registry://使用 file: 应该注意引用的文件必须存在于　CredentialSpecs,docker 数据目录的子目录中。在 Windows 上，该目录默认为 C:\\ProgramData\\Docker\\。以下示例从名为C:\\ProgramData\\Docker\\CredentialSpecs\\my-credential-spec.json 的文件加载凭证规范 ：\ncredential_spec: file: my-credential-spec.json 使用 registry: 将从守护进程主机上的 Windows 注册表中读取凭据规范。其注册表值必须位于：\nHKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Virtualization\\Containers\\CredentialSpecs 1 下面的示例通过 my-credential-spec 注册表中指定的值加载凭证规范：\ncredential_spec: registry: my-credential-spec\ndeploy 指定与部署和运行服务相关的配置  version: \u0026lsquo;3\u0026rsquo; services: redis: image: redis:alpine deploy: replicas: 6 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure\n这里有几个子选项\n endpoint_mode 指定连接到群组外部客户端服务发现方法  endpoint_mode:vip ：Docker 为该服务分配了一个虚拟 IP(VIP),作为客户端的 “前端“ 部位用于访问网络上的服务。 endpoint_mode: dnsrr : DNS轮询（DNSRR）服务发现不使用单个虚拟 IP。Docker为服务设置 DNS 条目，使得服务名称的 DNS 查询返回一个 IP 地址列表，并且客户端直接连接到其中的一个。如果想使用自己的负载平衡器，或者混合 Windows 和 Linux 应用程序，则 DNS 轮询调度（round-robin）功能就非常实用。 version: \u0026ldquo;3.3\u0026rdquo;\nservices: wordpress: image: wordpress ports: - 8080:80 networks: - overlay deploy: mode: replicated replicas: 2 endpoint_mode: vip\nmysql: image: mysql volumes: - db-data:/var/lib/mysql/data networks: - overlay deploy: mode: replicated replicas: 2 endpoint_mode: dnsrr\nvolumes: db-data:\nnetworks: overlay:\n相关信息：Swarm 模式 CLI 命令 、Configure 服务发现\n2.labels 指定服务的标签，这些标签仅在服务上设置。\nversion: \u0026ldquo;3\u0026rdquo; services: web: image: web deploy: labels: com.example.description: \u0026ldquo;This label will appear on the web service\u0026rdquo;\n通过将 deploy 外面的 labels 标签来设置容器上的 labels\nversion: \u0026ldquo;3\u0026rdquo; services: web: image: web labels: com.example.description: \u0026ldquo;This label will appear on all containers for the web service\u0026rdquo;\n3.mode global:每个集节点只有一个容器 replicated:指定容器数量（默认） version: \u0026lsquo;3\u0026rsquo; services: worker: image: dockersamples/examplevotingapp_worker deploy: mode: global\nplacement 指定 constraints 和 preferences  version: \u0026lsquo;3\u0026rsquo; services: db: image: postgres deploy: placement: constraints:\n - node.role == manager - engine.labels.operatingsystem == ubuntu 14.04 preferences: - spread: node.labels.zone  ５.replicas 如果服务是 replicated（默认)，需要指定运行的容器数量\nversion: \u0026lsquo;3\u0026rsquo; services: worker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 6\nresources 配置资源限制  version: \u0026lsquo;3\u0026rsquo; services: redis: image: redis:alpine deploy: resources: limits: cpus: \u0026lsquo;0.50\u0026rsquo; memory: 50M reservations: cpus: \u0026lsquo;0.25\u0026rsquo; memory: 20M\n此例子中，redis 服务限制使用不超过 50M 的内存和 0.50（50％）可用处理时间（CPU），并且 保留 20M 了内存和 0.25 CPU时间\nrestart_policy 配置容器的重新启动，代替 restart  condition:值可以为 none 、on-failure 以及 any(默认) delay: 尝试重启的等待时间，默认为 0 max_attempts:在放弃之前尝试重新启动容器次数（默认：从不放弃）。如果重新启动在配置中没有成功 window，则此尝试不计入配置max_attempts 值。例如，如果 max_attempts 值为 2，并且第一次尝试重新启动失败，则可能会尝试重新启动两次以上。 windows:在决定重新启动是否成功之前的等时间，指定为持续时间（默认值：立即决定）。 version: \u0026ldquo;3\u0026rdquo; services: redis: image: redis:alpine deploy: restart_policy: condition: on-failure delay: 5s max_attempts: 3 window: 120s\nupdate_config 配置更新服务，用于无缝更新应用（rolling update)  parallelism：一次性更新的容器数量 delay：更新一组容器之间的等待时间。 failure_action：如果更新失败，可以执行的的是 continue、rollback 或 pause （默认） monitor：每次任务更新后监视失败的时间(ns|us|ms|s|m|h)（默认为0） max_failure_ratio：在更新期间能接受的失败率 order：更新次序设置，top-first（旧的任务在开始新任务之前停止）、start-first（新的任务首先启动，并且正在运行的任务短暂重叠）（默认 stop-first） version: \u0026lsquo;3.4\u0026rsquo; services: vote: image: dockersamples/examplevotingapp_vote:before depends_on:\n - redis deploy: replicas: 2 update_config: parallelism: 2 delay: 10s order: stop-first  不支持 Docker stack desploy 的几个子选项 build、cgroup_parent、container_name、devices、tmpfs、external_links、inks、network_mode、restart、security_opt、stop_signal、sysctls、userns_mode\ndevices 设置映射列表，与 Docker 客户端的 \u0026ndash;device 参数类似 :  devices:\n \u0026ldquo;/dev/ttyUSB0:/dev/ttyUSB0\u0026rdquo; 1 2  depends_on 此选项解决了启动顺序的问题  在使用 Compose 时，最大的好处就是少打启动命令，但是一般项目容器启动的顺序是有要求的，如果直接从上到下启动容器，必然会因为容器依赖问题而启动失败。例如在没启动数据库容器的时候启动了应用容器，这时候应用容器会因为找不到数据库而退出，为了避免这种情况我们需要加入一个标签，就是 depends_on，这个标签解决了容器的依赖、启动先后的问题。\n指定服务之间的依赖关系，有两种效果\ndocker-compose up 以依赖顺序启动服务，下面例子中 redis 和 db 服务在 web 启动前启动 docker-compose up SERVICE 自动包含 SERVICE 的依赖性，下面例子中，例如下面容器会先启动 redis 和 db 两个服务，最后才启动 web 服务： version: \u0026lsquo;3\u0026rsquo; services: web: build: . depends_on:\n - db - redis redis: image: redis db: image: postgres  注意的是，默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系\ndns 自定义 DNS 服务器，与 \u0026ndash;dns 具有一样的用途，可以是单个值或列表  dns: 8.8.8.8 dns:\n 8.8.8.8 9.9.9.9 1 2 3 4  dns_search 自定义 DNS 搜索域，可以是单个值或列表  dns_search: example.com dns_search:\n dc1.example.com dc2.example.com  tmpfs 挂载临时文件目录到容器内部，与 run 的参数一样效果，可以是单个值或列表  tmpfs: /run tmpfs:\n /run /tmp  entrypoint 在 Dockerfile 中有一个指令叫做 ENTRYPOINT 指令，用于指定接入点。在 docker-compose.yml 中可以定义接入点，覆盖 Dockerfile 中的定义：  entrypoint: /code/entrypoint.sh 1 entrypoint 也可以是一个列表，方法类似于 dockerfile\nentrypoint: - php - -d - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so - -d - memory_limit=-1 - vendor/bin/phpunit\nenv_file 从文件中添加环境变量。可以是单个值或是列表 如果已经用 docker-compose -f FILE 指定了 Compose 文件，那么 env_file 路径值为相对于该文件所在的目录  但 environment 环境中的设置的变量会会覆盖这些值，无论这些值未定义还是为 None\nenv_file: .env 1 或者根据 docker-compose.yml 设置多个：\nenv_file:\n ./common.env ./apps/web.env /opt/secrets.env  环境配置文件 env_file 中的声明每行都是以 VAR=VAL 格式，其中以 # 开头的被解析为注释而被忽略\n注意环境变量配置列表的顺序*,例如下面例子\ndocker_compose.yml\nservices: some-service: env_file:\n - a.env - b.env  a.env 文件\na.env\nVAR=1 1 2 b.env文件\n对于在文件a.env 中指定的相同变量但在文件 b.env 中分配了不同的值，如果 b.env 像下面列在 a.env 之后，则刚在 a.env 设置的值被 b.env 相同变量的值覆盖，此时 $VAR 值为 hello。此外，这里所说的环境变量是对宿主机的 Compose 而言的，如果在配置文件中有 build 操作，这些变量并不会进入构建过程中，如果要在构建中使用变量还是首选 arg 标签\nenvironment 添加环境变量，可以使用数组或字典。与上面的 env_file 选项完全不同，反而和 arg 有几分类似，这个标签的作用是设置镜像变量，它可以保存变量到镜像里面，也就是说启动的容器也会包含这些变量设置，这是与 arg 最大的不同。 一般 arg 标签的变量仅用在构建过程中。而 environment 和 Dockerfile 中的 ENV 指令一样会把变量一直保存在镜像、容器中，类似 docker run -e 的效果  environment: RACK_ENV: development SHOW: \u0026rsquo;true' SESSION_SECRET:\n或\nenvironment:\n RACK_ENV=development SHOW=true SESSION_SECRET  expose 暴露端口，但不映射到宿主机，只被连接的服务访问。这个标签与 Dockerfile 中的 EXPOSE 指令一样，用于指定暴露的端口，但是只是作为一种参考，实际上 docker-compose.yml 的端口映射还得 ports 这样的标签  expose:\n \u0026ldquo;3000\u0026rdquo; \u0026ldquo;8000\u0026rdquo; 1 2 3  external_links 链接到 docker-compose.yml 外部的容器，甚至 并非 Compose 项目文件管理的容器。参数格式跟 links 类似  在使用Docker过程中，会有许多单独使用 docker run 启动的容器的情况，为了使 Compose 能够连接这些不在docker-compose.yml 配置文件中定义的容器，那么就需要一个特殊的标签，就是 external_links，它可以让Compose 项目里面的容器连接到那些项目配置外部的容器（前提是外部容器中必须至少有一个容器是连接到与项目内的服务的同一个网络里面）。\n格式如下\nexternal_links:\n redis_1 project_db_1:mysql project_db_1:postgresql  extra_hosts 添加主机名的标签，就是往 /etc/hosts 文件中添加一些记录，与 Docker 客户端 中的 \u0026ndash;add-host 类似：  extra_hosts:\n \u0026ldquo;somehost:162.242.195.82\u0026rdquo; \u0026ldquo;otherhost:50.31.209.229\u0026rdquo;  具有 IP 地址和主机名的条目在 /etc/hosts 内部容器中创建。启动之后查看容器内部 hosts ，例如：\n162.242.195.82 somehost 50.31.209.229 otherhost 1 2 26.healthcheck 用于检查测试服务使用的容器是否正常\nhealthcheck: test: [\u0026ldquo;CMD\u0026rdquo;, \u0026ldquo;curl\u0026rdquo;, \u0026ldquo;-f\u0026rdquo;, \u0026ldquo;http://localhost\u0026rdquo;] interval: 1m30s timeout: 10s retries: 3 start_period: 40s\ninterval，timeout 以及 start_period 都定为持续时间\ntest 必须是字符串或列表，如果它是一个列表，第一项必须是 NONE，CMD 或 CMD-SHELL ；如果它是一个字符串，则相当于指定CMD-SHELL 后跟该字符串。\nHit the local web app\ntest: [\u0026ldquo;CMD\u0026rdquo;, \u0026ldquo;curl\u0026rdquo;, \u0026ldquo;-f\u0026rdquo;, \u0026ldquo;http://localhost\u0026rdquo;]\nAs above, but wrapped in /bin/sh. Both forms below are equivalent.\ntest: [\u0026ldquo;CMD-SHELL\u0026rdquo;, \u0026ldquo;curl -f http://localhost || exit 1\u0026rdquo;] test: curl -f https://localhost || exit 1\n如果需要禁用镜像的所有检查项目，可以使用 disable:true,相当于 test:[\u0026ldquo;NONE\u0026rdquo;]\nhealthcheck: disable: true\nimage 从指定的镜像中启动容器，可以是存储仓库、标签以及镜像 ID  image: redis image: ubuntu:14.04 image: tutum/influxdb image: example-registry.com:4000/postgresql image: a4bc65fd\n如果镜像不存在，Compose 会自动拉去镜像\n isolation Linux 上仅仅支持 default 值\n  labels 使用 Docker 标签将元数据添加到容器，可以使用数组或字典。与 Dockerfile 中的 LABELS 类似：\n  labels: com.example.description: \u0026ldquo;Accounting webapp\u0026rdquo; com.example.department: \u0026ldquo;Finance\u0026rdquo; com.example.label-with-empty-value: \u0026quot;\u0026quot;\nlabels:\n \u0026ldquo;com.example.description=Accounting webapp\u0026rdquo; \u0026ldquo;com.example.department=Finance\u0026rdquo; \u0026ldquo;com.example.label-with-empty-value\u0026rdquo;  30.links 链接到其它服务的中的容器，可以指定服务名称也可以指定链接别名（SERVICE：ALIAS)，与 Docker 客户端的 \u0026ndash;link 有一样效果，会连接到其它服务中的容器\nweb: links:\n db db:database redis  使用的别名将会自动在服务容器中的 /etc/hosts 里创建。例如：\n172.12.2.186 db 172.12.2.186 database 172.12.2.187 redis\n相应的环境变量也将被创建\nlogging 配置日志服务  logging: driver: syslog options: syslog-address: \u0026ldquo;tcp://192.168.0.42:123\u0026rdquo;\n该 driver值是指定服务器的日志记录驱动程序，默认值为 json-file,与 \u0026ndash;log-diver 选项一样\ndriver: \u0026ldquo;json-file\u0026rdquo; driver: \u0026ldquo;syslog\u0026rdquo; driver: \u0026ldquo;none\u0026rdquo;\n注意：只有驱动程序 json-file 和 journald 驱动程序可以直接从 docker-compose up 和 docker-compose logs 获取日志。使用任何其他方式不会显示任何日志。\n对于可选值，可以使用 options 指定日志记录中的日志记录选项\ndriver: \u0026ldquo;syslog\u0026rdquo; options: syslog-address: \u0026ldquo;tcp://192.168.0.42:123\u0026rdquo;\n默认驱动程序 json-file 具有限制存储日志量的选项，所以，使用键值对来获得最大存储大小以及最小存储数量\noptions: max-size: \u0026ldquo;200k\u0026rdquo; max-file: \u0026ldquo;10\u0026rdquo;\n上面实例将存储日志文件，直到它们达到max-size:200kB，存储的单个日志文件的数量由该 max-file 值指定。随着日志增长超出最大限制，旧日志文件将被删除以存储新日志\ndocker-compose.yml 限制日志存储的示例\nservices: some-service: image: some-service logging: driver: \u0026ldquo;json-file\u0026rdquo; options: max-size: \u0026ldquo;200k\u0026rdquo; max-file: \u0026ldquo;10\u0026rdquo;\nnetwork_mode 网络模式，用法类似于 Docke 客户端的 \u0026ndash;net 选项，格式为：service:[service name]  network_mode: \u0026ldquo;bridge\u0026rdquo; network_mode: \u0026ldquo;host\u0026rdquo; network_mode: \u0026ldquo;none\u0026rdquo; network_mode: \u0026ldquo;service:[service name]\u0026rdquo; network_mode: \u0026ldquo;container:[container name/id]\u0026rdquo;\n可以指定使用服务或者容器的网络\nnetworks 加入指定网络  services: some-service: networks: - some-network - other-network\naliases 同一网络上的其他容器可以使用服务器名称或别名来连接到其他服务的容器  services: some-service: networks: some-network: aliases:\n - alias1 - alias3 other-network: aliases: - alias2  下面实例中，提供 web 、worker以及db 服务，伴随着两个网络 new 和 legacy 。\nversion: \u0026lsquo;2\u0026rsquo;\nservices: web: build: ./web networks: - new\nworker: build: ./worker networks: - legacy\ndb: image: mysql networks: new: aliases: - database legacy: aliases: - mysql\nnetworks: new: legacy:\n相同的服务可以在不同的网络有不同的别名\nipv4_address、ipv6_address 为服务的容器指定一个静态 IP 地址  version: \u0026lsquo;2.1\u0026rsquo;\nservices: app: image: busybox command: ifconfig networks: app_net: ipv4_address: 172.16.238.10 ipv6_address: 2001:3984:3989::10\nnetworks: app_net: driver: bridge enable_ipv6: true ipam: driver: default\n   config:     subnet: 172.16.238.0/24   -   subnet: 2001:3984:3989::/64     PID pid: \u0026ldquo;host\u0026rdquo; 1 将 PID 模式设置为主机 PID 模式，可以打开容器与主机操作系统之间的共享 PID 地址空间。使用此标志启动的容器可以访问和操作宿主机的其他容器，反之亦然。\n  ports 映射端口\n  SHORT 语法 可以使用 HOST:CONTAINER 的方式指定端口，也可以指定容器端口（选择临时主机端口），宿主机会随机映射端口\n  ports:\n \u0026ldquo;3000\u0026rdquo; \u0026ldquo;3000-3005\u0026rdquo; \u0026ldquo;8000:8000\u0026rdquo; \u0026ldquo;9090-9091:8080-8081\u0026rdquo; \u0026ldquo;49100:22\u0026rdquo; \u0026ldquo;127.0.0.1:8001:8001\u0026rdquo; \u0026ldquo;127.0.0.1:5000-5010:5000-5010\u0026rdquo; \u0026ldquo;6060:6060/udp\u0026rdquo;  注意：当使用 HOST:CONTAINER 格式来映射端口时，如果使用的容器端口小于 60 可能会得到错误得结果，因为YAML 将会解析 xx:yy 这种数字格式为 60 进制，所以建议采用字符串格式。\nLONG 语法 LONG 语法支持 SHORT 语法不支持的附加字段  target：容器内的端口 published：公开的端口 protocol： 端口协议（tcp 或 udp） mode：通过host 用在每个节点还是哪个发布的主机端口或使用 ingress 用于集群模式端口进行平衡负载， ports:\n target: 80 published: 8080 protocol: tcp mode: host   secrets 通过 secrets为每个服务授予相应的访问权限\n  SHORT 语法 version: \u0026ldquo;3.1\u0026rdquo; services: redis: image: redis:latest deploy: replicas: 1 secrets:\n my_secret my_other_secret secrets: my_secret: file: ./my_secret.txt my_other_secret: external: true    2.. LONG 语法 LONG 语法可以添加其他选项\nsource：secret 名称 target：在服务任务容器中需要装载在 /run/secrets/ 中的文件名称，如果 source 未定义，那么默认为此值 uid\u0026amp;gid：在服务的任务容器中拥有该文件的 UID 或 GID 。如果未指定，两者都默认为 0。 mode：以八进制表示法将文件装载到服务的任务容器中 /run/secrets/ 的权限。例如，0444 代表可读。 version: \u0026ldquo;3.1\u0026rdquo; services: redis: image: redis:latest deploy: replicas: 1 secrets: - source: my_secret target: redis_secret uid: \u0026lsquo;103\u0026rsquo; gid: \u0026lsquo;103\u0026rsquo; mode: 0440 secrets: my_secret: file: ./my_secret.txt my_other_secret: external: true\nsecurity_opt 为每个容器覆盖默认的标签。简单说来就是管理全部服务的标签，比如设置全部服务的 user 标签值为 USER  security_opt:\n label:user:USER label:role:ROLE  stop_grace_period 在发送 SIGKILL 之前指定 stop_signal ，如果试图停止容器（如果它没有处理 SIGTERM（或指定的任何停止信号）），则需要等待的时间  stop_grace_period: 1s stop_grace_period: 1m30s\n默认情况下，stop 在发送SIGKILL之前等待10秒钟容器退出\nstop_signal 设置另一个信号来停止容器。在默认情况下使用的 SIGTERM 来停止容器。设置另一个信号可以使用 stop_signal 标签：  stop_signal: SIGUSR1\nsysctls 在容器中设置的内核参数，可以为数组或字典  sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0\nsysctls:\n net.core.somaxconn=1024 net.ipv4.tcp_syncookies=0  ulimits 覆盖容器的默认限制，可以单一地将限制值设为一个整数，也可以将soft/hard 限制指定为映射  ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000\nuserns_mode userns_mode: \u0026ldquo;host\u0026rdquo; 1 volumes 挂载一个目录或者一个已存在的数据卷容器，可以直接使用 HOST:CONTAINER 这样的格式，或者使用 HOST:CONTAINER:ro 这样的格式，后者对于容器来说，数据卷是只读的，这样可以有效保护宿主机的文件系统  version: \u0026ldquo;3.2\u0026rdquo; services: web: image: nginx:alpine volumes: - type: volume source: mydata target: /data volume: nocopy: true - type: bind source: ./static target: /opt/app/static\ndb: image: postgres:latest volumes: - \u0026ldquo;/var/run/postgres/postgres.sock:/var/run/postgres/postgres.sock\u0026rdquo; - \u0026ldquo;dbdata:/var/lib/postgresql/data\u0026rdquo;\nvolumes: mydata: dbdata:\nCompose 的数据卷指定路径可以是相对路径，使用 . 或者 .. 来指定相对目录。\n数据卷的格式可以是下面多种形式：\nvolumes:\n只是指定一个路径，Docker 会自动在创建一个数据卷（这个路径是容器内部的）。\n /var/lib/mysql  使用绝对路径挂载数据卷\n /opt/data:/var/lib/mysql  以 Compose 配置文件为中心的相对路径作为数据卷挂载到容器。\n ./cache:/tmp/cache  使用用户的相对路径（~/ 表示的目录是 /home/\u0026lt;用户目录\u0026gt;/ 或者 /root/）。\n ~/configs:/etc/configs/:ro  已经存在的命名的数据卷。\n datavolume:/var/lib/mysql  如果你不使用宿主机的路径，可以指定一个 volume_driver\nvolume_driver: mydriver 1 2\n SHORT 语法 可以选择在主机（HOST:CONTAINER）或访问模式（HOST:CONTAINER:ro）上指定路径。  可以在主机上挂载相对路径，该路径相对于正在使用的 Compose 配置文件的目录进行扩展。相对路径应始终以 . 或 .. 开头\nvolumes:\nJust specify a path and let the Engine create a volume\n /var/lib/mysql  Specify an absolute path mapping\n /opt/data:/var/lib/mysql  Path on the host, relative to the Compose file\n ./cache:/tmp/cache  User-relative path\n ~/configs:/etc/configs/:ro  Named volume\n datavolume:/var/lib/mysql  LONG 语法 LONG 语法有些附加字段  type：安装类型，可以为 volume、bind 或 tmpfs source：安装源，主机上用于绑定安装的路径或定义在顶级 volumes密钥中卷的名称 ,不适用于 tmpfs 类型安装。 target：卷安装在容器中的路径 read_only：标志将卷设置为只读 bind：配置额外的绑定选项 propagation：用于绑定的传播模式 volume：配置额外的音量选项 nocopy：创建卷时禁止从容器复制数据的标志 tmpfs：配置额外的 tmpfs 选项 size：tmpfs 的大小，以字节为单位 version: \u0026ldquo;3.2\u0026rdquo; services: web: image: nginx:alpine ports: - \u0026ldquo;80:80\u0026rdquo; volumes: - type: volume source: mydata target: /data volume: nocopy: true - type: bind source: ./static target: /opt/app/static\nnetworks: webnet:\nvolumes: mydata:\nvolumes_from 从其它容器或者服务挂载数据卷，可选的参数是 :ro 或 :rw，前者表示容器只读，后者表示容器对数据卷是可读可写的（默认情况为可读可写的）。  volumes_from:\n service_name service_name:ro container:container_name container:container_name:rw  用于服务、群集以及堆栈文件的卷 在使用服务，群集和 docker-stack.yml 文件时，请记住支持服务的任务（容器）可以部署在群集中的任何节点上，并且每次更新服务时都可能是不同的节点。  在缺少指定源的命名卷的情况下，Docker 为支持服务的每个任务创建一个匿名卷。关联的容器被移除后，匿名卷不会保留。\n如果希望数据持久存在，请使用可识别多主机的命名卷和卷驱动程序，以便可以从任何节点访问数据。或者，对该服务设置约束，以便将其任务部署在具有该卷的节点上。\n下面一个例子，Docker Labs 中 votingapp 示例的 docker-stack.yml文件中定义了一个称为 db 的服务。它被配置为一个命名卷来保存群体上的数据， 并且仅限于在节点上运行。下面是来自该文件的部分内容：db postgres manager\nversion: \u0026ldquo;3\u0026rdquo; services: db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager]\nrestart 默认值为 no ，即在任何情况下都不会重新启动容器；当值为 always 时，容器总是重新启动；当值为 on-failure 时，当出现 on-failure 报错容器退出时，容器重新启动。  restart: \u0026ldquo;no\u0026rdquo; restart: always restart: on-failure restart: unless-stopped\n 其他选项 #    关于标签：cpu_shares、cpu_quota、 cpuse、domainname、hostname、 ipc、 mac_address、privileged、 read_only、 shm_size、stdin_open、tty、 user、 working_dir\n上面这些都是一个单值的标签，类似于使用 docker run 的效果\ncpu_shares: 73 cpu_quota: 50000 cpuset: 0,1\nuser: postgresql working_dir: /code\ndomainname: foo.com hostname: foo ipc: host mac_address: 02:42:ac:11:65:43\nprivileged: true\nread_only: true shm_size: 64M stdin_open: true tty: true\n持续时间  某些配置选项如 check 的子选项interval以及timeout 的设置格式\n2.5s 10s 1m30s 2h32m 5h34m56s\n支持的单位有 us、ms、s、m 以及 h\n 指定字节值 #    某些选项如 bulid 的子选项 shm_size\n2b 1024kb 2048k 300m 1gb\n支持的单位是 b，k，m 以及 g，或 kb， mb 和 gb。目前不支持十进制值\n extends #    这个标签可以扩展另一个服务，扩展内容可以是来自在当前文件，也可以是来自其他文件，相同服务的情况下，后来者会有选择地覆盖原有配置\nextends: file: common.yml service: webapp\n用户可以在任何地方使用这个标签，只要标签内容包含 file 和 service 两个值就可以了。file 的值可以是相对或者绝对路径，如果不指定 file 的值，那么 Compose 会读取当前 YML 文件的信息。\n"},{"id":28,"href":"/docs/03-git/03-git%E5%9B%A2%E9%98%9F%E5%BC%80%E5%8F%91/","title":"03-Git团队开发","section":"03-Git","content":"03-Git团队开发\n git clone 创建环境 当前分支 master 切换到自己的分支 ​  测试环境1 自己的分支 15#环境\n测试环境2 test 分支 16#环境\n测试环境3 对外测试 test分支 83# 环境\n线上环境1 分支 master\n线上环境2 # 正式环境 共享数据库\ngit pull origin v3.0 本地获取 v3.0\n微服务\ndocker\n镜像 .iso 操作系统的文件（备份），里面有需要的环境\n容器：操作系统\ndockerfile : 启动的配置文件， 指定是哪个镜像，里面程序需要的环境\n"},{"id":29,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/03-jenkins%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%9702/","title":"03-jenkins配置指南02","section":"15-集成开发","content":"操作环境：Windows\n一、环境准备\n1 安装JDK\n本文采用jdk-8u111-windows-x64.exe；\n2 配置tomcat\n本文采用tomcat8，无需安装，配置JAVA_HOME及JRE_HOME环境变量即可；\n3 安装maven\n本文采用maven3.3.9，无需安装；\n4 安装Jenkins\n下载地址https://jenkins.io/download/，仅下载war包，如下图：\n将下载好的jenkins.war放进tomcat/webapps目录下。\n二、相关配置\n1 登入http://localhost:8080/jenkins，进入Jenkins初始化页面，第一次启动时间可能有点长，耐心等待。进入成功后会看到如下画面，按提示路径打开密码文件，输入密码：\n解锁后又是一长段时间等待，此后可能出现如下图所示界面：\n表示无法下载Jenkins插件，可能是因为防火墙导致，而Jenkins插件的安装非常重要，建议翻墙。如无法翻墙，则选择Skip Plugin Installations跳过插件安装。进入以下页面，设置登陆用户：\n2 设置成功后即进入Jenkins主界面：\n点击左上侧系统管理，进入Jenkins基本系统设置(主要是以下三块):\n3 先进入“管理插件”模块安装必需的插件，以下是建议安装列表：\n将本文附件中的插件放入Jenkins插件存放目录即可，如本文插件存放目录为：C:\\Users\\Administrator.jenkins\\plugins（可点击系统管理–\u0026gt;系统设置,在最上方查看，如下图）；\n4 配置系统设置\n添加编码全局属性：\n增加系统管理员邮件地址：\n其他的可用默认配置，保存后退出。\n5 添加全局配置Global ToolConfiguration\n配置JDK，不采用自动安装：\n配置maven，不采用自动安装：\n以上即为需要设置的系统配置。\n三、系统部署\n系统设置完成后开始添加任务，任务类型选择自由风格：\n创建完成后可在主页看到如下画面：\n在”All” tab下能看到新建的任务，点击该任务，进入该任务的配置页面：\n设置项目备注及构建规则：\n配置项目轮询的源码位置(@HEAD表示构建最新的代码)并配置代码访问密码：\n配置构建触发器，如下图配置为每天晚上9：30开始构建（Cron表达式）：\n增加Invoke top-level Maven targets构建步骤，插件目标为编译、发现编译Bug、部署，另外还可以配置构建时忽略测试用例：\n增加构建后操作步骤：Publish FindBugs analysis results，用于查看FindBugs插件的代码分析报告，该模块可采用默认配置：\n增加构建后操作步骤：Deploy war/ear to a container，用于将构建后生成的war包部署至tomcat服务器，下图中Contextpath用于配置项目访问路径，如填/RMS_Server则表示项目的根访问目录为：http://localhost:8080/RMS_Server，Deploy on failure用于配置当前构建失败时是否仍然部署至tomcat，默认不选：\n以上即为本项目的所有配置，完成后应用（或保存）并退出。\n配置完成后即可开始构建，左侧可查看bugs分析信息及构建历史：\n点击某个构建记录，如上图中的#31，即可查看构建日志、SVN代码提交日志及bugs分析结果：\n四、编码问题\nFindBugs分析报告中查看某些代码文件时可能出现中文乱码情况，如下图：\n这是tomcat的编码问题导致的，可在系统管理中查看tomcat的相关编码情况：\n主要关注的是file.encoding属性及sun.jnu.encoding属性，二者需要设置为UTF-8以兼容中文：\n这可通过在tomcat配置文件/bin/catalina.bat文件中添加set “JAVA_OPTS=-Dfile.encoding=UTF-8-Dsun.jnu.encoding=UTF-8”命令实现，如下图：\n配置完成后重启tomcat，可看到编码已经更改：\n"},{"id":30,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/03-stringio/","title":"03-stringIO","section":"01-python基础","content":" from io import StringIO   s = StringIO() s.write(\u0026#39;www.baidu.com\\n\u0026#39;) s.write(\u0026#39;abc\\n\u0026#39;) s.write(\u0026#39;zhang\u0026#39;)   o = s.getvalue() print(o)   s.seek(0) # 指定开始读取的位置 while True:  strBuf = s.readline()  if not strBuf:  break  print(strBuf, end=\u0026#39;\u0026#39;)  s.close()   # 另外还有 readline() readlines() 等方法可以读取 "},{"id":31,"href":"/docs/05-linux/03-vim%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8/","title":"03-vim文本编辑器","section":"05-Linux","content":"vim 文本编辑器 基本操作笔记\n1.启动和退出\n vim + 文件名 打开或创建文件 :wq 末行模式  w 保存 q 退出 q! 强行退出  wq 保存退出    2.命令模式和编辑模式\n i / a 进入编辑模式 Esc退出编辑模式 进入命令模式 : 末行模式 set nu 出现行号syntax on 开启语法高亮 (当时有效)  vim .vimrc 文件修改设置 (永久有效)  set nu syntax off ts=4      3.定标操作\n G  去末尾 gg 回到开始 行号 + gg 光标移到某行  4.文本操作\n 复制代码 yy + 数字 多少行 粘贴 p dd 删除 + 数字 删除行  d$ 删除光标处到行位 删除单词 光标在第一个单词 dw   Ctrl   e 后一行 y前一行 f 前一页 b后一页    5.查找和替换\n / 搜索的内容 回车 n 下一处 N 上一处 正则查找  可以加正则表达式 /\\w+ 需要转义 量词要加反斜杠   替换  末行模式 :1,10s/替换前的元素/替换后的元素/替换模式 ()  s 替换  :1, 10s 第1行到第10行替换 , 1, $s第一行到最后一行 替换模式 g global 全局替换  i ignore 忽略大小写      高级技巧\n 映射快捷键 进入 末行模式 编辑快捷键 inoremap pymain if __name__ == '__main__':  i 编辑模式用的快捷键 nore不要递归 map映射 录制宏 参考菜鸟教程  "},{"id":32,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/03-%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/","title":"03-原型模式","section":"11-Python设计模式","content":"介绍 #  通过对传入的对象做深拷贝， 并且通过内部的更改对象属性的方法来使原始传入的对象的副本进行加工，最终在原始对象的原型的基础上得到新的对象\n原型模式用于创建对象的完全副本，确切的说，创建一个对象的副本可以指代以下两件事\n 当创建一个浅副本时，副本依赖引用 当创建一个深副本时，副本复制所有的东西  第一种情况，我们关注提升应用性能和优化内存使用，在对象之间引入数据共享，单需要小心的修改数据，因为所有的改变对所有的副本都是可见的。\n第二种情况中，我们希望能够对一个副本进行更改而不会影响其他对象。\n代码示例https://github.com/lanms/Python_design_pattern/blob/master/03_prototype_pattern/prototype.py\n"},{"id":33,"href":"/docs/13-tensorflow/03-%E5%9F%BA%E7%A1%80%E6%8C%87%E4%BB%A4/","title":"03-基础指令","section":"13-tensorflow","content":"constant # 定义常量 a = tf.constant([1.0, 2.0], name=\u0026#34;a\u0026#34;) 关于张量 #  在 TensorFlow中，所有的数据都是通过张量的形式来表示。但是张量在 TensorFlow 中实现并不是直接采用数组的形式，它是对 TF 中运算结果的引用。在张量中并没有真正的保存数据，它保存的是如何得到数据的计算过程。\n一个张量中主要保存了 name shape type 的三种属性\n前向传播算法 #  "},{"id":34,"href":"/docs/08-tornado/03-%E8%AF%B7%E6%B1%82%E6%A0%B8%E5%93%8D%E5%BA%9401/","title":"03-请求核响应01","section":"08-Tornado","content":"03-请求核响应01\n"},{"id":35,"href":"/docs/03-git/04-git%E5%88%AB%E5%90%8Dalias/","title":"04-Git别名alias","section":"03-Git","content":"给Git设置alias别名 #  修改git的config文件，只是针对当前git仓库进行修改\n [alias]  st = status  ck = checkout  cl = clone  br = branch  mg = merge  cm = commit  cmd = commit --amend  df = diff  dft = difftool  mt = mergetool  last = log -1 HEAD  cf = config  line = log --oneline  latest = for-each-ref --sort=-committerdate --format=\u0026#39;%(committerdate:short) %(refname:short) [%(committername)]\u0026#39;  lg = log --pretty=format:\\\u0026#34;%C(yellow)%h %C(blue)%ad %C(red)%d %C(reset)%s %C(green)[%cn]\\\u0026#34; --decorate --date=short  graph = log --pretty=format:\\\u0026#34;%C(yellow)%h %C(red)%d %C(reset)%s %C(green)[%an] %C(blue)%ad\\\u0026#34; --topo-order --graph --date=short  type = cat-file -t  dump = cat-file -p "},{"id":36,"href":"/docs/05-linux/04-redis%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"04-redis安装配置","section":"05-Linux","content":"非关系型数据库,redias安装,配置redias\nredias 数据库 非关系型数据库\n1.下载 #   Linux 下载到的是源代码 yum install  2.构建安装 #  2.1 下载\n 进入解压后的目录 有目录Makfile 目录 构建 make 安装 make install (make \u0026amp;\u0026amp; make install)  2.2 改配置文件 redias.config\n 进入redias文件夹 复制 redias.config 更改 61行 bind:  原来绑定的是本机 改为的阿里云内网地址(末行模式 !ifconfig 查看inet)172.2(内网地址)   84行 为端口 默认设置是 6379, 可自己更改 :/require (搜索)  480行 去注释 改pass 密码: *****  ** 2.3 启动**\n redis-server myredis.config \u0026gt; myredis.log \u0026amp;  2.4 连接\n redis-cli -h 172.24.(内网地址) -p 6379(端口号) 进入后输入auth + 密码  退出  将后台移到前台 ctrl + c 保存数据退出 fg %1 移动到前台 bg %1 移动到后台启动    "},{"id":37,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/04-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-tcp-udp-bs64/","title":"04-网络编程-TCP-UDP-BS64","section":"01-python基础","content":"1. 网络介绍 #   多台独立自主的计算机互联的总称叫计算机网络 实现信息互联与资源共享 网络接口 \u0026ndash;\u0026gt; 网络 \u0026ndash;\u0026gt; 传输 \u0026ndash;\u0026gt; 应用 Inernet 因特网 基于TCP/IP Model 的网络 ​  1. 1 TCP 可靠传输协议 #    传输控制协议 Transfer Control Protocol\n 可靠通信(数据不会穿丢也不会传错) 流量控制 自动调节发送数据的速度 拥塞控制 网络拥堵时会降低发送速率    可靠通讯的实现:\n 如何保证数据不会传输错误 握手机制 + 在数据中添加冗余校验对发送的数据 进行校验    流量控制:\n 滑动窗口机制 逐步增加发送的数据大小    拥塞控制:\n 减小滑动窗口 减小发送速率    1.2 UDP #   User Datagram Protocol 用户数据宝协议  数据可能会丢失某部分内容 只要不影响使用 列如视屏 不会影响用户的使用    2. 应用实例 网络扒图片 #   通过天行数据提供的数据接口  import os import requests, json   def get_file(path):  \u0026#34;\u0026#34;\u0026#34; 在url中查找图片 :param path: :return: 查找结果 \u0026#34;\u0026#34;\u0026#34;  resp = requests.get(path)  url_dict = json.loads(resp.text, encoding=\u0026#39;utf-8\u0026#39;)  i = 0  for new_dict in url_dict[\u0026#39;newslist\u0026#39;]:  url = new_dict[\u0026#39;picUrl\u0026#39;]  resp_new = requests.get(url)  print(resp_new.content)  i += 1  with open (\u0026#39;%d.jpg\u0026#39; % i, \u0026#39;wb\u0026#39;) as f:  f.write(resp_new.content)  print(i)  print(\u0026#39;下载完成\u0026#39;)   def rm_picture(path):  \u0026#34;\u0026#34;\u0026#34; 删除jpg格式文件 :param path: 删除的文件夹 \u0026#34;\u0026#34;\u0026#34;  list_file = os.listdir(path)  for file in list_file:  if file[file.rindex(\u0026#39;.\u0026#39;) + 1:] == \u0026#39;jpg\u0026#39;:  os.remove(file)  print(\u0026#39;图片删除完毕\u0026#39;)   path_file = \u0026#39;../day18\u0026#39; path_url = \u0026#39;http://api.tianapi.com/meinv/?key=\u0026#39; def main():  # get_file(path_url)  rm_picture(path_file)   if __name__ == \u0026#39;__main__\u0026#39;:  main() 3. 网络编程 服务器 客户端 #  3 .1 套接字编程 socket() #   服务器与客户端 代码实现实例  ******** 服务器 #### 套接字编程 socket() from socket import socket   def servey():  ser_temp = socket()  ser_temp.bind((\u0026#39;10.7.152.105\u0026#39;, 7779))  ser_temp.listen()  while True:  client, addr = ser_temp.accept()  while True: # 必须有这个循环才能一直接受一个客户的消息, 没有循环只能接收一次  get_msg = client.recv(1024).decode(\u0026#39;utf-8\u0026#39;)  print(get_msg)  sed_msg = input(\u0026#39;服务器:\u0026#39;).encode(\u0026#39;utf-8\u0026#39;)  client.send(sed_msg)    *********** 客户端 *********************** from socket import socket   def client():  client = socket()  client.connect((\u0026#39;10.7.152.105\u0026#39;, 7779))  while True:  msg = input(\u0026#39;客户端:\u0026#39;).encode(\u0026#39;utf-8\u0026#39;)  client.send(msg)  get_msg = client.recv(1024).decode(\u0026#39;utf-8\u0026#39;)  print(get_msg) emample 用服务器与客户端结合实现猜数字游戏 #  #服务器 from random import randint from socket import socket from time import sleep   class Robot(object):  def __init__(self):  self.answer = randint(1, 100)  self._hint = \u0026#39;\u0026#39;  self.count = 0   @property  def hint(self):  return self._hint   def judge(self, yours):  self.count += 1  if yours \u0026gt; self.answer:  self._hint = \u0026#39;请输入小一点\u0026#39;  elif yours \u0026lt; self.answer:  self._hint = \u0026#39;请输入大一点\u0026#39;  else:  self._hint = \u0026#39;猜对了,但没有奖励....\u0026#39;  if self.count \u0026gt; 7:  self._hint += \u0026#39;\\n智商真捉急!!!\u0026#39;  return True  return False   def main():  robot = Robot()  server = socket()  server.bind((\u0026#39;10.7.152.105\u0026#39;, 9669))  server.listen(512)  print(\u0026#39;服务器开启...\u0026#39;)  while True:  client, addr = server.accept()  print(addr)  while True:  get_msg = int(client.recv(1024).decode(\u0026#39;utf-8\u0026#39;))  if 0 \u0026lt; get_msg \u0026lt; 100:  robot.judge(get_msg)  out_msg = robot.hint  client.send(out_msg.encode(\u0026#39;utf-8\u0026#39;))  else:  out_msg = \u0026#39;输入有误,重新输入\u0026#39;  client.send(out_msg.encode(\u0026#39;utf-8\u0026#39;))   print(\u0026#39;服务器关闭.....\u0026#39;)  server.close()   if __name__ == \u0026#39;__main__\u0026#39;:  main()    \\****************************************\\  # 客户端  from socket import socket   def main():  client = socket()  client.connect((\u0026#39;10.7.152.105\u0026#39;, 9669))  while True:  numstr = input(\u0026#39;输入数字:\u0026#39;)  client.send(numstr.encode(\u0026#39;utf-8\u0026#39;))  in_msg = client.recv(1024).decode(\u0026#39;utf-8\u0026#39;)  print(in_msg)   print(\u0026#39;客户端断开连接\u0026#39;)  client.close()   if __name__ == \u0026#39;__main__\u0026#39;:  main() 4. BASE 64 编码 #  将二进制数据变为有64种符号表示的文本 011011001100001111010011 将二进制编码每6位分开 4.1 处理方法 示例 #  用一个字典的 键值对 形式保存要发送的数据 将字典处理成 JSON 格式进行传输  JSON 只能是纯文本 用 BSAE64 处理二进制数据  dumps()处理二进制数据  \\*********************** 服务器 from socket import socket, SOCK_STREAM, AF_INET from base64 import b64encode from json import dumps   def main():  # 1.创建套接字对象并指定使用哪种传输服务  server = socket()  # 2.绑定IP地址和端口(区分不同的服务)  server.bind((\u0026#39;10.7.152.69\u0026#39;, 5566))  # 3.开启监听 - 监听客户端连接到服务器  server.listen(512)  print(\u0026#39;服务器启动开始监听...\u0026#39;)  with open(\u0026#39;memory.png\u0026#39;, \u0026#39;rb\u0026#39;) as f:  # 将二进制数据处理成base64再解码成字符串  data = b64encode(f.read()).decode(\u0026#39;utf-8\u0026#39;)  while True:  client, addr = server.accept()  # 用一个字典(键值对)来保存要发送的各种数据  # 待会可以将字典处理成JSON格式在网络上传递  my_dict = dict({})  my_dict[\u0026#39;filename\u0026#39;] = \u0026#39;memory.png\u0026#39;  # JSON是纯文本不能携带二进制数据  # 所以图片的二进制数据要处理成base64编码  my_dict[\u0026#39;filedata\u0026#39;] = data  # 通过dumps函数将字典处理成JSON字符串  json_str = dumps(my_dict)  # 发送JSON字符串  client.send(json_str.encode(\u0026#39;utf-8\u0026#39;))  client.close()   if __name__ == \u0026#39;__main__\u0026#39;:  main() ********************************************** ## 客户端 ############# from socket import socket from json import loads from base64 import b64decode   def main():  client = socket()  client.connect((\u0026#39;10.7.152.69\u0026#39;, 5566))  # 定义一个保存二进制数据的对象  in_data = bytes()  # 由于不知道服务器发送的数据有多大每次接收1024字节  data = client.recv(1024)  while data:  # 将收到的数据拼接起来  in_data += data  data = client.recv(1024)  # 将收到的二进制数据解码成JSON字符串并转换成字典  # loads函数的作用就是将JSON字符串转成字典对象  my_dict = loads(in_data.decode(\u0026#39;utf-8\u0026#39;))  filename = my_dict[\u0026#39;filename\u0026#39;]  filedata = my_dict[\u0026#39;filedata\u0026#39;].encode(\u0026#39;utf-8\u0026#39;)  with open(\u0026#39;c:/images/\u0026#39; + filename, \u0026#39;wb\u0026#39;) as f:  # 将base64格式的数据解码成二进制数据并写入文件  f.write(b64decode(filedata))  print(\u0026#39;图片已保存.\u0026#39;)   if __name__ == \u0026#39;__main__\u0026#39;:  main() "},{"id":38,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/04-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"04-适配器模式","section":"11-Python设计模式","content":"介绍 #  适配器模式是一种结构型设计模式，帮助我们实现两个不兼容接口之间的兼容，实际就是将原来的对象转换为后者可以使用的对象\n将不同的对象实例化，并且赋予同样的接口指向对象内部不同的方法，实现统一方法不同的返回的适配器效果\n代码示例https://github.com/lanms/Python_design_pattern/blob/master/04-adapter.py\n"},{"id":39,"href":"/docs/03-git/05-gitattributes%E8%AE%BE%E7%BD%AE%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7/","title":"05-gitattributes设置文件属性","section":"03-Git","content":"Git的gitattributes文件详解 #  Git的gitattributes文件是一个文本文件，文件中的一行定义一个路径的若干个属性。\n  gitattributes文件以行为单位设置一个路径下所有文件的属性，格式如下： #     要匹配的文件模式 属性1 属性2 \u0026hellip;   在gitattributes文件的一行中，一个属性（以text属性为例）可能有4种状态： #     设置text 不设置-text 设置值text=string 未声明，通常不出现该属性即可；但是为了覆盖其他文件中的声明，也可以 !text   gitattributes文件示例： #    * text=auto .txt\ttext .jpg\t-text .vcproj\ttext eol=crlf .sh\ttext eol=lf .py\teol=lf 说明：\n  第1行，对任何文件，设置text=auto，表示文件的行尾自动转换。如果是文本文件，则在文件入Git库时，行尾自动转换为LF。如果已经在入Git库中的文件的行尾为CRLF，则该文件在入Git库时，不再转换为LF。\n  第2行，对于txt文件，标记为文本文件，并进行行尾规范化。\n  第3行，对于jpg文件，标记为非文本文件，不进行任何的行尾转换。\n  第4行，对于vcproj文件，标记为文本文件，在文件入Git库时进行规范化，即行尾为LF。但是在检出到工作目录时，行尾自动转换为CRLF。\n  第5行，对于sh文件，标记为文本文件，在文件入Git库时进行规范化，即行尾为LF。在检出到工作目录时，行尾也不会转换为CRLF（即保持LF）。\n  第6行，对于py文件，只针对工作目录中的文件，行尾为LF。\n   在一个Git库中可以有多个gitattributes文件： #    不同gitattributes文件中，属性设置的优先级(从高到低)：\n /myproj/info/attributes文件 /myproj/my_path/.gitattributes文件 /myproj/.gitattributes文件 同一个gitattributes文件中，按照行的先后顺序，如果一个文件的某个属性被多次设置，则后序的设置优先   也可以为所有Git库设置统一的gitattributes文件： #    git config --get core.attributesFile git config --global --get core.attributesFile  gitattributes文件中可以定义的属性： #     text，控制行尾的规范性。 如果一个文本文件是规范的，则Git库中该文件的行尾总是LF。  对于工作目录，除了text属性之外，还可以设置eol属性，或core.eol配置变量。\n eol，设置行末字符 eol=lf，入库时将行尾规范为LF，检出时禁止将行尾转换为CRLF eol=crlf，入库时将行尾规范为CRLF，检出时将行尾转换为CRLF crlf，已过时，类似于text ident，为路径设置ident属性，路径中的blob对象中的$Id$将会被替换为$Id:char_40_hexadecimal_name filter  利用命令clean,smudge\n diff merge，与merge.default配置变量一起确定如何合并文件 在执行git merge, git revert和git cherry-pick时，如何考虑文件的版本  Git内置的merge驱动：\n merge=text merge=binary merge=union whitespace，对应core.whitespace配置变量  在执行git diff, git apply时是否考虑空格。\n export-ignore,export-subst，打包相关的属性 delta，即Delta压缩  对于delta=false的路径中的blob对象，不会进行Delta压缩\n encoding，为GUI工具（如gitk, git-gui）设置字符编码，以正确显示匹配的文件内容  如果该属性未设置，或设置了无效值，则GUI工具会使用配置变量gui.encoding的值。\n参考链接：\nhttps://git-scm.com/docs/gitattributes #  "},{"id":40,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/05-pycharm%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC%E9%9B%86%E6%88%90%E8%AE%BE%E7%BD%AE/","title":"05-Pycharm代码风格集成设置","section":"15-集成开发","content":"设置代码分风格为 Google\n设置默认的测试模式\n"},{"id":41,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/05-yield%E5%87%BD%E6%95%B0/","title":"05-yield函数","section":"01-python基础","content":"sys #   在Linux系统命令行参数 在输入命令是给的参数 sys.argv 接受所有的参数 保存在数组中  yield #  # 生成式 列表已存在,占用空间大 list1 = [x for x in range(10)]  #生成器 得到的是 generator 对象 引用  list3 = (x for c in range(10)) for i in list3: # 在需要用的时候再计算出值  print(i)  # 生成器函数 def fibo(n): #普通函数   a, b = (0, 1)  for _ in range(n):  a, b = b, a + b  return a  def fibo(n): #生成器函数 保留上次计算的值 不会重复计算   a, b = (0, 1)  for _ in range(n):  a, b = b, a + b  yield a string.center(占据的位置大小, [,空位填补]) string.ljust() string.rjust() # 二选一列表 [[0], [1]][True] = [1] [[0], [1]][False] = [0] 进阶 #   生成器函数， 可以理解为暂停，程序会暂停在yield的地方， 等待下一次调用 next() 时， 程序又会执行一次， 然后继续执行  next() #  可以通过打断点来进行理解， 让程序一步一步执行， 查看程序到底执行到了那里， 暂停到了那里\nsend() #   import time   def constumer():  r = \u0026#39;\u0026#39;  while True:  n = yield r  if not n:  return  print(\u0026#39;[CONSUMER] 消费者：%s\u0026#39; % n)  time.sleep(1)  r = \u0026#39;CONSUMER，结束状态！\u0026#39;  def produce():  c = constumer()  next(c)   n = 0  while n \u0026lt; 3:  n += 1  print(\u0026#39;n的值：%s...\u0026#39; % n)  # 将 n 传入到 yield 中， yield r 的值 替换为 n，  # 同时 将原来的r 的值获取到， 赋值给当前的 r  r = c.send(n)   print(\u0026#39;r的值：%s\u0026#39; % r)  print(\u0026#39;--\u0026#39; * 20)   def main():  produce()   if __name__ == \u0026#39;__main__\u0026#39;:  main() "},{"id":42,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/05-%E4%BF%AE%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"05-修饰器模式","section":"11-Python设计模式","content":"修饰器模式 #  和继承相比，通常因该优先选择组合，因为继承使得代码更加难复用，继承关系是静态的。修时器模式能够以透明的方式动态的将功能添加到一个对象中，对该对象的功能进行扩展。\n代码示例https://github.com/lanms/Python_design_pattern/blob/master/05-deactor_pattern.py\n"},{"id":43,"href":"/docs/05-linux/05-%E5%AE%9A%E6%97%B6%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%E4%BB%BB%E5%8A%A1/","title":"05-定时执行脚本任务","section":"05-Linux","content":"05-定时执行脚本任务\ncrontab -t 执行脚本 creotab -e 修改程序\n 今天做了个数据库的备份脚本，顺便系统得学习一下Linux下定时执行脚本的设置。Linux下的定时执行主要是使用crontab文件中加入定制计划来执行，设置比Windows稍微复杂一些(因为没有图形界面嘛)，但是也不是非常复杂，基本上用过一遍就能记住了，关键是要记住/var/spool/cron这个目录。下面看一下具体的用法：   首先查看一下/etc/crontab文件：  $ cat /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/  # run-parts 01 * * * * root run-parts /etc/cron.hourly 02 4 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly   前四行是有关设置cron任务运行的环境变量。SHELL变量的值指定系统使用的SHELL环境(该样例为bash shell)，PATH变量定义了执行命令的路径。Cron的输出以电子邮件的形式发给MAILTO变量定义的用户名。如果MAILTO变量定义为空字符串(MAILTO=\u0026#34;\u0026#34;)，电子邮件不会被发送。执行命令或脚本时HOME变量可用来设置基目录。  文件/etc/crontab中每行任务的描述格式如下:   minute hour day month dayofweek command   minute - 从0到59的整数  hour - 从0到23的整数  day - 从1到31的整数 (必须是指定月份的有效日期)  month - 从1到12的整数 (或如Jan或Feb简写的月份)  dayofweek - 从0到7的整数，0或7用来描述周日 (或用Sun或Mon简写来表示)  command - 需要执行的命令(可用as ls /proc \u0026gt;\u0026gt; /tmp/proc或 执行自定义脚本的命令)   root表示以root用户身份来运行  run-parts表示后面跟着的是一个文件夹，要执行的是该文件夹下的所有脚本   对于以上各语句，星号(*)表示所有可用的值。例如*在指代month时表示每月执行(需要符合其他限制条件)该命令。  整数间的连字号(-)表示整数列，例如1-4意思是整数1,2,3,4  指定数值由逗号分开。如：3,4,6,8表示这四个指定整数。  符号“/”指定步进设置。“/\u0026lt;interger\u0026gt;”表示步进值。如0-59/2定义每两分钟执行一次。步进值也可用星号表示。如*/3用来运行每三个月份运行指定任务。   以“#”开头的为注释行,不会被执行。   如果一个cron任务需要定期而不是按小时,天,周,月来执行,则需要添加/etc/cron.d目录。这个目录下的所有文件和文件/etc/crontab语法相同，查看样例：  # record the memory usage of the system every monday  # at 3:30AM in the file /tmp/meminfo  30 3 * * mon cat /proc/meminfo \u0026gt;\u0026gt; /tmp/meminfo # run custom scrīpt the first day of every month at 4:10AM  10 4 1 * * /root/scrīpts/backup.sh   除了root用户之外的用户可以执行crontab配置计划任务。所有用户定义的crontab存储在目录/var/spool/cron下，任务会以创建者的身份被执行。要以特定用户创建一个crontab，先以该用户登录，执行命令crontab -e，系统会启动在VISUAL或者EDITOR中指定的的编辑软件编辑crontab。文件内容与/etc/crontab格式相同。示例如下：  # 表示每天3点执行/home/dbbackup/db1backup.sh backup 0 3 * * * /home/dbbackup/db1backup.sh backup # 4点执行/home/dbbackup/db2backup.sh backup 0 4 * * * /home/dbbackup/db2backup.sh backup  # 如果是每五分钟执行一次可改为： */5 * * * * /home/dbbackup/db2backup.sh backup   当更改的crontab需要保存时，文件会保存在成如下文件/var/spool/cron/username。文件名会根据用户名而不同。   cron服务会每分钟检查一次/etc/crontab、/etc/cron.d/、/var/spool/cron文件下的变更。如果发现变化，就会下载到存储器中。因此，即使crontab文件改变了，程序也不需要重新启动。推荐自定义的任务使用crontab -e命令添加，退出后用/etc/init.d/crond restart命令重启crond进程，官方文件说不用重启进程，但我遇到不重启无法运行任务的情况。开始不知道/etc/crontab文件中的run-parts是什么意思，直接把命令按照/etc/crontab的格式加上总是无法运行，后来才知道run-parts是指后面跟着的是文件夹。  下面再附一篇介绍： ************************************************************************************ cron是一个linux下的定时执行工具，可以在无需人工干预的情况下运行作业。由于Cron 是Linux的内置服务，但它不自动起来，可以用以下的方法启动、关闭这个服务：  /sbin/service crond start //启动服务 /sbin/service crond stop //关闭服务 /sbin/service crond restart //重启服务 /sbin/service crond reload //重新载入配置  你也可以将这个服务在系统启动的时候自动启动：  在/etc/rc.d/rc.local这个脚本的末尾加上： /sbin/service crond start  现在Cron这个服务已经在进程里面了，我们就可以用这个服务了，Cron服务提供以下几种接口供大家使用：  1.直接用crontab命令编辑  cron服务提供crontab命令来设定cron服务的，以下是这个命令的一些参数与说明：  crontab -u //设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数 crontab -l //列出某个用户cron服务的详细内容 crontab -r //删除没个用户的cron服务 crontab -e //编辑某个用户的cron服务  比如说root查看自己的cron设置：crontab -u root -l 再例如，root想删除fred的cron设置：crontab -u fred -r 在编辑cron服务时，编辑的内容有一些格式和约定，输入：crontab -u root -e  进入vi编辑模式，编辑的内容一定要符合下面的格式：*/1 * * * * ls \u0026gt;\u0026gt; /tmp/ls.txt  这个格式的前一部分是对时间的设定，后面一部分是要执行的命令，如果要执行的命令太多，可以把这些命令写到一个脚本里面，然后在这里直接调用这个脚本就可以了，调用的时候记得写出命令的完整路径。时间的设定我们有一定的约定，前面五个*号代表五个数字，数字的取值范围和含义如下：  分钟 (0-59) 小時(0-23) 日期(1-31) 月份(1-12) 星期(0-6) //0代表星期天   除了数字还有几个个特殊的符号就是\u0026#34;*\u0026#34;、\u0026#34;/\u0026#34;和\u0026#34;-\u0026#34;、\u0026#34;,\u0026#34;，*代表所有的取值范围内的数字，\u0026#34;/\u0026#34;代表每的意思,\u0026#34;*/5\u0026#34;表示每5个单位，\u0026#34;-\u0026#34;代表从某个数字到某个数字,\u0026#34;,\u0026#34;分开几个离散的数字。以下举几个例子说明问题：  #每天早上6点 ----------------- 0 6 * * * echo \u0026#34;Good morning.\u0026#34; \u0026gt;\u0026gt; /tmp/test.txt //注意单纯echo，从屏幕上看不到任何输出，因为cron把任何输出都email到root的信箱了。  #每两个小时 ----------------- 0 */2 * * * echo \u0026#34;Have a break now.\u0026#34; \u0026gt;\u0026gt; /tmp/test.txt  #晚上11点到早上8点之间每两个小时，早上八点 ----------------- 0 23-7/28 * * * echo \u0026#34;Have a good dream：）\u0026#34; \u0026gt;\u0026gt; /tmp/test.txt  #每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 ----------------- 0 11 4 * 1-3 command line  #1月1日早上4点 ----------------- 0 4 1 1 * command line   每次编辑完某个用户的cron设置后，cron自动在/var/spool/cron下生成一个与此用户同名的文件，此用户的cron信息都记录在这个文件中，这个文件是不可以直接编辑的，只可以用crontab -e 来编辑。cron启动后每过一份钟读一次这个文件，检查是否要执行里面的命令。因此此文件修改后不需要重新启动cron服务。  2.编辑/etc/crontab 文件配置cron   cron服务每分钟不仅要读一次/var/spool/cron内的所有文件，还需要读一次/etc/crontab，因此我们配置这个文件也能运用cron服务做一些事情。用crontab配置是针对某个用户的，而编辑/etc/crontab是针对系统的任务。此文件的文件格式是：  SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root //如果出现错误，或者有数据输出，数据作为邮件发给这个帐号 HOME=/ //使用者运行的路径,这里是根目录 # run-parts 01 * * * * root run-parts /etc/cron.hourly //每小时执行/etc/cron.hourly内的脚本 02 4 * * * root run-parts /etc/cron.daily //每天执行/etc/cron.daily内的脚本 22 4 * * 0 root run-parts /etc/cron.weekly //每星期执行/etc/cron.weekly内的脚本 42 4 1 * * root run-parts /etc/cron.monthly //每月去执行/etc/cron.monthly内的脚本  大家注意\u0026#34;run-parts\u0026#34;这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是文件夹名了。 ************************************************************************************ "},{"id":44,"href":"/docs/03-git/06-gitignore%E8%AE%BE%E7%BD%AE/","title":"06-gitignore设置","section":"03-Git","content":"Git的gitignore文件设置 #  [TOC]\n在使用Git的过程中，我们喜欢有的文件比如日志，临时文件，编译的中间文件等不要提交到代码仓库，这时就要设置相应的忽略规则，来忽略这些文件的提交。\nGit 忽略文件提交的方法 #  有三种方法可以实现忽略Git中不想提交的文件。\n在Git项目中定义 .gitignore 文件 #  这种方式通过在项目的某个文件夹下定义 .gitignore 文件，在该文件中定义相应的忽略规则，来管理当前文件夹下的文件的Git提交行为。\n.gitignore 文件是可以提交到公有仓库中，这就为该项目下的所有开发者都共享一套定义好的忽略规则。\n在 .gitingore 文件中，遵循相应的语法，在每一行指定一个忽略规则。如：\n*.log *.temp /vendor 在Git项目的设置中指定排除文件 #  这种方式只是临时指定该项目的行为，需要编辑当前项目下的 .git/info/exclude 文件，然后将需要忽略提交的文件写入其中。\n需要注意的是，这种方式指定的忽略文件的根目录是项目根目录。\n定义Git全局的 .gitignore 文件 #  除了可以在项目中定义 .gitignore 文件外，还可以设置全局的 git .gitignore 文件来管理所有Git项目的行为。这种方式在不同的项目开发者之间是不共享的，是属于项目之上Git应用级别的行为。\n这种方式也需要创建相应的 .gitignore 文件，可以放在任意位置。然后在使用以下命令配置Git：\ngit config --global core.excludesfile ~/.gitignore Git 忽略规则 #  详细的忽略规则可以参考官方英文文档\nGit 忽略规则优先级 #  在 .gitingore 文件中，每一行指定一个忽略规则，Git 检查忽略规则的时候有多个来源，它的优先级如下（由高到低）：\n 从命令行中读取可用的忽略规则 当前目录定义的规则 父级目录定义的规则，依次递推 $GIT_DIR/info/exclude 文件中定义的规则 core.excludesfile中定义的全局规则  Git 忽略规则匹配语法 #  在 .gitignore 文件中，每一行的忽略规则的语法如下：\n 空格不匹配任意文件，可作为分隔符，可用反斜杠转义 # 开头的文件标识注释，可以使用反斜杠进行转义 ! 开头的模式标识否定，该文件将会再次被包含，如果排除了该文件的父级目录，则使用 ! 也不会再次被包含。可以使用反斜杠进行转义 / 结束的模式只匹配文件夹以及在该文件夹路径下的内容，但是不匹配该文件 / 开始的模式匹配项目跟目录 如果一个模式不包含斜杠，则它匹配相对于当前 .gitignore 文件路径的内容，如果该模式不在 .gitignore 文件中，则相对于项目根目录 ** 匹配多级目录，可在开始，中间，结束 ? 通用匹配单个字符 [] 通用匹配单个字符列表  常用匹配示例： #   bin/: 忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件 /bin: 忽略根目录下的bin文件 /*.c: 忽略 cat.c，不忽略 build/cat.c debug/*.obj: 忽略 debug/io.obj，不忽略 debug/common/io.obj 和 tools/debug/io.obj **/foo: 忽略/foo, a/foo, a/b/foo等 a/**/b: 忽略a/b, a/x/b, a/x/y/b等 !/bin/run.sh: 不忽略 bin 目录下的 run.sh 文件 *.log: 忽略所有 .log 文件 config.php: 忽略当前路径的 config.php 文件 .gitignore规则生效 #  .gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。\n解决方法就是先把本地缓存删除（改变成未track状态），然后再提交:\ngit rm -r --cached . git add . git commit -m \u0026#39;update .gitignore\u0026#39; 原文出处：http://uusama.com/542.html\n"},{"id":45,"href":"/docs/05-linux/06-linux%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/","title":"06-Linux操作命令","section":"05-Linux","content":"Linux常用命令 #  chmod a+x file.txt 赋予文件权限\necho 回声命令\nprintf 打印 可以格式化输出\ncat 查看文档\nrpm -q package_name 确认安装包已成功安装\nsysctl -p 验证Linux 核心参数\n$$ 当前的PID\n$? 检测命令是否运行成功 -0 标准输入 -1 标准输出 -2 标准错误 -其他 错误\n$* 运行的参数的个数\n$@ 当前文件\n$0 当前运行的文件\n$1 第一个参数\nread var 读取输入，赋值给 var\n-d path 判断是否为目录 [ -d /home ] \u0026amp;\u0026amp; echo yes\npgrep xxx 获得xxx的进程ID\nps -ef |grep xxx 查看完成的进程信息\ncat/proc/$PID/environ | tr '\\0' '\\n' 查看PID 进程的环境变量，替换 空 为换行输出\n{} 分隔变量和普通字符 ${fruit}(s)\n\u0026gt; 输出到文件，每次输出会覆盖原内容\n\u0026gt;\u0026gt; 追加的方式输出到文件\n别名\nalias new_command=\u0026quot;command sequence\u0026quot;\n eg: alias rm='cp $@ ~/backup \u0026amp;\u0026amp; rm $@' 备份当前文件并删除  tput 获取终端相关的信息\ndate 显示读取的时间\ndate +%s  时间戳显示时间，纪元时间\ndata --data 'Jan 20 2011' +%A ===\u0026raquo; Satarday 对时间进行计算，格式化输出需要的内容\n%a 星期简写 %A 全拼\n%b %B 月份\n%d %D 日期\n%y %Y 年\nbash -x script.sh shell 跟踪调试\n{1..8} 1-8 的数组\n #! /bin/bash  function DEBUG() {  [ \u0026#34;$_DEBUG\u0026#34;==\u0026#34;on\u0026#34; ] \u0026amp;\u0026amp; $@ ||: } for i in {1..10} do \tDEBUG echo \u0026#34;I am $i\u0026#34; done  # 执行 $ _DEBUG=on ./secript.sh  # 在每一条需要打印调试信息的语句前加上DEBUG，如果没有 DEBUG=on 传递给脚本，那么调试信息就不会被打印出来 Frok 炸弹\n:(){ :|:\u0026amp; }; :\n"},{"id":46,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/06-pycharm%E9%9B%86%E6%88%90%E6%A3%80%E6%9F%A5%E5%B7%A5%E5%85%B7/","title":"06-Pycharm集成检查工具","section":"15-集成开发","content":"pylint\n Program: C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36-32\\Scripts\\pylint.exe Arguments: -rn --msg-template=\u0026#34;{abspath}:{line}: [{msg_id}({symbol}), {obj}] {msg}\u0026#34; $FilePath$ Working directory: $FileDir$  Output filters: flake8\n Program: $PyInterpreterDirectory$/python  C:\\Users\\zhang\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\flake8.exe Arguments: -m flake8 --show-source --statistics $ProjectFileDir$ Working directory: $ProjectFileDir$  Output filters: autopep8\n Program: C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36-32\\Scripts\\autopep8.exe Arguments: --in-place --aggressive --aggressive $FilePath$ Working directory: $ProjectFileDir$  Output filters: $FILE_PATH$\\:$LINE$\\:$COLUMN$\\:.* "},{"id":47,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/06-python%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93/","title":"06-Python操作数据库","section":"01-python基础","content":"ORM - Object Relation Mapping 对象关系映射\n 关系型数据库 - 关系模型 Python 程序 - 对象模型 第三方框架 Alchemy 可以完成对象关系的双向转换,可以直接操作 数据库, 不用写 SQL 语句, 但是会降低性能  关键字 #  host / [port] / user / passwd / db / charset / [autocommit / cursorclass=pymysql.cursors.DictCursor]\n操作方法 #   调用的是pymysql的connect()/Cursor()方法 创建连接 pymysql.connect() 输入  import pymysql conn = pymysql.connect(host=\u0026#39;localhost\u0026#39;, port=3306,user=\u0026#39;root\u0026#39;, passwd=\u0026#39;123456\u0026#39;, db=\u0026#39;hrs\u0026#39;,charset=\u0026#39;utf8\u0026#39;, autocommit=False)  创建Cursor()  cursor.execute() 执行sql语句    try: \twith conn.cursor() as cursor:  result = cursor.execute(\u0026#39;insert into tbdept values ()\u0026#39;)  conn.commit() finally:  conn.close()   在写sql语句时, 不可以用字符串格式化的方法来传参数,会被SQL注射攻击(SQL Injection) (x\u0026rsquo; or 1=1\u0026rsquo;) 加一个恒成立的条件来跳过检查 使用其规定的占位符写法(占位符加元组) 也可以使用命名占位符 名称 + 字典  # 安全占位符 result = cursor.execute(\u0026#39;insert into tbdept values (%s, %s, %s)\u0026#39;,(dno, dname, dloc)) # 命名占位  result = cursor.execute(\u0026#39;insert into tbdept values (%(no)s, %(name)s, %(dloc)s)\u0026#39;, {\u0026#39;no\u0026#39;: dno, \u0026#39;name\u0026#39;: dname, \u0026#39;loc\u0026#39;: dloc}) 用 select + fetchone() 对查找内容进行输出\n 使用查询语句对数据库进行查询,返回的是一个元组 不可使用 select * from table 的方法对数据库进行查询,这样会先查询该数据库的属性然后在将属性和内容返回出来,变变为了两次查询,降低了查询的速度   try:  with conn.cursor() as cursor:  # 一般不适用 * 查询 ,  cursor.execute(\u0026#39;select dno, dname, dloc from tbdept\u0026#39;)  result = cursor.fetchone()  while result: # fetchone 每次抓去一条出来  print(result[1])  result = cursor.fetchone()  conn.commit()  finally:  conn.close()  构建一个类, 将查到的结果(元组)出入, 通过类的构造方法对需要的属性进行查询 将 cursor 的类型改为字典 cursor  cursorclass=pymysql.cursors.Dictcursor    常见的报出的错误 #  Cannot connect\u0026hellip; host 错误 port 错误 服务器没有启动\nAccess denied \u0026hellip; -user/ -passwd错误\nUnknown database \u0026hellip;. 数据库名字写错\nMySQL syntax Error / unknow \u0026hellip; SQL 语句错误\n默认情况root 只能本地连接,不能远程连接, 如果出现远程连接错误时, 将数据库的主机改为 %\n"},{"id":48,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/06-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/","title":"06-外观模式","section":"11-Python设计模式","content":"外观模式 #  系统会随着演化变得非常复杂，最终代码内部的类有大量的交互，错综复杂，不适合将其暴露给客户，外观设计模式有助于隐藏系统的内部复杂性，并通过一个简化的接口向客户端提供数据。本质上，外观模式是在已有的复杂系统上实现的一个抽象层。\n外观模式常用于给一个复杂的系统提供简单的接口\n核心实现方法是使用，抽象方法在类中实现固定接口，将其他没必要暴露在外的方法都交给类内部自己实现，在调用需要实现类中的功能的时候只需要将类中暴露出来的方法进行实现即可\n代码示例https://github.com/lanms/Python_design_pattern/blob/master/06-face_pattern.py\n"},{"id":49,"href":"/docs/03-git/07-git_flow%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","title":"07-Git_Flow使用方法","section":"03-Git","content":"  http://www.berlinix.com/it/gitflow.php\nhttp://www.berlinix.com/it/gitflow.php\nhttp://www.berlinix.com/it/git.php\nhttp://www.berlinix.com/it/git.php\ngitflow分支管理模型 #  gitflow的分支类型：\n master分支（1个） develop分支（1个） feature分支。同时存在多个。 release分支。同一时间只有1个，生命周期很短，只是为了发布。 hotfix分支。同一时间只有1个。生命周期较短，用了修复bug或小粒度修改发布。  在这个模型中，master和develop都具有象征意义。master分支上的代码总是稳定的（stable build），随时可以发布出去。develop上的代码总是从feature上合并过来的，可以进行Nightly Builds，但不直接在develop上进行开发。当develop上的feature足够多以至于可以进行新版本的发布时，可以创建release分支。\nrelease分支基于develop，进行很简单的修改后就被合并到master，并打上tag，表示可以发布了。紧接着release将被合并到develop；此时develop可能往前跑了一段，出现合并冲突，需要手工解决冲突后再次合并。这步完成后就删除release分支。\n当从已发布版本中发现bug要修复时，就应用到hotfix分支了。hotfix基于master分支，完成bug修复或紧急修改后，要merge回master，打上一个新的tag，并merge回develop，删除hotfix分支。\n由此可见release和hotfix的生命周期都较短，master/develop虽然总是存在但却不常使用。\n以上就是gitflow的基本概念了。下面是nvie（gitflow的提出者，一个荷兰人！） A successful Git branching model（发布于2010年月5日）一文的笔记。\n从右看起：\n 时间轴。 feature（玫红）。主要是自己玩了，差不多的时候要合并回develop去。从不与master交互。 develop（黄色）。主要是和feature以及release交互。 release（绿色）。总是基于develop，最后又合并回develop。当然对应的tag跑到master这边去了。 hotfix（红色）。总是基于master，并最后合并到master和develop。 master（蓝色）。没有什么东西，仅是一些关联的tag，因从不在master上开发。  接下来nvie说道自己喜爱git，因git改变了人们对合并/分支（merge/branches）的看法。从集中式的代码管理工具过来的人感到释放了（beware of merge conflicts, they bite you，注意合并冲突，它们会跳出来咬你！）。\ngitflow实例 #  安装gitflow：\n$ git clone --recursive git://github.com/nvie/gitflow.git $ cd gitflow/ $ sudo make install $ ls /usr/local/bin/git-flow /usr/local/bin/git-flow 到项目根目录下执行gitflow，因为之前修改没有commit，所以gitflow初始化失败：\n$ git flow init fatal: Working tree contains unstaged changes. Aborting. commit后再次进行gitflow初始化：\n$ git commit -a -m \u0026#34;update Bash\u0026#34; [master 8f5b874] update Bash 4 files changed, 71 insertions(+), 5 deletions(-) [bailing@zhuji zhuji]$ git flow init Which branch should be used for bringing forth production releases? - master Branch name for production releases: [master] Branch name for \u0026#34;next release\u0026#34; development: [develop] How to name your supporting branch prefixes? Feature branches? [feature/] Release branches? [release/] Hotfix branches? [hotfix/] Support branches? [support/] Version tag prefix? [] 一路回车下来，各个分支名都按默认的设置。最后，当前分支已经被切换到了develop：\n$ git branch * develop master 建立一个新的feature。git flow新建了功能分支feature/blog_builder，并在develop的基础上checkout了新分支：\n$ git flow feature start blog_builder $ git branch develop * feature/blog_builder master 开发完成后执行如下命令：\n$ git flow feature finish blog_builder Summary of actions: - The feature branch \u0026#39;feature/blog_builder\u0026#39; was merged into \u0026#39;develop\u0026#39; - Feature branch \u0026#39;feature/blog_builder\u0026#39; has been removed - You are now on branch \u0026#39;develop\u0026#39; 正如这条命令的总结所言，git flow为我们做了3件事：\n 把feature/blog_builder合并到了develop。 删除了feature/blog_builder分支。 切换回develop分支。  接下来发布一个正常的版本：\n$ git flow release start v0.5 一旦需要发布的版本确认无误可以发布后，执行命令：\n$ git flow release finish v0.5 summary of actions: - Latest objects have been fetched from \u0026#39;origin\u0026#39; - Release branch has been merged into \u0026#39;master\u0026#39; - The release was tagged \u0026#39;v0.5\u0026#39; - Release branch has been back-merged into \u0026#39;develop\u0026#39; - Release branch \u0026#39;release/v0.5\u0026#39; has been deleted 注意release/v0.5被合并到了master和develop分支，并打了个v0.5的tag，然后被删除，最后切换回了develop分支：\n$ git branch * develop master 发布时只需将tag为v0.5的版本checkout出来部署即可：\n$ git tag v0.5 当上线后发现v0.5的bug，可以进行hotfix：\n$ git flow hotfix start v0.5.1 此时gitflow从master分支上拉出一个hotfix/v0.5.1的分支，接下来在新分支上修改bug。最后执行命令：\n$ git flow hotfix finish v0.5.1 这样hotfix/v0.5.1被merge到master/develop分支，打好v0.5.1这个tag，删除这个分支，切换回develop分支。\n之后又是新一次的轮回，启动正常的feature开发。\n-\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\nGit（the stupid content tracker）是一个源自Linux内核项目的源码管理工具。和传统的CVS、SVN不同，git是一个分布式源码管理工具。\n   Git命令 简单说明     git init 初始化一个本地的代码仓库。   git clone 从远程复制一个代码仓库。   git config git选项设置。   git add 添加文件/目录。   git commit 提交修改。   git status 显示工作目录的状态以及缓冲区内的快照。   git log 已提交快照的日志。   git branch 创建分支。   git checkout 迁出/拉出/切换到一个分支。   git merge 合并分支。   git revert 撤销commit快照。   git reset 撤销本地工作目录的修改。   git clean 删除代码仓库以外的文件。   git remote 管理远程git。   git fetch 从远程获取分支。   git pull 从远程获取分支。   git push 把代码推到远程分支。    基本概念 #  文件状态 #  Git仓库中的文件有几种状态：\n untracked - 还没添加到仓库中。 unmodified - 自上次提交以来，文件未曾修改过。 modified - 文件修改了还没提交。 staged - 文件提交到了暂存区中。一旦执行git commit就会转换为unmodified状态。  Git暂存区（Staged Area）的意思是：你把一个文件托付给Git跟踪（git add），然后又修改了它，此时这个文件就位于暂存区了。暂存区内的文件几乎只做一件事：等待你执行git commit，把它提交。\n快照（snapshot） #  Git与其他版本控制系统的区别在于：Git只关心文件是否变化，而不关心文件内容的变化。大多数版本控制系统都会忠实地记录版本间的文件差异（diff），但Git不关心这些具体差异（哪一行有什么变动），Git只关心哪些文件修改了哪些没有修改，修改了的文件直接复制形成新的blob（这就是所谓的快照snapshot）。当你需要切换到或拉出一个分支时，Git就直接加载当时的文件快照即可，这就是Git快的原因。说起来，这也是用空间换取时间的经典案例。\n从这个角度看，Git更像是一个小型文件系统，并在这个系统上提供一系列的工具来辅助开发。\nGit的地理观 #  Git是一个分布式的版本控制系统，因此没有所谓的中心。粗略来看Git可分为本地库（local repository）和远程库（remote repository），细致地看可分为以下几个部分：\n Working Directory - 工作目录。Git仓库位于工作目录之下，工作目录下的文件有加入Git仓库（tracked）和没加入Git仓库（untracked）的区别。 Stage Area - 暂存区。如上所述，已加入Git仓库并被修改（尚未提交）的文件。 Local Repository - 本地仓库。 Remote Repository - 远程仓库。  文件通常是：加入Git仓库（git add）-\u0026gt; 修改后即位于暂存区 -\u0026gt; 提交到本地库（git commit） -\u0026gt; 推送到远程库（git push）。\norigin/master #  这里主要笔记一些在Git上下文中经常遇见的术语。origin/master指远程仓库origin的master分支。\n远程仓库/分支 这样的形式。虽然Git是分布式的系统，但通常把git clone的源头叫做origin，origin也被视为中心仓库（Central Repository）。\ngit入门 #  创建目录，并用git init初始化：\n$ mkdir learn-git \u0026amp;\u0026amp; cd learn-git $ git init Initialized empty Git repository in /tmp/learn-git/.git/ 从git init输出可知，git创建了一个名为.git的隐藏目录。\n创建一个文件，并用git add添加到仓库，用git commit提交：\n$ echo \u0026#34;hello git\u0026#34; \u0026gt; README.txt $ git add . $ git commit -m \u0026#34;readme file\u0026#34; [master (root-commit) cd27ac1] readme file 1 file changed, 1 insertion(+) create mode 100644 README.txt 接下来对已提交文件做一些修改，并新添加一个文件：\n$ echo \u0026#34;learn files here\u0026#34; \u0026gt;\u0026gt; README.txt $ cp ~/.vimrc . 用git diff查看文件差异（每次commit前应该先diff对比差异详情）：\n$ git diff diff --git a/README.txt b/README.txt index 8d0e412..0219596 100644 --- a/README.txt +++ b/README.txt @@ -1 +1,2 @@ hello git +learn files here 差异对比可以用git diff --cached保存下来（如此差异则不输出到屏幕）。\n用git status查看git仓库状态：\n$ git status # On branch master # Changes not staged for commit: # (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) # (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) # # modified: README.txt # # Untracked files: # (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) # # .vimrc no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 这里显示README.txt被修改了，而.vimrc则等待添加。接下来，我们将.vimrc添加到git仓库中，且将所有修改一并提交（git commit -a）：\n$ git commit -a -m \u0026#34;update readme \u0026amp;\u0026amp; add vimrc\u0026#34; [master f6162f0] update readme \u0026amp;\u0026amp; add vimrc 2 files changed, 123 insertions(+) create mode 100755 .vimrc git log输出git日志，包括提交编号（如\u0026quot;f6162f04170e3665bc03744e43f764c903e4e38d\u0026quot;这样的字串）、提交者、提交日期和提交日志。\ngit log的其他输出：\n$ git log -p # 详细日志，并输出到分页程序 $ git log --stat --summary 美化git log输出\n$ git log --graph --pretty=format:\u0026#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset\u0026#39; --abbrev-commit -- 修改全局配置：\n$ git config --global alias.lg \u0026#34;log --color --graph --pretty=format:\u0026#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset\u0026#39; --abbrev-commit --\u0026#34; $ git lg 管理分支 #  创建一个分支：\n$ git branch exp 查看当前git仓库的所有分支：\n$ git branch exp * master 切换到exp分支：\n$ git checkout exp Switched to branch \u0026#39;exp\u0026#39; 修改文件，并提交：\n$ echo \u0026#34;start branch: exp\u0026#34; \u0026gt;\u0026gt; README.txt $ git commit -a -m \u0026#34;modified readme in exp branch\u0026#34; [exp 2e825a4] modified readme in exp branch 1 file changed, 1 insertion(+) 切换回master分支：\n$ git checkout master Switched to branch \u0026#39;master\u0026#39; 在master分支检查文件，可见exp分支的修改并没影响到master分支（注意，在exp分支的修改都已提交；如果没有提交，则切换回master分支会看到文件已变）。接下来我们制造一个冲突：\n$ echo \u0026#34;return branch: master\u0026#34; \u0026gt;\u0026gt; README.txt $ git commit -a -m \u0026#34;modified readme in master branch\u0026#34; [master 8dd9fb2] modified readme in master branch 1 file changed, 1 insertion(+) 用git merge exp合并分支：\n$ git merge exp Auto-merging README.txt CONFLICT (content): Merge conflict in README.txt Automatic merge failed; fix conflicts and then commit the result. 从git输出可见，git尝试自动合并但失败了，因此提示需要解决冲突再提交\n用git diff查看差异，且差异文件被修改：\n$ git diff ... $ cat README.txt hello git learn files here \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD return branch: master ======= start branch: exp \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; exp 手工解决冲突并再次提交：\n(edit file) $ git commit -a -m \u0026#34;do merge\u0026#34; 接下来，可以删除exp分支：\n$ git branch -d exp Deleted branch exp (was 2e825a4). git branch -d删除分支时会检查分支是否完全合并到主干，如果不是，则会删除失败，并提示需要合并：\n$ git branch exp # 建立exp分支 $ git checkout exp # 切换到exp分支 $ echo \u0026#34;exp again\u0026#34; \u0026gt;\u0026gt; README.txt # 修改并提交 $ git commit -a -m \u0026#34;exp again\u0026#34; [exp 868e68c] exp again 1 file changed, 1 insertion(+) $ git checkout master # 切换回master Switched to branch \u0026#39;master\u0026#39; $ git branch -d exp # 删除失败 error: The branch \u0026#39;exp\u0026#39; is not fully merged. If you are sure you want to delete it, run \u0026#39;git branch -D exp\u0026#39;. 可以用git branch -D exp忽略修改，完全删除分支：\n$ git branch -D exp Deleted branch exp (was 868e68c). 查看远端git #  基础命令是：git remote show, git remote show X。\n$ git remote show origin web 查看GitHub默认设置的origin\n$ git remote show origin * remote origin Fetch URL: git@github.com:berlinix/blog.git Push URL: git@github.com:berlinix/blog.git HEAD branch: master Remote branch: master tracked Local branch configured for \u0026#39;git pull\u0026#39;: master merges with remote master Local ref configured for \u0026#39;git push\u0026#39;: master pushes to master (fast-forwardable) git命令快查 #  以下列出一些常用的git命令\n   命令 说明     基础操作    git init 初始化git仓库   git add X 添加X文件/路径到git仓库   git commit -m \u0026ldquo;COMMENTS\u0026rdquo; 提交更新   分支管理    git branch X 创建一个名为X的分支   git checkout X 切换到X分支   git merge X 自动合并X分支   git branch -d X 删除X分支，需要先merge   git branch -D X 强制删除X分支，忽略其修改，无须先merge   与远程git交互    git remote show 显示远程git仓库   git remote show X 显示远程git一个名为X的仓库   git push origin master 更新提交到GitHub    Git日常问题 #  撤销commit #  刚与master合并并提交后就后悔了现在要做的是撤销commit（revoke/undo merge/commit）。\n查看当前所在分支：\n$ git branch bs3 * coin dev master 查看日志：\n$ git log --oneline 9b7ba39 merged with master 73a66e8 update FAQ 用以下2个命令来撤销提交（把COMMIT_SHA替换为实际的SHA值；把HEAD~N中的N替换为一个数字，表示回退几步）：\n$ git reset --hard COMMIT_SHA $ git reset --hard HEAD~N 例如回退到合并前：\n$ git reset --hard 73a66e8 HEAD is now at 73a66e8 update FAQ 回退后发现不对，因为现在这个commit还是在master中的（在merge之前master已经走的太远），赶紧再次reset到merge时的状态：\n$ git reset --hard 9b7ba39 HEAD is now at 9b7ba39 merged with master 如此一来就是就是merge后commit之前的状态。接下来就是要完成undo merge（已经undo commit了）：\n$ git revert -m 1 9b7ba39 这下就彻底回到merge前了，以防万一再次检查：\n$ git diff --name-status master..coin 看起来没什么问题了，检查下日志：\n$ git log --oneline 2691516 Revert \u0026#34;merged with master\u0026#34; 9b7ba39 merged with master 73a66e8 update FAQ 用git找回已删除文件 #  首先找到与目标文件相关的最后一次commit。如果目标文件没有出现在HEAD commit中，那么在这次commit时，文件就被删除了：\n$ git rev-list -n 1 HEAD -- htdocs/myfile.php 1e8182f58dc038c8e6bc2025e8430f463d372030 接下来就是恢复工作了：\n$ git checkout 1e8182f58dc038c8e6bc2025e8430f463d372030^ -- htdocs/myfile.php 合并分支的部分文件 #  有时候只想合并分支里的部分文件，而不是整个分支，可以用这个命令：\ngit checkout BRANCH FILE ... 例如，从test_branch分支中合并file_modified文件：\n$ git checkout test_branch file_modified 参考Git Tip: How to \u0026ldquo;Merge\u0026rdquo; Specific Files from Another Branch。\n  "},{"id":50,"href":"/docs/05-linux/07-linux%E5%91%BD%E4%BB%A4cat-find/","title":"07-Linux命令cat-find","section":"05-Linux","content":"常用命令 cat find\n[TOC]\ncat #   -s  去除文件的多余空白行显示，不会对原文件进行修改 -n 显示行号 -t 挂起文件，始终显示最后更行内容  录制终端会话并进行回放\n # 开始录制 script -t 2\u0026gt; timing.log -a output.seeeion  # 回放 scriptreplay timing.log output.session find #    -print 打印查找内容， \\n 分隔\n  find . -type f -print|xargs ls -l\n  find . -iname 'filename' -print 模糊查找\n  逻辑运算关联查找 find . \\( -name '*e*' -and -name 's*'\\)\n  -a -and 关联查找 -o -or 逻辑或\n  -regex 正则表达式查找 -iregex\n  ! 否定参数 find . ！ -name '*.txt' -print\n  -maxdepth 指定查找的深度 -mindepth\n  -type 文件类型 f 普通文件 d 目录\n  -atime 访问时间 默认是 天 day -tmin 分钟\n  -mtime 修改时间 -mmin\n  -ctime 变化时间 -cmin\n  find . -type f -atime -7 -print 7天内访问过\n  find . -type f -amin +7 -print 5分钟之前访问过的文件\n  -newer 参考其他文件的访问时间新的访问过的文件\n  -perm 基于文件的权限 find . -type f -perm 644 -print\n  -delete 删除\n  -exec 执行其他命令，将查找到的内容作为参数\n  "},{"id":51,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/07-%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/","title":"07-享元模式","section":"11-Python设计模式","content":"享元模式 #  介绍 #  享元模式通过为相似对象引入数据共享来最小化内存使用，提升性能，一个享元就是一个包含状态的独立的不可变数据的共享对象，依赖状态的可变数据不应是享元的一部分，因为每个对象的这种信息不相同，无法共享，如果享元需要非固有数据应该由客户端代码显示提供。\n例如我们正在设计一个性能为关键的游戏，例如第一人称设计游戏（FPS），在FPS游戏中，玩家（士兵）共享一些状态，如外在的表现和行为。例如在 CS 游戏中，同一团队的所有士兵看起来都是一样的，所有的士兵都有一些共同 的动作，比如，低头，跳跃等，这意味着我们可以创建一个享元来包含所有的共同数据，当然，士兵也有许多因人而异的数据，这些数据不是享元的一部分，比如，枪支/健康状况和地理位置等。\n应用场景 #  享元旨在优化性能和内存的使用。所有的嵌入式系统（如手机，平板，游戏终端和微控制器等）还有和性能相关的应用，如游戏，3D图形处理和实时系统等，都能从其中获益。\n享元模式的使用条件：\n 应用需要使用大量的对象 对象太多，存储/渲染它们的代价太大，一旦移除对象中的可变形态，多组不同的对象可以被相对更少的共享对象所替代。 对象的ID对于应用不重要，对象共享改会造成ID的比较失败，所以不能依赖对象的ID。  关于memoization与享元模式之间的区别 #  memoization是一种优化技术，使用一个缓存来避免重复计算已经在前期步骤中计算好的结果，memoization并不是只能应用于某种特定的编程方式，还可以应用于方法和简单的函数。享元则是一种特定于面向对象编程优化的审计模式，享元关注的是共享的诗句。\n享元的实现 #  在Python中，享元可以以多种方式实现\n代码示例https://github.com/lanms/Python_design_pattern/blob/master/07-share_pattern.py\n def __new__(cls, tree_type):  obj = cls.pool.get(tree_type, None)  if not obj:  obj = object.__new__(cls)  cls.pool[tree_type] = obj  obj.tree_type = tree_type  return obj  # pool 是一个类属性，使用 __new__ 把 Tree 变成一个元类，元类支持自引用，cls 引用的是 Tree 类， # 当客户端需要创建一个 Tree实例时，会以 Tree_type 参数传递树的种类， # 树的种类用于检查是否创建过相同的树，如果已经创建过，则返回之前创建的对象， # 否则，将这种新的树种添加到池中，并创建新的对象  一句话总结 #  享元模式就是通过避免重复创建大量的已有的实列来优化程序的结构和性能，Python中可以使用元类来创建，类似于单例模式\n"},{"id":52,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/07-%E8%A3%85%E9%A5%B0%E5%99%A8/","title":"07-装饰器","section":"01-python基础","content":"装饰器\n 一个函数, 两个功能  def func_3(line):  def comp(value):  if value \u0026gt;= line:  print(\u0026#39;{}\u0026gt;= {}\u0026#39;.format(value, line))  else:  print(\u0026#39;{}\u0026lt; {}\u0026#39;.format(value, line))  return comp  f = func_3(60) # 第一次调用外侧函数 f(89) # 第二次调用内层x # 相当于  func_3(60)(89)  自动将函数的参数放进了中间功能函数的中作为参数 会将实际传入目标函数的参数在装饰器中先传入进行验证, 也就是先执行装饰器的函数, 再执行目标函数  def dec_1(func):  def wrapper(num1, num2):  if num2 == 0:  return (\u0026#39;0000\u0026#39;)  return func(num1, num2)  return wrapper  def average_1(num1, num2):  return num1 / num2  # averge_1 = dec_1(average_1) # a = averge_1(5, 0) # print(a) @dec_1 def sum_1(num1, num2):  return num1 + num2 a = sum_1(1, 0) print(a) ==接收不同 的参数==\n 装饰器需要写三层 也就是说最内层的只能接收到目标函数的参数, 但是如果需要传入目标函数参数以外的参数就必须要再加一层装饰器, 来讲需要的参数传入  def auth(auth_type):  def dec_3(func):  def wrapper(*args, **kwargs):  if auth_type == \u0026#39;1\u0026#39;:  print(\u0026#39;111111111\u0026#39;)  elif auth_type == \u0026#39;2\u0026#39;:  print(\u0026#39;22222222\u0026#39;)  else:  print(\u0026#39;0000--0000\u0026#39;)  return func(*args, **kwargs)  return wrapper  return dec_3 @auth(auth_type=\u0026#39;4\u0026#39;) def average_3(*args):  return sum(args) a = average_3(1, 2, 3, 4) print(a) "},{"id":53,"href":"/docs/05-linux/08-centos7%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%89%A9%E5%B1%95%E7%A3%81%E7%9B%98/","title":"08-Centos7虚拟机扩展磁盘","section":"05-Linux","content":"Centos虚拟机扩展磁盘\n简介 #  CentOS7虚拟机原硬盘空间只分配了10GB，需要扩容到20GB。 环境：VMware 10\nVMware分配空间 #  选中虚拟机-\u0026gt;虚拟机设置-\u0026gt;硬盘-\u0026gt;实用工具-\u0026gt;扩展-\u0026gt;设置最大磁盘大小-\u0026gt;点击扩展 CentOS7内部分配 #  可以参考：http://jingyan.baidu.com/article/54b6b9c0fc8b0b2d583b47c6.html\n 查看当前磁盘空间，/dev/mapper/cl-root硬盘空间只有8GB，打算扩容：  # df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/cl-root 8.0G 3.8G 4.3G 47% / devtmpfs 482M 0 482M 0% /dev tmpfs 493M 0 493M 0% /dev/shm tmpfs 493M 6.7M 486M 2% /run tmpfs 493M 0 493M 0% /sys/fs/cgroup /dev/sda1 1014M 184M 831M 19% /boot tmpfs 99M 0 99M 0% /run/user/0  对新增的硬盘空间做新增分区（硬盘数没有增加，增加的是空间）  # fdisk /dev/sda Welcome to fdisk (util-linux 2.23.2).  Changes will remain in memory only, until you decide to write them. Be careful before using the write command.   Command (m for help): n Partition type:  p primary (2 primary, 0 extended, 2 free)  e extended Select (default p): p Partition number (3,4, default 3): 3 First sector (20971520-41943039, default 20971520): Using default value 20971520 Last sector, +sectors or +size{K,M,G} (20971520-41943039, default 41943039): Using default value 41943039 Partition 3 of type Linux and of size 10 GiB is set  Command (m for help): t Partition number (1-3, default 3): 3 Hex code (type L to list all codes): 8e Changed type of partition \u0026#39;Linux\u0026#39; to \u0026#39;Linux LVM\u0026#39;  Command (m for help): p  Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000bc924   Device Boot Start End Blocks Id System /dev/sda1 * 2048 2099199 1048576 83 Linux /dev/sda2 2099200 20971519 9436160 8e Linux LVM /dev/sda3 20971520 41943039 10485760 8e Linux LVM  Command (m for help): w The partition table has been altered!  Calling ioctl() to re-read partition table.  WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks.  重启系统 reboot 查看当前分区类型，本例类型为xfs  # df -T /dev/sda1 Filesystem Type 1K-blocks Used Available Use% Mounted on /dev/sda1 xfs 1038336 188240 850096 19% /boot  在新磁盘上创建xfs文件系统  # mkfs.xfs /dev/sda3 meta-data=/dev/sda3 isize=512 agcount=4, agsize=655360 blks  = sectsz=512 attr=2, projid32bit=1  = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=2621440, imaxpct=25  = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2  = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0  创建PV  # pvcreate /dev/sda3 WARNING: xfs signature detected on /dev/sda3 at offset 0. Wipe it? [y/n]: y  Wiping xfs signature on /dev/sda3.  Physical volume \u0026#34;/dev/sda3\u0026#34; successfully created. # pvdisplay  --- Physical volume ---  PV Name /dev/sda2  VG Name cl  PV Size 9.00 GiB / not usable 3.00 MiB  Allocatable yes (but full)  PE Size 4.00 MiB  Total PE 2303  Free PE 0  Allocated PE 2303  PV UUID MlRwjY-TmVF-H8PV-heSz-ALGL-Q7sp-jFU6Al   \u0026#34;/dev/sda3\u0026#34; is a new physical volume of \u0026#34;10.00 GiB\u0026#34;  --- NEW Physical volume ---  PV Name /dev/sda3  VG Name  PV Size 10.00 GiB  Allocatable NO  PE Size 0  Total PE 0  Free PE 0  Allocated PE 0  PV UUID 0hmgH0-0wVg-jWUW-65WX-1TYb-sUGH-6jF1qm  PV加入VG，vgextend后接VG Name，本例中为cl  vgextend cl /dev/sda3 # vgdisplay  --- Volume group ---  VG Name cl  System ID  Format lvm2  Metadata Areas 1  Metadata Sequence No 3  VG Access read/write  VG Status resizable  MAX LV 0  Cur LV 2  Open LV 2  Max PV 0  Cur PV 1  Act PV 1  VG Size 9.00 GiB  PE Size 4.00 MiB  Total PE 2303  Alloc PE / Size 2303 / 9.00 GiB  Free PE / Size 0 / 0  VG UUID dYdb4l-wMUh-e2xv-WiaJ-Oa52-NvdF-s5ICJC  # vgextend cl /dev/sda3  VG加入LV  # lvextend -l +2559 /dev/cl/root  Size of logical volume cl/root changed from 8.00 GiB (2047 extents) to 17.99 GiB (4606 extents).  Logical volume cl/root successfully resized. 后两个参数“+2559”和“/dev/cl/root”来源详解： “+2559”来自于vgdisplay命令的Free PE/Size字段\n# vgdisplay  --- Volume group ---  VG Name cl  ...  VG Size 18.99 GiB  PE Size 4.00 MiB  Total PE 4862  Alloc PE / Size 2303 / 9.00 GiB  Free PE / Size 2559 / 10.00 GiB  VG UUID dYdb4l-wMUh-e2xv-WiaJ-Oa52-NvdF-s5ICJC “/dev/cl/root”来自于lvdisplay命令的LV Path字段。\n# lvdisplay  ...  --- Logical volume ---  LV Path /dev/cl/root  ...  调整文件系统大小，本例中是xfs文件系统使用xfs_growfs命令调整，若其他文件系统，如ext4使用resize2fs命令，注意区分。  # xfs_growfs /dev/cl/root # xfs_growfs /dev/mapper/centos-root # centos7命令 meta-data=/dev/mapper/cl-root isize=512 agcount=4, agsize=524032 blks  = sectsz=512 attr=2, projid32bit=1  = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=2096128, imaxpct=25  = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2  = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 2096128 to 4716544 结果 #  /dev/mapper/cl-root从8G增加到了18G\n# df -h Filesystem Size Used Avail Use% Mounted on /dev/mapper/cl-root 18G 3.8G 15G 21% / devtmpfs 482M 0 482M 0% /dev tmpfs 493M 0 493M 0% /dev/shm tmpfs 493M 6.7M 486M 2% /run tmpfs 493M 0 493M 0% /sys/fs/cgroup /dev/sda1 1014M 184M 831M 19% /boot tmpfs 99M 0 99M 0% /run/user/0https://www.cnblogs.com/x_wukong/tag/Linux/) "},{"id":54,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/08-mvc%E6%A8%A1%E5%BC%8F/","title":"08-MVC模式","section":"11-Python设计模式","content":"MVC模式 #  模型-视图-控制器模式\nSoC 关注点分离（Separation of Concerns）是软件工程相关设计原则之一。SoC原则背后的思想是将一个应用切分成不同的部分，每个部分解决一个单独的关注点。分层设计中的层次即是关注点的例子，使用SoC原则能简化软件应用的开发和维护。\nMVC就是应用到面向对象编程的SoC原则。\n模型是核心部分，代表着应用的信息本源，包含和管理业务逻辑，数据，状态以及应用的规则。\n视图是模型的可视化表现。\n控制器是模型和视图之间的链接。模型和视图之间的信息交互都是由控制器进行控制。\n总结 #  MVC模式将各个模块的功能进行解耦和，方便应用的管理和代码的扩展\n"},{"id":55,"href":"/docs/03-git/08-tox%E4%BD%BF%E7%94%A8/","title":"08-tox使用","section":"03-Git","content":"tox\ntox是通用的虚拟环境管理和测试命令行工具，tox能够让我们在同一个Host上自定义出多套相互独立且隔离的python环境\n 检查软件包能否在不同的python版本或解释器下正常安装 在不同的环境中运行测试代码 作为持续集成服务的前端，大大减少测试工作所需的时间  2、openstack社区tox使用：\n比如openstack社区的openstack-infra/project-config工程，其gerrit配置的门禁，其门禁具体执行中使用了tox执行基本语法检测。\nS1、clone该工程：\ngit clone https://github.com/openstack-infra/project-config.git\nS2、查看project-config的工程门禁配置（project-config/zuul/layout.yaml截取一部分）：\n - name: openstack-infra/project-config  template:  - name: bindep-fallback  - name: merge-check  check:  - gate-project-config-gerrit  - gate-project-config-grafyaml  - gate-project-config-layout\t# check阶段的门禁   - gate-project-config-linters-ubuntu-xenial  - gate-project-config-irc-access  - gate-project-config-jenkins-project  - gate-project-config-nodepool  - gate-infra-docs-index  - gate-generate-specs-site  - gate-project-config-dib S3、查看gate-project-config-layout的工程配置：\n（位于project-config/jenkins/jobs/infra.yaml中）\njob: name: gate-project-config-layout node: ubuntu-trusty  builders:  - net-info # 显示环境信息，如构建时间、ip、网络状况等  - zuul-git-prep # zuul-clone工程  - install-distro-packages # 安装相应依赖  - revoke-sudo # 取消sudo权限  - run-tox: # 调用tox的相关脚本   envlist: \u0026#39;zuul\u0026#39;   publishers:  - test-results - console-log S4、重点是查看builder：run-tox的配置，位于project-config/jenkins/jobs/macros.yaml：\n  - builder:  name: run-tox  builders:  - shell: \u0026#34;/usr/local/jenkins/slave_scripts/run-tox.sh {envlist}\u0026#34; 实际上最后执行的脚本就是：/usr/local/jenkins/slave_scripts/run-tox.sh zuul\nrun-tox.sh的脚本位于：project-config/jenkins/scripts/run-tox.sh\nS5、run-tox.sh中脚本，最重要的就是：\ntox -vv -e$venv （其中venv=$1，也就是zuul）\n其中执行的脚本就是zuul -vv zuul，执行对应的测试\n具体的参见openstack的gerrit：\nhttps://review.openstack.org/#/q/status:merged+project-config\n3、tox -vv zuul的具体执行任务：\n当clone下来project-config的工程后，里面有tox.ini文件（截取相关的部分）\n[testenv:zuul] basepython = python2.7 deps = # 安装对应的依赖   jenkins-job-builder==1.6.1  zuul whitelist_externals = # 白名单，列出的命令可在virtualenv中使用   bash  find  jenkins-jobs  mkdir  rm commands = # 具体的执行命令的过程脚本   rm -rf {envdir}/tmp  mkdir -p {envdir}/tmp/jobs  pip install -U jenkins/modules/jjb_afs  jenkins-jobs -l debug test -o {envdir}/tmp/jobs jenkins/jobs  bash -c \u0026#39;find {envdir}/tmp/jobs -printf \u0026#34;%f\\n\u0026#34; \u0026gt; {envdir}/tmp/job-list.txt\u0026#39;  zuul-server -c tools/zuul.conf-sample -l zuul/layout.yaml -t {envdir}/tmp/job-list.txt  {toxinidir}/tools/layout-checks.py {envdir}/tmp/job-list.txt 可以看到，这个tox.ini文件中有很多配置，这里只是截取了该任务对应的配置。、\n{envdir}：tox.ini文件目录\n4、查看tox的详细配置：\ntox的https://tox.readthedocs.io/en/latest/examples.html\n常见配置如下：\n（1）tox -i http://pypi.my-alternative-index.org：更换pypi依赖的下载地址\n（或者在tox.ini中指定indexserver地址）\n（2）通常tox只能传递系统变量PATH，如果需要传递其他变量，需要赋值指定；\n（3）指定基础环境，有几种方式：\n使用tox -e ENV1[,ENV2\u0026hellip;]\n（4）使用distshare变量实现多个tox工程的文件共享\n（5）使用basepython指定构建virtualenv的编译器\n（6）usedevelop：使用开发模式安装\n（7）skipsdist：不在virtualenv中安装本次软件，使用时需谨慎\n5、tox集成pytest、unitest、nose等：\n比如一个简单的例子如下，在工程的tox.ini中写入：\n [tox] envlist = py26,py31 [testenv] deps=pytest # PYPI package providing pytestcommands=  pytest \\ ​ {posargs} # substitute with tox\u0026#39; positional arguments 在tox.ini目录中执行tox命令的时候，会构建py26、py31两个环境，并且安装pytest，并执行对应的pytest测试\n6、使用tox类：\n可以在python脚本中使用tox的类调用对应的tox方法。\n import tox os.chdir(os.getenv(\u0026#39;WORKSPACE\u0026#39;)) tox.cmdline()\t# 执行对应的tox命令，可根据情况入参，具体参见tox类的函数 7、构建一个开发的virtual环境：\n我们可以使用tox构建一个简单的virtualenv环境辅助我们进行开发\n详情参见：https://tox.readthedocs.io/en/latest/example/devenv.html\n然后用virtualenv + 路径切入进行测试开发\n"},{"id":56,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/08-tox%E9%9B%86%E6%88%90%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","title":"08-tox集成使用指南","section":"15-集成开发","content":"以keystone工程为例，其他工程类似\n内容包括：打源码包（sdist）、单元测试（UT）、测试覆盖率（coverage）、代码格式检查（pep8，flake）\npip install tox 可以将tox安装在外部全局环境中，方便每次使用tox命令，而不用激活虚拟环境，tox会在当前工程的文件目录下创建.tox文件目录来下载需要的虚拟环境和存放生成的文件\n1、引子 #  接触了一段时间openstack社区，并提交了几个bug之后，就发现社区中，从bug提交、问题确认、到bug修复，代码review，自动构建、单元测试、静态检查、再到代码合入，也就是我们经常说的持续集成（CI），是一个非常简单和高效的过程。\n开发人员都是懒人，这点我从来都没有怀疑过，怎么让一群懒人（还是一大群）将CI的这么多步骤做规范，并且不觉得是一个麻烦的过程，需要很高的技巧和聪明才智。\n我认为持续集成（CI）有两个重点需要把握，首先要好上手，简单易学，开发都是懒人，不好用的东西，很难养成习惯使用；其次做且仅做应该做的事，也就是CI检查的范围要确定，保持CI的高速，写完代码10分钟之内，要出ut和coverage的结果。\n来让我们看看openstack社区的持续集成都包括哪些内容，使用了哪些工具。\n2、tox具体使用方法 #  对openstack几个核心工程代码比较熟悉的朋友，可能都会注意到代码根目录下都有个tox.ini文件，tox其实就是openstack持续集成中非常重要的一个工具，tox.ini就是tox的配置文件。\ntox的官方对于tox的定义是这样的：\nTox as is a generic virtualenv management and test command line tool\nhttp://tox.readthedocs.org/en/latest/\n也就是一个通用的虚拟环境管理和测试命令行工具。\n所谓的虚拟环境，就是可以在一个主机上，自定义出多套的python环境，多套环境中使用不同的python拦截器，环境变量设置，第三方依赖包，执行不同的测试命令，最重要的是各个环境之间互不影响，相互隔离。\n最典型的应用就测试在不同python版本下代码的兼容性，我们可以为py2.4，py2.5，py2.6，py2.7创建不同的虚拟环境，都可以用tox统一管理；也可以在tox.ini中自定义虚拟环境，例如：testevn:pep8，代码格式检查；testenv:cover，测试覆盖率。\n我们以最新的H版的keystone的tox.ini为例：\n首先定义tox的全局配置，列出了需要执行的虚拟环境列表，在命令行中直接执行tox，就会依次执行py26，py27，pep8\n[tox] envlist = py26,py27,pep8 然后定义了虚拟环境的配置\nsetenv列出了虚拟机环境中生效的环境变量，一些配色方案和单元测试标志；\ndeps列出了虚拟环境需要的第三方依赖包，也就是keystone根目录下的requirements.txt和test-requirements.txt其中包括了keystone运行和单元测试时，需要用到的依赖包，每个虚拟环境创建的时候，会通过pip install -r requirements.txt和pip install -r test-requirements.txt安装依赖包到虚拟环境；\ncommands就是在当前虚拟环境中需要执行的命令，python tools/patch_tox_venv.py就是安装了redhat-eventlet.patch补丁；nosetests {posargs}就是执行nose进行单元测试，{posargs}参数就是可以将tox的参数传递给nosetests，例如：tox \u0026ndash; \u0026ndash;with-coverage执行的时候就是nosetests \u0026ndash;with-coverage\n[testenv] setenv = VIRTUAL_ENV={envdir}  NOSE_WITH_OPENSTACK=1  NOSE_OPENSTACK_COLOR=1  NOSE_OPENSTACK_RED=0.05  NOSE_OPENSTACK_YELLOW=0.025  NOSE_OPENSTACK_SHOW_ELAPSED=1  NOSE_OPENSTACK_STDOUT=1 deps = -r{toxinidir}/requirements.txt  -r{toxinidir}/test-requirements.txt commands = python tools/patch_tox_venv.py  nosetests {posargs} 自定义了一个pep8的代码静态检查的虚拟环境，执行flake8 \u0026ndash;filename=keystone* bin\n[testenv:pep8] commands =  flake8  flake8 --filename=keystone* bin \u0026lt;span style=\u0026#34;font-family: Arial, Helvetica, sans-serif; background-color: rgb(255, 255, 255);\u0026#34;\u0026gt;定义了和CI server jenkins的集成配置，指定了pip的下载cache目录，提高构建虚拟环境的速度\u0026lt;/span\u0026gt; [tox:jenkins] downloadcache = ~/cache/pip 定义一个cover的虚拟环境，就是指定了一些环境变量，使单元测试的时候，自动应用coverage，并定义了coverage生成的html报告目录\n[testenv:cover] setenv = VIRTUAL_ENV={envdir}  NOSE_WITH_COVERAGE=1  NOSE_COVER_HTML=1  NOSE_COVER_HTML_DIR={toxinidir}/cover 这个不太明白，也许就是创建一个虚拟机环境，执行一个自定义的命令行，以备扩展\n[testenv:venv] commands = {posargs} 定义了flake8静态检查的一些细节配置\n[flake8] show-source = true # H304: no relative imports.  ignore = H304 builtins = _ exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,tools,vendor,.update-venv 3、使用过程中的一些改进 #  直接使用keystone自带的tox.ini执行单元测试和静态检查时，也遇到了一些问题：\n每次执行tox命令的时候，所有的虚拟环境都会重建，重新用pip下载依赖包，时间都浪费在了下包上，recreate=False也不能解决，后来想了个招儿，先手动用pip将requirements.txt和test-requirements.txt都安装在系统python库下，然后将sitepackages=True，继承系统的依赖包。这样似乎打破了虚拟环境相互隔离的好处，但是能节省非常多的时间，大概70%。大家自己权衡是否需要使用这种方法。\n执行单元测试的时候，顺便生成单元测试报告，并检查测试覆盖率，并生成覆盖率报告。直接执行tox是不行的，只能进行单元测试，需要给tox增加扩展参数，如下：tox \u0026ndash; \u0026ndash;cover-erase \u0026ndash; \u0026ndash;with-coverage \u0026ndash; \u0026ndash;cover-html\n一开始执行tox的时候，生成的coverage覆盖率报告都是0%，百思不得其解，后来发现keystone根目录下有个.coveragerc文件，这个文件是coverage的配置文件，会影响coverage的行为，将文件中的source = keystone注释掉之后，正常生成覆盖率报告。\n"},{"id":57,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/08-%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0/","title":"08-递归函数","section":"01-python基础","content":"简介 #  ​\t一个递归函数的调用过程类似于多个函数的嵌套的调用，只不过调用函数和被调用函数是同一个函数。为了保证递归函数的正确执行，系统需设立一个工作栈。具体地说，递归调用的内部执行过程如下：\n 运动开始时，首先为递归调用建立一个工作栈，其结构包括值参、局部变量和返回地址； 每次执行递归调用之前，把递归函数的值参和局部变量的当前值以及调用后的返回地址压栈； 每次递归调用结束后，将栈顶元素出栈，使相应的值参和局部变量恢复为调用前的值，然后转向返回地址指定的位置继续执行。  简单来说:\n 递归就是对函数自身的调用, 但是必须有一个明确的结束条件, 称为递归出口  简单的递归函数\n def foo(n):   if n == 1: # 最后写中间的条件部分  return 1   return n * foo( n - 1 ) # 优先写递归调用的函数 ===\u0026gt; fact(5) ===\u0026gt; 5 * fact(4) ===\u0026gt; 5 * (4 * fact(3)) ===\u0026gt; 5 * (4 * (3 * fact(2))) ===\u0026gt; 5 * (4 * (3 * (2 * fact(1)))) ===\u0026gt; 5 * (4 * (3 * (2 * 1))) ===\u0026gt; 5 * (4 * (3 * 2)) ===\u0026gt; 5 * (4 * 6) ===\u0026gt; 5 * 24 ===\u0026gt; 120 代码来源, 廖雪峰的官方博客\n 一般在写递归是, 先将其外层的递归调用写出来, 然后在写中间判断使递归终止的条件, 条件一定要明确, 不然递归会一直递归下去, 造成死循环\n #####小结\n递归会将前面的调用的函数暂时挂起, 等待递归的终止条件给出的明确的条件, 然后将所有的挂起的内容进行反向计算, 其实, 递归也可以看做是一种反向计算的过程, 前面调用递归的过程只是将表达式罗列出来, 等待终止条件出现后, 依次从后往前倒序进行计算前面挂起的内容, 最后将所有结果一起返回\n递归调用的次数过多会导致栈的溢出, 入上例中 fact(1000), 这时就需要优化\n尾递归优化\n def fact_iter(num, product):  if num == 1:  return product   return fact_iter(num - 1, num * product)  def fact(n):  return fact_iter(n, 1)  将每次的乘积存入到 product 中, return fact_iter(num -1, num * product) 返回的仅仅是函数本身, num - 1, 和 num * product 在函数调用前就会被计算出来\n 上例中的优化其实就是讲 原本的倒序的计算, 通过 num * product 变为了正序的计算, 还是递归的思想, 但是不会占用其他的栈帧, 因为所有的结果都已近存放在了 product 中\n递归主要还是有防止溢出, Python标准的解释器并没有对尾递归做出优化, 所有一定要防止 栈溢出 的情况\n"},{"id":58,"href":"/docs/05-linux/09-alias%E7%BC%96%E8%BE%91%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4/","title":"09-alias编辑系统命令","section":"05-Linux","content":" vi ~/.bashrc  添加别名 在profile中设置PATH\nvi /etc/profile\n找到export行，在下面新增加一行，内容为：\nexport PATH=$PATH:/usr/local/apache/bin export PATH=$PATH:/home/lanms/Desktop/software/navicat121_premium_cs_x64 export PATH=$PATH:/usr/local/apache/bin 后面为想要添加的服务所在的文件目录 注：＝ 等号两边不能有任何空格。这种方法最好,除非手动强制修改PATH的值,否则将不会被改变。 编辑/etc/profile后PATH的修改不会立马生效，如果需要立即生效的话，可以执行\nsource profile命令苏\n"},{"id":59,"href":"/docs/03-git/09-git_rebase/","title":"09-git_rebase","section":"03-Git","content":"参考链接\nhttps://www.jianshu.com/p/4a8f4af4e803\n"},{"id":60,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/09-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","title":"09-代理模式","section":"11-Python设计模式","content":"代理模式 #  在某些应用中我们想要访问一个或者多个重要的操作，有时会进行一些敏感操作，在允许用户进行这些敏感操作的之前，我们希望确保用户具备足够的权限，操作系统也存在这样的情况，如在执行某些操作的时候必须有管理员权限才可以进行。\n常见的知名代理模式 #   远程代理：实际存在于不同地址空间的对象在本地的代理 虚拟代理：用于懒初始化，将一个大计算量对象的创建延迟到真正需要的时候 保护/防护代理：控制对敏感对象的访问 智能（引用）代理：在对象被访问时执行额外的动作，此类代理的例子包括引用计数和线程安全检查。  虚拟代理，代码示例https://github.com/lanms/Python_design_pattern/blob/master/09-proxy_pattern/09-1-Lazy.py\n代理模式代码 https://github.com/lanms/Python_design_pattern/blob/master/09-proxy_pattern/09-2-proxy.py\n"},{"id":61,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/09-%E7%BA%BF%E7%A8%8B%E5%92%8C%E8%BF%9B%E7%A8%8B/","title":"09-线程和进程","section":"01-python基础","content":"线程和进程 #  1. 同步和异步 #  针对结果\n 同步 - 多任务，多个任务执行的时候有先后的顺序， 必须一个先执行后， 另外一个才能继续执行， 只有一条运行主线 异步 - 多任务， 多个任务之间执行没有想先后顺序， 可以同时运行， 执行时先后顺序不会对程序有什么影响， 存在多条运行主线  2. 阻塞和非阻塞 #  针对运行状态 线程的状态（就绪、运行、阻塞）\n 阻塞 - 从调用者的角度出发， 如果在调用的时候， 被卡住， 不能再继续往下执行， 需要等待， 就是 阻塞 非阻塞 - 从调用者的角度出发， 如果在调用的时候， 没有被卡住， 能够继续向下执行， 无需等待， 就是 非阻塞  3. 并发和并行 #   并发 - 同时处理任务 并行 - 交替处理任务， 类似线程之间不断切换   并发的关键是你有处理多个任务的能力，不一定要同时。\n并行的关键是你有同时处理多个任务的能力,强调的是同时.\n 下面这篇文章可以参考解释上述概念\nhttps://blog.csdn.net/timemachine119/article/details/54091323\n进程和线程使用 #   进程：内存独立， 线程共享同一进程的内存， 一个进程就像是一个应用程序（app） 进程是资源的组合， 线程是执行的单位 进程之间不能直接相互访问， 同一进程中的线程可以相互通讯 创建新的进程很消耗系统资源， 线程非常轻量， 只需要保存线程运行时的必要数据， 如上下文， 程序的堆栈信息 同一进程里的线程可以相互控制， 父进程可以控制子进程  开多进程\n redis 缓存问题 读写分离， 单独设置缓存服务器来保存缓存， 读写都在该服务器上进行  关于 IO 密集型任务 和 计算密集型任务 #   CPU密集型 - 多进程 计算 IO密集型 - 多线程 文本操作   如果多线程的进程是CPU密集型的，那多线程并不能有多少效率上的提升，相反还可能会因为线程的频繁切换，导致效率下降，推荐使用多进程；如果是IO密集型，多线程进程可以利用IO阻塞等待时的空闲时间执行其他线程，提升效率。所以我们根据实验对比不同场景的效率\n 线程常用方法 #   t.start() 激活线程 （开始） t.getName() 获取线程名称 t.setName() 设置 t.name : 获取或设置线程的名称  t.is_alive() ： 判断线程是否为激活状态  t.isAlive() ：判断线程是否为激活状态  t.setDaemon() 设置为后台线程或前台线程（默认：False）;通过一个布尔值设置线程是否为守护线程，必须在执行start()方法之后才可以使用。如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止；如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程也执行完成后，程序停止  t.isDaemon() ： 判断是否为守护线程  t.ident ：获取线程的标识符。线程标识符是一个非零整数，只有在调用了start()方法之后该属性才有效，否则它只返回None。  t.join() ：逐个执行每个线程，执行完毕后继续往下执行，该方法使得多线程变得无意义  t.run() ：线程被cpu调度后自动执行线程对象的run方法 ==进程==\n  import os import time import random  from multiprocessing import Process   def coding():  while True:  print(\u0026#39;AAAAAA, 进程号：%s\u0026#39; % os.getpid())  time.sleep(random.randint(1, 5))  print(\u0026#39;BBBBBBB， 进程号：%s\u0026#39; % os.getpid())   def play():  while True:  print(\u0026#39;1111111111， 进程号：%s\u0026#39; % os.getpid())  time.sleep(random.randint(1, 5))  print(\u0026#39;2222222222， 进程号：%s\u0026#39; % os.getpid())   def main():  p1 = Process(target=coding)  p2 = Process(target=play)   p1.start() # 进程之间在不阻塞的情况下是没有影响的，  # 阻塞 等执行完才会进行下一个  # p1.join()  # p2.join(timeout=3) # 设置超时时间   p2.start()   if __name__ == \u0026#39;__main__\u0026#39;:  main() ==线程==\n   import threading import time   class Study(threading.Thread):   def __init__(self, name):  super(Study, self).__init__()  self.s_name = name   def run(self): # 重构方法  print(\u0026#39;当前线程名称- %s\u0026#39; % threading.current_thread().name)  print(\u0026#39;开始学习！- %s\u0026#39; % self.s_name)  time.sleep(3)  print(\u0026#39;学习结束\u0026#39;)  print(\u0026#39;当前线程名称- %s\u0026#39; % threading.current_thread().name)  # print(\u0026#39;---\u0026#39; * 20)   def main():   s1 = Study(\u0026#39;语文\u0026#39;)  s2 = Study(\u0026#39;数学\u0026#39;)   # 守护线程 在 start 前 主线程结束 子线程会被强制结束  # s1.daemon = True  # s2.daemon = True   # s1.start()  # 阻塞  # s1.join() # 阻塞在这里 等 s1 结束 再向下执行程序   # s2.start()   s1.run() # 都变为主线程 程序会顺序执行， 不存在同时执行  s2.run() # 相当于只是在执行函数， 并没有使用 多线程   print(\u0026#39;测试结束-----\u0026#39;)   # s1.run()   if __name__ == \u0026#39;__main__\u0026#39;:  main()  线程锁  多线程会共享资源， 需要线程锁， 当多个线程需要对同一资源进行修改时， 需要线程锁来保护资源， 避免操作资源出错\n未加锁\n  import threading   class MyThread(threading.Thread):   def __init__(self):  super(MyThread, self).__init__()  # self.s_name = s_name   def run(self):  global n  print(\u0026#39;number: %s, threading name: %s\u0026#39;% (n, self.name))  n += 1   def main():  thread_list = []  for i in range(20):  t1 = MyThread()  thread_list.append(t1)   for t in thread_list:  t.start()   if __name__ == \u0026#39;__main__\u0026#39;:  n = 0  main() 加线程锁\n Lock() 和 RLock() lock = threading.RLock() 允许加多把锁 lock = threading.Lock（） 只能加一把锁 lock = threading.BoundedSemaphore(3)  同时允许三个线程进入， 同时进入的线程多于 3 时会引发 ValueError   锁的本质是内部有一个计数器，调用 acquire() 会使这个计数器 -1，release() 则是+1.计数器的值永远不会小于 0，当计数器到 0 时，再调用 acquire() 就会阻塞，直到其他线程来调用release()\n   import threading   mylock = threading.Lock() # 添加锁   class MyThread(threading.Thread):   def __init__(self):  super(MyThread, self).__init__()  # self.s_name = s_name   def run(self):  if mylock.acquire(): # 锁定  global n  print(\u0026#39;number: %s, threading name: %s\u0026#39;% (n, self.name))  n += 1  mylock.release() #释放锁   def main():  thread_list = []  for i in range(20):  t1 = MyThread()  thread_list.append(t1)   for t in thread_list:  t.start()   if __name__ == \u0026#39;__main__\u0026#39;:  n = 0  main() 事件Event\npython线程的事件用于主线程控制其他线程的执行，事件主要提供了三个方法 set、wait、clear。\n事件处理的机制：全局定义了一个“Flag”，如果“Flag”值为 False，那么当程序执行 event.wait 方法时就会阻塞，如果“Flag”值为True，那么event.wait 方法时便不再阻塞。\n clear：将“Flag”设置为False set：将“Flag”设置为True Event.isSet() ：判断标识位是否为Ture   1 # 事件 event  2 lock = threading.Event()  3 def task(arg):  4 time.sleep(1)  5 # 锁住所有的线程  6 lock.wait()  7 print(arg)  8 for i in range(10):  9 t = threading.Thread(target=task,args=(i,)) 10 t.start() 11 while 1: 12 value = input(\u0026#39;\u0026gt;\u0026gt;:\u0026#39;).strip() 13 if value == \u0026#39;1\u0026#39;: 14 lock.set() # 打开锁，执行上面的print 15 # lock.clear() # 再锁上 线程池 #   会让线程 更具线程池设置的个数进行 执行， 每次同时执行的个数是设置的个数   import time  from concurrent.futures import ThreadPoolExecutor  def task(i):   time.sleep(2)  print(\u0026#39;hello!, 编号：\u0026#39;, i)  pool = ThreadPoolExecutor(3)  for i in range(50):  pool.submit(task, i) # 每次输出 三个 hello 线程池的回调函数\n 将前面函数的返回值作为后面的结果进行传递 future.add_done_callback(add1000) num = future.result()   import time  from concurrent.futures import ThreadPoolExecutor   def add100(num):  print(\u0026#39;我是 100 \u0026#39;)  return num + 100   def add1000(future):  print(\u0026#39;我是 + 1000\u0026#39;)  num = future.result()  time.sleep(5)  print(num + 1000)   def main():  pool = ThreadPoolExecutor(3)  for num in range(1,50):  print(\u0026#39;开始计算数字：%s！\u0026#39; % num)  future = pool.submit(add100, num)  future.add_done_callback(add1000) # 前面的结果返回后进行下个函数的调用   if __name__ == \u0026#39;__main__\u0026#39;:  main() 多进程 #   多进程之间可以数据共享   import time  from multiprocessing import Process   def task():  time.sleep(1)  print(\u0026#39;hello!\u0026#39;)   def main():   for i in range(10):  p = Process(target=task)  # p.daemon = True  p.start()  # p.join()  print(\u0026#39;主进程结束！！！\u0026#39;)   if __name__ == \u0026#39;__main__\u0026#39;:  main()   ### 数据共享  import time  from multiprocessing import Process, Array   def task(num, li):  time.sleep(1)  li[num] = num  print(list(li))   def main():  li = Array(\u0026#39;i\u0026#39;, 10)  for i in range(10):  p = Process(target=task, args=(i, li))  # p.daemon = True  p.start()  # p.join()  print(\u0026#39;主进程结束！！！\u0026#39;)   if __name__ == \u0026#39;__main__\u0026#39;:  main() 进程池 #  和线程池差不多\nfrom concurrent.futures import ProcessPoolExecutor as PPE    #基本用法  def task(arg):  time.sleep(1)  print(arg)   pool = PPE(5)  for i in range(10):  pool.submit(task,i)    # 进程池回调  def call(arg):  data = arg.result()  print(data)   def task(arg):  print(arg)  return arg+100   pool = PPE(5)  for i in range(10):  obj = pool.submit(task,i)  obj.add_done_callback(call) "},{"id":62,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/10-git_rebase/","title":"10-git_rebase","section":"15-集成开发","content":"https://www.jianshu.com/p/4a8f4af4e803\npick：保留该commit（缩写:p） reword：保留该commit，但我需要修改该commit的注释（缩写:r） edit：保留该commit, 但我要停下来修改该提交(不仅仅修改注释)（缩写:e） squash：将该commit和前一个commit合并（缩写:s） fixup：将该commit和前一个commit合并，但我不要保留该提交的注释信息（缩写:f） exec：执行shell命令（缩写:x） drop：我要丢弃该commit（缩写:d） s: 提供可编辑界面，编辑commit\nf: 自动融合，放弃当前的commit内容\nr: 需要继续　git rebase \u0026ndash;continue 进行编辑commit\ne: 需要继续执行命令　git commit \u0026ndash;admend 修改commit\nd: 删除commit ,慎用！\np: 保留commit\nx: 执行cmd shell 命令\n"},{"id":63,"href":"/docs/05-linux/10-linux%E5%AE%89%E8%A3%85%E5%B7%A5%E5%85%B7%E5%91%BD%E4%BB%A4/","title":"10-Linux安装工具命令","section":"05-Linux","content":"修改Host文件\nsudo gedit /etc/hosts chorme\nsudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/ \u0026amp; wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add - \u0026amp;sudo apt-get update \u0026amp; sudo apt-get install google-chrome-stable \u0026amp; /usr/bin/google-chrome-stable fish\n软件源所在文件目录\n/etc/apt/sources.list.d  apt update apt install fish sublime\nhttp://www.sublimetext.com/docs/3/linux_repositories.html\nwget -qO - https://download.sublimetext.com/sublimehq-pub.gpg | sudo apt-key add - echo -e \u0026#34;\\n[sublime-text]\\nServer = https://download.sublimetext.com/arch/dev/x86_64\u0026#34; | sudo tee -a /etc/pacman.conf apt-get update apt-get install sublime-text # 启动 subl # 修改host 添加 127.0.0.1 license.sublimehq.com 127.0.0.1 45.55.255.55 127.0.0.1 45.55.41.223 # 注册码 ----- BEGIN LICENSE ----- sgbteam Single User License EA7E-1153259 8891CBB9 F1513E4F 1A3405C1 A865D53F 115F202E 7B91AB2D 0D2A40ED 352B269B 76E84F0B CD69BFC7 59F2DFEF E267328F 215652A3 E88F9D8F 4C38E3BA 5B2DAAE4 969624E7 DC9CD4D5 717FB40C 1B9738CF 20B3C4F1 E917B5B3 87C38D9C ACCE7DD8 5F7EF854 86B9743C FADC04AA FB0DA5C0 F913BE58 42FEA319 F954EFDD AE881E0B ------ END LICENSE ------ "},{"id":64,"href":"/docs/05-linux/10-ubantu%E5%AE%89%E8%A3%85%E5%B7%A5%E5%85%B7%E5%91%BD%E4%BB%A4/","title":"10-ubantu安装工具命令","section":"05-Linux","content":"将vim设置为默认文本编辑器\necho export EDITOR=/usr/bin/vim \u0026gt;\u0026gt; ~/.bashrc 修改Host文件\nsudo gedit /etc/hosts chorme\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb sudo dpkg -i google-chrome-stable_current_amd64.deb fish\n软件源所在文件目录\n/etc/apt/sources.list.d  apt update apt install fish sublime\nhttp://www.sublimetext.com/docs/3/linux_repositories.html\nwget -qO - https://download.sublimetext.com/sublimehq-pub.gpg | sudo apt-key add - echo -e \u0026#34;\\n[sublime-text]\\nServer = https://download.sublimetext.com/arch/dev/x86_64\u0026#34; | sudo tee -a /etc/pacman.conf apt-get update apt-get install sublime-text # 启动 subl # 修改host 添加 127.0.0.1 license.sublimehq.com 127.0.0.1 45.55.255.55 127.0.0.1 45.55.41.223 # 注册码 ----- BEGIN LICENSE ----- sgbteam Single User License EA7E-1153259 8891CBB9 F1513E4F 1A3405C1 A865D53F 115F202E 7B91AB2D 0D2A40ED 352B269B 76E84F0B CD69BFC7 59F2DFEF E267328F 215652A3 E88F9D8F 4C38E3BA 5B2DAAE4 969624E7 DC9CD4D5 717FB40C 1B9738CF 20B3C4F1 E917B5B3 87C38D9C ACCE7DD8 5F7EF854 86B9743C FADC04AA FB0DA5C0 F913BE58 42FEA319 F954EFDD AE881E0B ------ END LICENSE ------ mysql\napt-get install mysql-server mysql-client libmysqlclient-dev mysql -u root -p redis\napt-get install redis-server navicat\nhttps://blog.csdn.net/ouzhuangzhuang/article/details/81739933\n破解方法\nhttps://blog.csdn.net/liumengyan_ysu/article/details/44224735\n定时删除注册信息可以永久使用\nhttps://blog.csdn.net/a295277302/article/details/78143010\n30 14 * * 2 rm -f /home/lanms/.navicat64/system.reg # 每周二，14：30执行一次 vi /etc/profile export PATH=$PATH:/home/lanms/Desktop/software/navicat121_premium_cs_x64 vi ~/.bashrc alias navicat=\u0026#34;/home/lanms/Desktop/software/navicat121_premium_cs_x64/start_navicat\u0026#34; 解决乱码\n选项里左边选择第一个，在右边第一个下拉框中选择Noto Sans mono CJK SC Regular\nhttps://blog.csdn.net/sinat_26546385/article/details/80381282\n"},{"id":65,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/10-%E5%8D%8F%E7%A8%8B%E5%92%8Caiohttp/","title":"10-协程和aiohttp","section":"01-python基础","content":"关于 GIL #   Pyhton的全局解释器锁  协程 #   协程其实就是一个线程， 在执行过程中， 在程序内部中断，然后转而执行别的程序，在适当的时候再返回来接着执行  优势 #   最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。  原因 : #   cpython解释器中存在一个GIL(全局解释器锁),他的作用就是保证同一时刻只有一个线程可以执行代码, 因此造成了我们使用多线程的时候无法实现并行。  解决方案法 : #    更换解释器 比如使用jpython(java实现的python解释器)\n  使用多进程完成多任务的处理\n   Python语言和GIL没有关系。仅仅是由于历史原因在Cpython虚拟机(解释器)，难以移除GIL。\n  GIL：\n  全局解释器锁。\n 每个线程在执行的过程都需要先获取GIL，保证同一时刻只有一个线程可以执行代码。 线程释放GIL锁的情况： 在IO操作等可能会引起阻塞的system call之前,可以暂时释放GIL,但在执行完毕后, 必须重新获取GIL Python 3.x使用计时器（执行时间达到阈值后，当前线程释放GIL）或Python 2.x，tickets计数达到100 Python使用多进程是可以利用多核的CPU资源的。 多线程爬取比单线程性能有提升，因为遇到IO阻塞会自动释放GIL锁  结论:\n 在 处理像科学计算 这类需要持续使用cpu的任务的时候 单线程会比多线程快 在 处理像IO操作等可能引起阻塞的这类任务的时候 多线程会比单线程  yield函数 #   生成器函数， 可以理解为暂停，程序会暂停在yield的地方， 等待下一次调用 next() 时， 程序又会执行一次， 然后继续执行  可以通过打断点来进行理解， 让程序一步一步执行， 查看程序到底执行到了那里， 暂停到了那里\nnext() 让 yield 向下执行\nsend(n) 将值传入到 yield ， 让后向下执行\n import time   def consumer():  r = \u0026#39;\u0026#39;  while True:  n = yield r  if not n:  return  print(\u0026#39;[CONSUMER] 消费者：%s\u0026#39; % n)  time.sleep(1)  r = \u0026#39;CONSUMER，结束状态！\u0026#39;   def produce(c):  next(c) # 启动程序 ，让执行到 yield 处， 暂停, 等待  n = 0  while n \u0026lt; 3:  n += 1  print(\u0026#39;n的值：%s...\u0026#39; % n)  # 将 n 传入到 yield 中， yield r 的值 替换为 n，  # 同时 将原来的r 的值获取到， 赋值给当前的 r  r = c.send(n)  print(\u0026#39;r的值：%s\u0026#39; % r)  print(\u0026#39;--\u0026#39; * 20)  c.close()   def main():  c = consumer()  produce(c)   if __name__ == \u0026#39;__main__\u0026#39;:  main() 总结 #   next() 激活， 向下执行 yield 暂停 停止， 并且返回值 sent() 激活 并且 替换 yield 的值  aiohttp #  官方文档 #  http://aiohttp.readthedocs.io/en/stable/\nasyncio #  asyncio 是 Python 3.4 版本引用的标准库， 直接内置了对异步IO 的支持\nasyncio的编程模式就是一个消息循环，我们从asyncio模块中直接获取一个 EventLoopd的引用， 然后把需要执行的协程扔到 EventLoop 中执行， 就实现了异步 IO，异步 IO 不会中断 CPU ，CPU 可以 继续其他的请求\n@asyncio.coroutine和anync + await效果相同， 只是写法不同 #  async和await是针对coroutine(/,kəuru:\u0026rsquo;ti:n/)的新语法（最新添加的保留关键字），要使用新的语法，只需要做两步简单的替换：\n 把@asyncio.coroutine替换为async 把yield from替换为await。  下面的函数得到相同的结果\nimport asyncio   @asyncio.coroutine def hello(n):  print(\u0026#39;hello, world! \u0026#39; + n)  r = yield from asyncio.sleep(3) # 等待 3s 但是程序马上启动了第二个任务  print(\u0026#39;hello complete! \u0026#39; + n)  async def hello(n):  print(\u0026#39;hello, world! \u0026#39; + n)  r = await asyncio.sleep(3)  print(\u0026#39;hello complete! \u0026#39; + n)  loop = asyncio.get_event_loop() task = asyncio.wait([hello(\u0026#39;AAAAAA\u0026#39;), hello(\u0026#39;BBBBBB\u0026#39;)]) loop.run_until_complete(task) loop.close() 我们可以在耗时较长的任务前中添加 await来让其实现多线程的并发\n实际就是在 判断为耗时较长的 程序代码前 添加 await\n使用自定义域名服务器 #  aiohttp #  异步 http 请求\n底层需要aiodns支持:\nfrom aiohttp.resolver import AsyncResolver  resolver = AsyncResolver(nameservers=[\u0026#34;8.8.8.8\u0026#34;, \u0026#34;8.8.4.4\u0026#34;]) conn = aiohttp.TCPConnector(resolver=resolver) 为TCP sockets添加SSL控制: #  默认情况下aiohttp总会对使用了HTTPS协议(的URL请求)查验其身份。但也可将verify_ssl设置为False让其不检查:\nr = await session.get(\u0026#39;https://example.com\u0026#39;, verify_ssl=False) 如果你需要设置自定义SSL信息(比如使用自己的证书文件)你可以创建一个ssl.SSLContext实例并传递到ClientSession中:\nsslcontext = ssl.create_default_context(  cafile=\u0026#39;/path/to/ca-bundle.crt\u0026#39;) r = await session.get(\u0026#39;https://example.com\u0026#39;, ssl_context=sslcontext) 代理支持 #  aiohttp 支持 HTTP/HTTPS形式的代理。你需要使用proxy参数:\nasync with aiohttp.ClientSession() as session:  async with session.get(\u0026#34;http://python.org\u0026#34;,  proxy=\u0026#34;http://some.proxy.com\u0026#34;) as resp:  print(resp.status) 同时支持认证代理:\nasync with aiohttp.ClientSession() as session:  proxy_auth = aiohttp.BasicAuth(\u0026#39;user\u0026#39;, \u0026#39;pass\u0026#39;)  async with session.get(\u0026#34;http://python.org\u0026#34;,  proxy=\u0026#34;http://some.proxy.com\u0026#34;,  proxy_auth=proxy_auth) as resp:  print(resp.status) 也可将代理的验证信息放在url中:\nsession.get(\u0026#34;http://python.org\u0026#34;,  proxy=\u0026#34;http://user:pass@some.proxy.com\u0026#34;) 与requests(另一个广受欢迎的http包)不同，aiohttp默认不会读取环境变量中的代理值。但你可以通过传递trust_env=True来让aiohttp.ClientSession读取HTTP_PROXY或HTTPS_PROXY环境变量中的代理信息(不区分大小写)。\nasync with aiohttp.ClientSession() as session:  async with session.get(\u0026#34;http://python.org\u0026#34;, trust_env=True) as resp:  print(resp.status) 设置超时 #  默认情况下每个IO操作有5分钟超时时间。可以通过给ClientSession.get()及其同类组件传递timeout来覆盖原超时时间:\nasync with session.get(\u0026#39;https://github.com\u0026#39;, timeout=60) as r:  ... None 或者0则表示不检测超时。 还可通过调用async_timeout.timeout上下文管理器来为连接和解析响应内容添加一个总超时时间:\nimport async_timeout  with async_timeout.timeout(0.001):  async with session.get(\u0026#39;https://github.com\u0026#39;) as r:  await r.text() 愉快地结束: #  当一个包含ClientSession的async with代码块的末尾行结束时(或直接调用了.close())，因为asyncio内部的一些原因底层的连接其实没有关闭。在实际使用中，底层连接需要有一个缓冲时间来关闭。然而，如果事件循环在底层连接关闭之前就结束了，那么会抛出一个 资源警告: 存在未关闭的传输(通道)(ResourceWarning: unclosed transport),如果警告可用的话。 为了避免这种情况，在关闭事件循环前加入一小段延迟让底层连接得到关闭的缓冲时间。 对于非SSL的ClientSession, 使用0即可(await asyncio.sleep(0)):\n"},{"id":66,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/10-%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/","title":"10-责任链模式","section":"11-Python设计模式","content":"责任链模式 #  当在开发中无法预知使用哪种方法处理某个特定的请求时，使用责任链模式来不停的进行吹，直到有合适的处理方法为止\n原则：\n 存在一个对象链 我们一开始将请求发送给链中的第一个对象 对象决定是否要处理该请求 将请求传递给下一个对象 重复该过程，一直到链尾  code https://github.com/lanms/Python_design_pattern/blob/master/10_chain_pattern.py\n"},{"id":67,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/11-%E5%85%83%E7%B1%BB/","title":"11-元类","section":"01-python基础","content":"元类介绍 #  type可以直接生成类（class），但也可以先生成元类（metaclass），再使用元类批量定制类（class）\n使用 class 创建类\n class Hello():  def say(self, name=\u0026#39;world\u0026#39;):  print(\u0026#39;Hello, %s\u0026#39; % name)  h = Hello() h.say() 使用 type 直接创建\n def say(self, name=\u0026#39;world\u0026#39;):  print(\u0026#34;Hello, %s\u0026#34; % name)  Hello = type(\u0026#39;Hello\u0026#39;, (object, ), dict(say_hello=say)) h = Hello() h.say() 先生成元类 metaclass，再批量创建\n# 传入type class SayMetaClass(type):   # 传入 类名称、父类、属性  def __new__(cls, name, bases, attrs):  # 添加属性   attrs[\u0026#39;say_\u0026#39;+name] = lambda self,value,saying=name: print(saying+\u0026#39;,\u0026#39;+value+\u0026#39;!\u0026#39;)  # 传承三大：类名称、父类、属性  return type.__new__(cls, name, bases, attrs)  # 创建类 class Hello(object, metaclass=SayMetaClass):  pass  # 创建实列 hello = Hello()  # 调用实例方法 hello.say_Hello(\u0026#39;world!\u0026#39;) # Hello, world！ 类名 + 传入的参数  class NiHao(object, metaclass=SayMetacalss):  pass  n = NiHao() n.say_NiHao(\u0026#34;中国\u0026#34;) # NiHao, 中国！ 元类的应用 #  参考文章 快速掌握元类\nORM 对象关系映射 #     class Field(object):   def __init__(self, name, column_type):  self.name = name  self.column_type = column_type   def __str__(self):  return \u0026#39;\u0026lt;%s: %s\u0026gt;\u0026#39; % (self.__class__.__name__, self.name)   class StringField(Field):   def __init__(self, name):  super().__init__(name, \u0026#39;varchar(100)\u0026#39;)   class IntegerField(Field):   def __init__(self, name):  super().__init__(name, \u0026#39;bigint\u0026#39;)   class ModelMetaClass(type):  \u0026#34;\u0026#34;\u0026#34;元类\u0026#34;\u0026#34;\u0026#34;  \u0026#34;\u0026#34;\u0026#34; 创建一个新的字典mapping 将每一个类的属性，通过.items()遍历其键值对。 如果值是Field类，则打印键值，并将这一对键值绑定到mapping字典上。 将刚刚传入值为Field类的属性删除。 创建一个专门的__mappings__属性，保存字典mapping。 创建一个专门的__table__属性，保存传入的类的名称。 \u0026#34;\u0026#34;\u0026#34;  def __new__(cls, name, bases, attrs):  if name == \u0026#39;Model\u0026#39;:  return type.__new__(cls, name, bases, attrs)  print(\u0026#39;Found model: %s\u0026#39; % name)  mappings = dict()  for k, v in attrs.items():  if isinstance(v, Field):  print(\u0026#39;Found mapping: %s==\u0026gt; %s\u0026#39; % (k, v))  mappings[k] = v  for k in mappings.keys():  attrs.pop(k)  attrs[\u0026#34;__mappings__\u0026#34;] = mappings  attrs[\u0026#34;__table__\u0026#34;] = name  return type.__new__(cls, name, bases, attrs)   class Model(dict, metaclass=ModelMetaClass):  \u0026#34;\u0026#34;\u0026#34;创建 Modle 来自于元类\u0026#34;\u0026#34;\u0026#34;   def __init__(self, **kwargs):  super().__init__(**kwargs)   def __getattr__(self, key):  try:  return self[key]  except KeyError:  raise AttributeError(\u0026#34;\u0026#39;Model\u0026#39; object has no attribute \u0026#39;%s\u0026#39;\u0026#34; % key)   def __setattr__(self, key, value):  self[key] = value   def save(self):  \u0026#34;\u0026#34;\u0026#34;模拟 sql 语句\u0026#34;\u0026#34;\u0026#34;  fields = []  args = []  for k, v in self.__mappings__.items():  fields.append(v.name)  args.append(getattr(self, k, None))  sql = \u0026#39;insert into %s(%s) values (%s)\u0026#39; % (self.__table__, \u0026#39;,\u0026#39;.join(fields), \u0026#39;,\u0026#39;.join(str(i) for i in args))  print(\u0026#34;SQL: %s\u0026#34; % sql)  print(\u0026#34;Args: %s\u0026#34; % str(args))   class User(Model):  \u0026#34;\u0026#34;\u0026#34;创建子类\u0026#34;\u0026#34;\u0026#34;  \u0026#34;\u0026#34;\u0026#34; id= IntegerField(‘id’)就会自动解析为： Model.__setattr__(self, ‘id’, IntegerField(‘id’)) 因为IntergerField(‘id’)是Field的子类的实例，自动触发元类的__new__， 所以将IntergerField(‘id’)存入__mappings__并删除这个键值对 \u0026#34;\u0026#34;\u0026#34;  id = IntegerField(\u0026#39;id\u0026#39;)  name = StringField(\u0026#39;username\u0026#39;)  email = StringField(\u0026#39;email\u0026#39;)  password = StringField(\u0026#39;password\u0026#39;)  \u0026#34;\u0026#34;\u0026#34; 实例化过程中 先调用Model.__setattr__，将键值载入私有对象 然后调用元类的“天赋”，ModelMetaclass._new_，将Model中的私有对象，只要是Field的实例，都自动存入u.__mappings__ \u0026#34;\u0026#34;\u0026#34; # 实例化 User u = User(id=12345, name=\u0026#39;Batman\u0026#39;, email=\u0026#39;12343@qq.com\u0026#39;, password=\u0026#39;qwerqwer\u0026#39;) u.save() "},{"id":68,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/11-%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/","title":"11-命令模式","section":"11-Python设计模式","content":"命令模式 #   只需要执行一个命令，就可以实现对应的功能 调用命令的对象知道如何执行命令的对象解耦，调用者无需知道命令的任何实现细节 如果有意义，可以把多个命令组织起来，这样调用者能够按照顺序执行它们  code https://github.com/lanms/Python_design_pattern/blob/master/11_command_pattern.py\n"},{"id":69,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/12-anaconda%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/","title":"12-Anaconda创建虚拟环境","section":"01-python基础","content":"下载安装 #  https://www.jianshu.com/p/920a6e18cfd6 (参考文档)\n下载地址： https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/ 下载最新的windows版本\n安装过程如果没有选择添加环境变量，那么需要手动添加一下环境变量\n常用命令 #  conda -V (大写) 查看版本\nconda list 查看安装了哪些包\nconda env list 或 conda info -e 查看当前存在哪些虚拟环境\nconda update conda 检查更新当前的conda\n创建Python虚拟环境 #  conda create -n your_env_name python=X.X(版本) 创建指定Python版本的虚拟环境\n激活 activate your_env_name\n对指定虚拟环境安装扩展包 #  conda install -n your_env_name [package_name]\n卸载指定的安装包 #  conda remove -n your_env_name \u0026ndash;all 全部卸载\nconda remove \u0026ndash;name your_env_name [package_name] 卸载某个包\n"},{"id":70,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/12-%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"12-解释器模式","section":"11-Python设计模式","content":"解释器模式 #  客户分类：\n 基本用户 高级用户  解释器模式主要是引起应用的高级用户的兴趣\ncode https://github.com/lanms/Python_design_pattern/blob/master/12_interpreter_pattern.py\n"},{"id":71,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/13-py2%E5%92%8Cpy3%E7%9A%84%E5%8C%BA%E5%88%AB/","title":"13-py2和py3的区别","section":"01-python基础","content":"python3和python2的区别 #  注：没有特别说明的都是 python3 的特性\n性能 #  2的性能比3的性能高越 15%-30%\n编码 #  3使用的是 utf-8\n语法 #  去除了\u0026lt;\u0026gt; 全部使用 ！=\n全部改用 repr() 去除 ``\n加入关键子 as和with, 还有True,False None\n整型相除得到的是浮点数， // 得到的是整型\n加入 nolocal\n将print关键子去除，添加 print() 方法\n print \u0026ldquo;This is\u0026rdquo;, 2*2 print \u0026raquo; sys.stderr. \u0026lsquo;fatal error\u0026rsquo; 3.X print(\u0026ldquo;fatal error\u0026rdquo;, file=sys.stderr)  x \u0026lt; y 当 x 和 y 的类型不匹配抛出 Typeerror 而不是随机的 bool 值\n输入函数改变\n 2 ： raw_input(\u0026ldquo;请输入：\u0026rdquo;) 3 ： input(\u0026ldquo;请输入：\u0026rdquo;)  不能定义函数如下\n def(a, (b, c)): pass  增加了二进制字面量和bin() 函数\na, b, *rest = seq 是合法的\n在定义类的 init 时，新的super 可以不再给super()传参数\n新的 metaclass 语法\n支持 class decorater 即，类装饰器\n3中的默认字符串类型是 2 中的unicode类型\n3去除了long类型，只有一种类型 int\n新增 bytes 类型，对应 2 中的八位串\nstr 和 bytes 类型可以相互转换 encode 和 decode\ndict的 .keys()、.items 和 .values() 方法返回迭代器，而之前的 iterkeys()、dict.has_key() 都被废弃\n面型对象， 引入抽象基类\n所有的异常都从 BaseException 继承，去除了 error.message的方法\n用 raise Exception(args) 代替 raise Exception,args语法\n"},{"id":72,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/13-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/","title":"13-观察者模式","section":"11-Python设计模式","content":"观察者模式 #  在一个对象的状态改变时可以改变另外一组对象\n观察者模式描述单个对象与一个或多个对象之间的发布订阅关系。在MVC的例子中，发布者是模型，订阅者是视图。\n观察者模式希望一个对象的状态变化时，能够通知/提醒多有相关者，则可以使用观察者模式，观察者模式的一个重要特性为，在运行时，订阅者/观察者的数量以及观察者时谁都会发生变化。\ncode https://github.com/lanms/Python_design_pattern/blob/master/13_observer_pattern.py\n"},{"id":73,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/14-%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95%E6%B1%87%E6%80%BB/","title":"14-函数的用法汇总","section":"01-python基础","content":"or\n取第一个不为空值的变量\na = b or c or d or e callable\n验证函数是否是可被调用的方法\n\u0026gt;\u0026gt;\u0026gt; callable(max) True \u0026gt;\u0026gt;\u0026gt; callable(9) False "},{"id":74,"href":"/docs/11-python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/14-%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/","title":"14-状态模式","section":"11-Python设计模式","content":"状态模式 #  "},{"id":75,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/15-python%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%E5%BA%93/","title":"15-python内置函数库","section":"01-python基础","content":"1. functool #  1.1 lru_cache #   当api传入相同参数时，快速返回缓存的值   from urllib import request, error  from functools import lru_cache   @lru_cache(maxsize=32) def get_pep(num):  resource = \u0026#39;http://www.python.org/dev/peps/pep-%04d/\u0026#39; % num  try:  with request.urlopen(resource) as s:  return s.read()  except error.HTTPError:  return \u0026#34;NOT found {}\u0026#34;.format(num)   for n in 8, 290, 308, 320, 8, 218, 320, 279, 289, 320, 9991:  pep = get_pep(n)  print(f\u0026#34;{n}{len(pep)}{pep}\u0026#34;) 1.2 reduce #   累加  reduce(lambda x, y: x + y, [1, 2, 3]) 6 2. itertools #  from itertools import count, cycle, repeat  c = count(10) [next(c) for _ in range(3)] [10, 11, 12]  cy = cycle(\u0026#34;abc\u0026#34;) [next(cy) for _ in range(10)] [\u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]  c = repeat(\u0026#34;abc\u0026#34;, 3) [next(c) for _ in range(1)] [\u0026#39;abc\u0026#39;] [next(c) for _ in range(2)] [\u0026#39;abc\u0026#39;, \u0026#39;abc\u0026#39;]c = repeat(\u0026#34;abc\u0026#34;, 3) [next(c) for _ in range(1)] [\u0026#39;abc\u0026#39;] [next(c) for _ in range(2)] [\u0026#39;abc\u0026#39;, \u0026#39;abc\u0026#39;] 2.1 chain #   链接iter  list(chain(\u0026#34;ABC\u0026#34;, \u0026#39;123\u0026#39;)) [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;] groupby() #   注意 * 使用前需要先将值按照顺序进行排序  {os: [item.version for item in items] for os, items in  groupby(os_version_list, key=lambda x: x.os)} filter #  过滤，满足条件的返回True此时改值会被返回出来，不满足条件的值被忽略\n"},{"id":76,"href":"/docs/10-%E4%BC%98%E5%8C%96/celery%E5%92%8Crabbitmq/","title":"Celery和RabbitMQ","section":"10-优化","content":"Celery和RabbitMQ\nCelery是Distributed Task Queue，分布式任务队列，分布式决定了可以有多个 worker 的存在，队列表示其是异步操作，即存在一个产生任务提出需求的 master，和很多的等待分配的 工人\n在 Python 中定义Celery，引入了 Broker 中间件，当 worker 处理完之后还会有一个 backend\n任务模块 Task\n包含异步任务和定时任务，其中，异步任务通常在业务逻辑中被触发并投放在任务队列中，而定时任务也会有 Celery Beat 进程周期性地将任务发往任务队列\n消息中间件 Broker\n任务调度队列，官方推荐使用 RabbitMQ和Redis等\n任务执行单元 Worker\n监控消息队列，获取队列中调度的任务，并执行它\n任务结果 Backend\n存储任务处理的结果，存储也可以使用RabbitMQ，Redis, MongoDB\n # 安装 RabbitMQ sudo apt-get install rabbitmq-server  # 启动 sudo rabbitmq-server -detached # 停止 sudo ranbbitmqctl stop # 设置 RabbitMQ sudo rabbitmqctl add_user USER_NAME PASSWORD #创建用户 sudo rabbitmqctl add_vhost VHOST_NAME # 添加 vhost 的名称 sudo rabbitmqctl set_user_tags USER_NAME USER_TAGS_NAME # 添加tags sudo rabbitmqctl set_permissions VHOST_NAME USER_NAME \u0026#39;.*\u0026#39; \u0026#39;.*\u0026#39; \u0026#39;.*\u0026#39; rabbitmqctl list_queues -p VHOST_NAME  # 安装 celery pip3 install celery  # 返回的 broker_url broker_url = \u0026#39;amqp://USER_NAME:PASSWORD@localhost:5672/VHOST_NAME\u0026#39;  # 编辑 task.py 任务文件 import time from celery import Celery  app = Celery(\u0026#34;task\u0026#34;, backend=\u0026#39;amqp://USER_NAME:PASSWORD@localhost:5672/VHOST_NAME\u0026#39;,  broker=\u0026#39;amqp://USER_NAME:PASSWORD@localhost:5672/VHOST_NAME\u0026#39;)  @app.task def add(x, y):  time.sleep(3)  return x + y  # 运行 celery worker nohup celery -A task worker --loglevel=info \u0026amp;  # 查看执行，进入 python3 交互环境 from task import add result = add.delay(4,4) result.ready() result.get(timeout=1) result.status result.id "},{"id":77,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/celery%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"celery的使用","section":"15-集成开发","content":"celery的使用\nhttps://blog.csdn.net/Shyllin/article/details/80940643\nhttps://www.cnblogs.com/forward-wang/p/5970806.html\n启动命令\ncelery -A task_dir_name beat\nhttp://127.0.0.1:5555/user/celery/?v1=aaaa\u0026amp;v2=bbb 可使用 AWS 的 SQS 和 DynmoDB\nwindows\n pip install eventlet celery -A \u0026lt;mymodule\u0026gt; worker -l info -P eventlet http://www.cnblogs.com/cwp-bg/p/8759638.html\ncelery_aaa\ncelery -A celery_aaa worker --loglevel=info  python3 -m celery_aaa.run_tasks 可视化 celery 和 rabbitmq\npip install flower 所有的任务会存在本地的 schedule文件中\n当没有发布任务时 worker 会等待，直到有任务发布\n当没有worker存在时，会一直发布任务，直到worker出现\n启动任务发布时会返回它的pid，可以通过kill pid 来停止\ncelery_aaa\n# 运行worker celery -A celery_aaa worker --loglevel=info  # 导入任务 from celery_util.celery_aaa.tasks import longtime_add  longtime_add.delay(1, 2) "},{"id":78,"href":"/docs/20-airflow%E5%AE%9E%E6%88%98/create-db/","title":"create db","section":"20-airflow实战","content":"create database aiflow CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; "},{"id":79,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/docker%E4%BD%BF%E7%94%A8/","title":"Docker使用","section":"15-集成开发","content":"Docker使用\n安装\nhttps://docs.docker.com/install/linux/docker-ce/ubuntu/#install-docker-ce-1\n命令\nhttps://www.jianshu.com/p/ef8f17442d8f\n"},{"id":80,"href":"/docs/17-emacs/emacs%E9%85%8D%E7%BD%AE/","title":"emacs配置","section":"17-emacs","content":"evil 为emacs绑定vim键\ngit clone https://github.com/emacs-evil/evil ~/.emacs.d/evil 编辑~/.emacs\n(add-to-list \u0026#39;load-path \u0026#34;~/.emacs.d/evil\u0026#34;) (require \u0026#39;evil) (evil-mode 1) siderbar\n"},{"id":81,"href":"/docs/02-%E5%89%8D%E7%AB%AFhtml-js-css/js%E4%B8%ADcookie%E5%80%BC%E7%9A%84%E8%AE%BE%E7%BD%AE%E5%92%8C%E8%8E%B7%E5%8F%96/","title":"js中cookie值的设置和获取","section":"02-前端HTML-js-css","content":"JS cookie的取值和设置值 #  第一步：引入js\n\u0026lt;script src=\u0026quot;/XX/js/login/jquery-1.5.1.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;/XX/js/login/jquery.cookie.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  第二步：存放值\n$.cookie('the_cookie', 'the_value', { expires: 7, path: '/' }); 一步写到位，不要轻易把path去掉。不然只能在当前js使用，我吃过亏的\n举个实例吧： 需求：城市定位，需要下次进入页面时记住上次自动定位的城市名字或者手动选择的城市名字\n百度地图API功能\n var geolocation = new BMap.Geolocation(); geolocation.getCurrentPosition(function(r){  if(this.getStatus() == BMAP_STATUS_SUCCESS){  var 城市名= r.address.city；（拿到的城市名字）  //往cookie里面放城市名称  $.cookie(\u0026#39;locateCity\u0026#39;, 城市名, { expires: 7 ,path:\u0026#39;/\u0026#39;});  }  else {  //alert(\u0026#39;failed\u0026#39;+this.getStatus());  mui.alert(\u0026#34;城市定位失败\u0026#34;);  }  },{enableHighAccuracy: true}) 第三步：取值\n var locateCity = $.cookie(\u0026#39;locateCity\u0026#39;); "},{"id":82,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/memcached%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E5%90%AF%E5%8A%A8/","title":"memcached的安装和启动","section":"15-集成开发","content":"README\nwindows创建服务 #  schtasks /create /sc onstart /tn memcached /tr \u0026#34;\u0026#39;D:\\softWare\\memcached-amd64\\memcached.exe\u0026#39; -m 512 -p 10000 \u0026#34; 删除服务\nschtasks /delete /tn memcached windows启动服务\nmemcached -u root -l 0.0.0.0 -p 10001 -c 1024 -P D:\\softWare\\memcached-amd64\\Pid\\memcached.pid 启动memcached #  memcached -d -m 10 -u root -l 0.0.0.0 -p 12000 -c 256 -P /tmp/memcached.pid  参数说明:  -d 是启动一个守护进程  -m 是分配给Memcache使用的内存数量，单位是MB  -u 是运行Memcache的用户  -l 是监听的服务器IP地址  -p 是设置Memcache监听的端口,最好是1024以上的端口  -c 选项是最大运行的并发连接数，默认是1024，按照你服务器的负载量来设定  -P 是设置保存Memcache的pid文件 常用命令\n存储命令: set/add/replace/append/prepend/cas 获取命令: get/gets 其他命令: delete/stats.. https://www.cnblogs.com/wang-yc/p/5693268.html\n"},{"id":83,"href":"/docs/10-%E4%BC%98%E5%8C%96/mysql%E4%B8%BB%E4%BB%8E%E5%88%86%E7%A6%BB/","title":"MySQL主从分离","section":"10-优化","content":"MySQL主从分离，读写分离\n Orical适合做集群，没有主从\n 磁盘阵列，raid\n数据库日志 #  错误日志，数据日志，慢查询日志，启动日志\n数据日志\n 全量备份：全部备份，每周 增量备份：每天，将增加的部分进行备份，日志中会记录每个对数据库的操作记录， 冷备份：关掉数据库备份 热备份：不关数据库备份  主从分离配置 #  # master配置 server-id=200 # 一般取IP的最后一组数字 innodb_flush_log_at_trx_commit=2 sync_binlog=1 log-bin=mysql-bin-200 binlog-do-db= # 同步的数据库的名称,全部可以使用 * 重启MySQL # 客户端执行命令,授权给 slave grant replication slave on *.* to \u0026#39;zhang\u0026#39;@\u0026#34;IP\u0026#34; identified by \u0026#39;123456\u0026#39;; show master status;  # slave 更改配置 server-id=201 innodb_flush_log_at_trx_commit=2 sync_binlog=1 log-bin=mysql-bin-201  # slave mysql客户端执行命令 change master to master_host=\u0026#39;10.7.152.77\u0026#39;, # 连接 master的 IP master_user=\u0026#39;zhang\u0026#39;, # master授权的用户 master_password=\u0026#39;123456\u0026#39;, # 密码 master_log_file=\u0026#39;mysql-bin-200.000002\u0026#39;, # master 的日志位置 master_log_pos=448; # master 的 Position  start salve; show slave status\\G; # 查看状态 Nginx\n单点故障：\nwebServer的优势\nAppServer：\n uwsgi：网关接口，WSGI 网管协议，uwsgi时WSGI的一种实现方式，时沟通Nginx和django的桥梁  "},{"id":84,"href":"/docs/10-%E4%BC%98%E5%8C%96/mysql%E4%BC%98%E5%8C%96/","title":"MySQL优化","section":"10-优化","content":"MySQL优化 #   SQL优化 参数配置优化  对sql语句进行优化 #  缓存查询语句：\n 不开启缓存的情况：cursor.execute(\u0026quot;select username from user where singup_data\u0026gt;=curdate()\u0026quot;); 开启缓存进行查询：cursor.execute(\u0026quot;select * from user where signup_data\u0026gt;=%s\u0026quot;, (datetime.now()))但是有时会有 sql 注入攻击的风险  EXPLAIN：对要执行的 sql 语句的运行过程进行查看\n只需要一条数据时使用 LIMIT 1\n cursor.execute(\u0026quot;select 1 from user where country='china' limit 1\u0026quot;);  使用索引：\n create index ix_tablename_colname on table(col1, col2);  在Join 表时使用相同的类型的字段，并将其索引\n 如下语句中，两个 state 中应该是创建过索引的，而且是相同的类型，相同的字符集  cursor.execute(\u0026#34;select company_name from users left join conpanies on (users.state=companies.state) where users.id=%s\u0026#34;, (user_id)) 避免使用 select * ， 使用具体的属性进行查询，避免 select * 的二次查询\n每张表都应该创建一个 主键 id\n尽可能使用 NOT NULL 避免空值\n固定长度的表会让查询的速度更快\n垂直分割：将数据库中的一张表分为几张表，降低查询时得到的不是必须的字段，降低表的复杂度和字段的数目\n 另外：被分出去的字段形成的表，一般不会经常性的 Join 它们，不然会让性能比分割前还差  拆分大的 DELETE 或 INSERT 语句\n 使用 limit 限制每次操作的数据的条数，避免锁表  选择正确的存储引擎\n InnoDB：支持 \u0026ldquo;行锁\u0026rdquo;，在写入操作时性能更好，对事物比较支持 MysSAM：适合大量查询时使用，但是对大量的写入操作不是很好  查看存储引擎\n show create table lesson;  优化参数配置 #  back_log=500\n 默认时50，back_log指在 MySQL中暂时停止回答请求之前的短时间有多少个请求可以被存在栈中，也就时当连接数达到 max_connections时，新的请求会被存在 栈 中等待响应，即 back_log的数量，但是超过back_log的请求将会无法响应 查看当前的数量show variables like 'back_log';  wait_timeout参数，由默认的8小时，修改为30分钟\n wait_timeout=1800 show variables like 'wait_timeout'  max_connection，修改默认值，由默认的151，修改为3000\n max_connections=3000  max_user_connection,默认是 0 ， 修改为 800\n max_user_connections=800 针对某一账号的所有客户端并行连接在 mysql 服务的最大并行连接数，简单说是指同一个账号能够同时连接到 mysql服务的最大连接数，设置为 0表示不限制 show variables like 'max_user_connections'  修改 thread_concurrency，默认是8，修改为64\n thread_concurrency=64 这个应该设置为CPU核数的两倍， show variables like 'thread_concurrency'  default-storage-engine=InnoDB，存储引擎设置\n create table mytable (id int, title char(20)) ENGINE=INNODB; show variables like '%max_connections%'  创建索引：\nix\nux\n cerate index ix_tablename_column on  # 查询语句 explain + sql 查看查询的详细信息, 性能分析 0\n"},{"id":85,"href":"/docs/18-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/nginx_uwsgi/","title":"Nginx_uwsgi","section":"18-安装脚本","content":"Nginx+uwsgi安装配置 #  yum install epel-release \u0026amp;\u0026amp; yum install nginx \u0026amp;\u0026amp; systemctl start nginx \u0026amp;\u0026amp; firewall-cmd --permanent --zone=public --add-service=http \u0026amp;\u0026amp; firewall-cmd --permanent --zone=public --add-service=https \u0026amp;\u0026amp; firewall-cmd --reload \u0026amp;\u0026amp;systemctl enable nginx \u0026amp;\u0026amp; pip3 install uwsgi \u0026amp;\u0026amp; ln -s /usr/local/python3/bin/uwsgi /usr/bin/uwsgi 4.1 配置nginx.conf文件 #  首先：编写自己项目的nginx.conf文件如下：\n每一个项目对应有一个自己定义的nginx的配置文件，比如爱鲜蜂项目，我定义为axfnginx.conf文件\nserver { listen 80; server_name 39.104.176.9 localhost; access_log /home/logs/access.log; error_log /home/logs/error.log; location / { include uwsgi_params; uwsgi_pass 127.0.0.1:8890; } location /static/ { alias /home/src/axf/static/; expires 30d; } } 其次：修改总的nginx的配置文件，让总的nginx文件包含我们自定义的项目的axfnginx.conf文件\n总的nginx配置文件在：/etc/nginx/nginx.conf中\n以上步骤操作完成以后，需要重启nginx：\nsystemctl restart nginx 如果自定义的axfnginx.conf文件没有错误的话，查看nginx的运行状态会有如下的结果：\n4.2 配置uwsgi文件 #  在conf文件夹下除了包含自定义的axfnginx.conf文件，还有我们定义的uwsgi.ini文件\n[uwsgi] projectname = axf base = /home/src  # 守护进程 master = true  # 进程个数 processes = 4  # 虚拟环境 pythonhome = /home/env/axfenv  # 项目地址 chdir = %(base)/%(projectname)  # 指定python版本 pythonpath = /usr/local/python3/bin/python3  # 指定项目的wsgi文件 module = %(projectname).wsgi  # 和nginx通信地址:端口 socket = 127.0.0.1:8890  # 日志文件地址 logto = /home/logs/uwsgi.log 运行项目:\nuwsgi --ini uwsgi.ini "},{"id":86,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/rabbitmq%E4%BD%BF%E7%94%A8/","title":"rabbitmq使用","section":"15-集成开发","content":"参考链接\nhttps://tests4geeks.com/python-celery-rabbitmq-tutorial/\n # 安装 sudo apt-get install rabbitmq-server  # 设置用户和权限  # add user \u0026#39;jimmy\u0026#39; with password \u0026#39;jimmy123\u0026#39; $ rabbitmqctl add_user jimmy jimmy123 # add virtual host \u0026#39;jimmy_vhost\u0026#39; $ rabbitmqctl add_vhost jimmy_vhost # add user tag \u0026#39;jimmy_tag\u0026#39; for user \u0026#39;jimmy\u0026#39; $ rabbitmqctl set_user_tags jimmy jimmy_tag # set permission for user \u0026#39;jimmy\u0026#39; on virtual host \u0026#39;jimmy_vhost\u0026#39; $ rabbitmqctl set_permissions -p jimmy_vhost jimmy \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; "},{"id":87,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/scrapyd%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","title":"scrapyd使用方法","section":"15-集成开发","content":"scrapyd使用方法\n发布爬虫任务\nscrapyd-deploy 001 -p lianjiaSpider\n打包egg文件\nscrapyd-deploy --build-egg lianjia.egg\n1 启动\nscrapyd\n2 发布工程到scrapyd\nscrapyd-deploy \u0026lt;target\u0026gt; -p \u0026lt;project\u0026gt;\n scrapyd-deploy scrapyd1 -p Crawler  3 验证是否发布成功\nscrapyd-deploy -L \u0026lt;target\u0026gt;\nscrapyd-deploy -L scrapyd1\n也可以 scrapyd-deploy -l\n4 启动爬虫\ncurl http://192.168.2.333:6800/schedule.json -d project=Crawler -d spider=CommonSpider 5 终止爬虫\ncurl http://192.168.2.333:6800/cancel.json -d project=Crawler -d job8270364f9d9811e5adbf000c29a5d5be 参考链接 使用scrapyd\nhttps://www.jianshu.com/p/f0077adb74bb\n"},{"id":88,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/shell%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/","title":"shell脚本语言","section":"01-python基础","content":"shell脚本编辑\n 变量定义  数字字母下划线, 不能数字开头,不能使用关键字 使用定义过的变量只要在变量名前加 $ 即可 $(ls ) 将当前目录下的文件遍历出来   去变量值 $ 变量边界 ${} 子符长度${#} 去元素 ${数组名[下标]}  $ 的使用\n $#传递到脚本的参数 $*以一个单字符串显示向脚本传递的参数, 即 传递给脚本的参数组装 $$脚本运行的进程号 $!后台运行的最后一个进程号  **test命令 ** 可参考菜鸟教程shell test 命令\n数值测试\n -eq  等于则为 true  equal -ne 不等于 true not equal -gt 大于为true great -ge 大于等于 true  great equal -lt 小于 true little -le小于等于 true little equal  字符串测试\n= != -z 字符串长度为0 -n 字符串长度不为0\n文件测试\n -e 文件存在 true -r 可读文件 -w 可写文件 -x 可执行 -s 文件至少有一个字符 -d 文件存在且为目录 -f 文件为普通文件 -c 文件为特殊文件 -b 文件为块特殊文件  代码示例\n#!/bin/bash  func(){  result=1  n=1  while test $n -le $2  do  result=$(($result*$1))  n=$(($n+1))  done  return $result }  func 5 3 echo $? #!/bin/bash  if test -e ~/abc then  rm -rf ~/abc fi  mkdir ~/test/abc num=1 while test $num -le 100 do  touch \u0026#34;user${num}.text mv \u0026#34;user${num}.txt ~/test/abc/  num=$(($num+1)) done "},{"id":89,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/spiderkeeper%E6%8E%A5%E5%8F%A3/","title":"spiderKeeper接口","section":"15-集成开发","content":"创建项目\n create project url: /project/create method: post  form 上传egg文件\ndeploy submit upload egg url: /project/1/spider/upload method: post  form 删除项目\nmanage delete project url: /project/1/delete method: get  创建定时任务\n Periodic Jobs add job 创建定时任务 url: /project/1/job/add/ method: post \tform 运行一次\nrun once create url : /project/1/job/add method: post \tform 停止任务\n/project/1/jobexecs/3/stop 查看日志\n log url: /project/1/jobexecs/1/log method: get 和scrapyd通讯文件\napp =\u0026gt; proxy =\u0026gt; contrib =\u0026gt; scrapy.py ScrapydProxy "},{"id":90,"href":"/docs/01-python%E5%9F%BA%E7%A1%80/%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95/","title":"一些函数的用法","section":"01-python基础","content":"一些函数的用法\n  hasattr(s, name) # 判断有没有 属性或方法  getattr(s, name) # 获取 setattr(s, name) # 设置 "},{"id":91,"href":"/docs/10-%E4%BC%98%E5%8C%96/%E4%B8%B4%E6%97%B6%E7%AC%94%E8%AE%B0/","title":"临时笔记","section":"10-优化","content":"Linux 操作系统 #  基本知识\n $ 普通用户  超级用户 #    shell 脚本起始都是 #! /bin/bash\nshell 脚本执行 #   bash myScript.sh chmod 755 myScript.sh ./myScript.sh 先授予执行权限，再执行脚本 chmod a+x sample.sh ./sample.sh 也可以使用脚本的完整路径进行执行脚本，如：/home/path/script.sh  echo #   用于终端打印的基本命令，默认情况下 echo 会在每次调用后添加一个换行符 echo \u0026lsquo;hello\u0026rsquo; echo -n 禁止添加换行符 echo -e 使用转义序列,转义序列可生效 echo -e \u0026ldquo;1\\t2\\t3\u0026rdquo; 打印彩色输出  echo -e \u0026ldquo;\\e[1;31m This is red text \\e[0m\u0026rdquo; \\e[1;31m 是一个转义字符，可以将颜色设置为红色，\\e[0m 是将颜色重置 重置 0 ，黑色 40，红色 41，绿色 42，黄色 43，蓝色 44，洋红 45， 青色 46，白色47    printf #   用于接受引用文本或由空格分隔的参数，可以使用格式化字符串的方法来输出个格式化字符，它不会添加换行符，必须手动指定  格式化输出 printf %-5s 输出占5个字符的长度\n printf \u0026ldquo;%-5s %-10s %-4s\\n\u0026rdquo; no name mark 格式化替换符 %s %c %d %f  "},{"id":92,"href":"/docs/20-airflow%E5%AE%9E%E6%88%98/%E4%BD%BF%E7%94%A8celerykubernetesexecutor/","title":"使用celerykubernetesexecutor","section":"20-airflow实战","content":"同一DAG使用CeleryExecutor和KubernetesExecutor #    Airflow版本：2.2.5\n  设置环境变量 AIRFLOW__CORE__EXECUTOR: \u0026ldquo;CeleryKubernetesExecutor\u0026rdquo;\n  使用 KubernetesExecutor 需要设置任务 queue=\u0026lsquo;kubernetes\u0026rsquo;\n  示例DAG\n  from airflow import DAG from airflow.decorators import task from airflow.utils.dates import days_ago from airflow.settings import AIRFLOW_HOME  import os import time  with DAG(  dag_id=\u0026#34;example_kubernetes_executor\u0026#34;,  schedule_interval=\u0026#34;33 * * * *\u0026#34;,  start_date=days_ago(2),  catchup=False,  tags=[\u0026#34;example\u0026#34;], ) as dag:  executor_config = {  \u0026#34;pod_template_file\u0026#34;: os.path.join(  AIRFLOW_HOME, \u0026#34;base.yaml\u0026#34;  ),  #\u0026#34;pod_override\u0026#34;: k8s.V1Pod(  # metadata=k8s.V1ObjectMeta(labels={\u0026#34;release\u0026#34;: \u0026#34;stable\u0026#34;})  #),  }   for i in range(2):  @task(task_id=f\u0026#39;kubernetes_task_{i}\u0026#39;, executor_config=executor_config, queue=\u0026#39;kubernetes\u0026#39;)  def test11():  print(\u0026#39;------------- start ----------------\u0026#39;)  for i in range(10):  print(f\u0026#39;{i}\u0026#39; * 10)  time.sleep(3)  print(\u0026#39;-------------- end ------------------\u0026#39;)  test_task = test11()    for i in range(2):  @task(task_id=f\u0026#39;celery_task_{i}\u0026#39;)  def test222():  print(\u0026#39;------------- start ----------------\u0026#39;)  for i in range(10):  print(f\u0026#39;{i}\u0026#39; * 10)  time.sleep(3)  print(\u0026#39;-------------- end ------------------\u0026#39;)   test_task2 = test222() Pod_template 文件示例\n base.yaml   --- apiVersion: v1 kind: Pod  metadata:  name: testname  namespace: cmbchina spec:  containers:  - name: base  image: \u0026#39;aiflow:xxxxx\u0026#39;  imagePullPolicy: IfNotPresent  env:  - name: test111  value: ttttttt  envFrom:  - configMapRef:  name: airflow-conf  volumeMounts:  - name: airflow-home  mountPath: /root/airflow  restartPolicy: Never  volumes:  - name: airflow-home  hostPath:  path: /xxxxx/airflow  type: DirectoryOrCreate "},{"id":93,"href":"/docs/10-%E4%BC%98%E5%8C%96/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","title":"单元测试","section":"10-优化","content":"单元测试\n白盒测试和黑盒测试\n 白盒测试：是通过程序的源代码进行测试而不使用用户界面。这种类型的测试需要从代码句法发现内部代码在算法，溢出，路径，条件等等中的缺点或者错误，进而加以修正。黑盒测试：又被称为功能测试、数据驱动测试或基于规格说明的测试，是通过使用整个软件或某种软件功能来严格地测试, 而并没有通过检查程序的源代码或者很清楚地了解该软件的源代码程序具体是怎样设计的。测试人员通过输入他们的数据然后看输出的结果从而了解软件怎样工作  Python的单元测试模块 UnitTest #   test case , test suit, test runner, test fixture  测试用例：\n 继承 unittest.TestCase 内部定义以test_开头的方法，每个test case 都是单独运行，如果一个class中有多个 test_XXX 那么最后在load到suit时也会有多个测试 覆盖度越高越准确  测试运行后的输出：\n 第一行给出每个用力执行后的标识，成功时 . ，出错时 E，失败时 F, 跳过时 S 在unittest.main() 中可以添加 verbosity 参数，控制最后报告的详细程度，默认时1，0表示不输出每一个用例的执行结果，2 输出详细的执行结果  使用test suite\n if __name__ == \u0026#39;__main__\u0026#39;:  suite = unittest.TestSuite() \t# 定义测试的内容列表  tests = [TestMathFunc(\u0026#39;test_add\u0026#39;), TestMathFunc(\u0026#39;test_minus\u0026#39;)]  # 添加到测试中，addTest 可以添加单个  suite.addTests(tests) \t# 定义 runner 执行测试  runner = unittest.TextTestRunner(verbosity=2)  runner.run(suite) 测试环境准备 #  setUp和tearDown\n 在每个测试用例开始和结束时执行的方法，用于测试环境的准备，清理环境  setUpClass和tearDownClass\n 在所有的 case 开始之前准备一次环境，所有的 case 结束之后再清理环境   class TestModel(unittest.TestCase):   @classmethod  def setUpClass(cls):  print(\u0026#39;准备环境\u0026#39;)  \t@classmethod  def tearDownClass(cls):  print(\u0026#34;清理环境\u0026#34;) 跳过某个case\n 使用 装饰器装饰方法， @unittest.skip(\u0026quot;跳过此方法\u0026quot;) skip装饰器一共有三个 unittest.skip(reason)、unittest.skipIf(condition, reason)、unittest.skipUnless(condition, reason)，skip无条件跳过，skipIf当condition为True时跳过，skipUnless当condition为False时跳过。  输出 HTML 报告\n首先下载官方的HTMLTestRunnerhttp://tungwaiyip.info/software/HTMLTestRunner.html\n import unittest from test_model import TestModel from HTMLTestRunner import HTMLTestRunner   if __name__ == \u0026#39;__main__\u0026#39;:  suite = unittest.TestSuite()  suite.addtests(unittest.TestLoader().loadTestsFromTestCase(TestModel))   with open(\u0026#34;test.html\u0026#34;, \u0026#39;w\u0026#39;) as f:  runner = HTMLTestRunner(stream=f, title=\u0026#39;Hell test\u0026#39;, description=\u0026#34;discription\u0026#34;, verbosity=2)  runner.run(suite) "},{"id":94,"href":"/docs/04-%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%B0%8F%E7%BB%93/","title":"各种数据库读写分离小结","section":"04-数据库","content":"数据库读写分离设置 #  MySQL #  # master配置 server-id=200 # 一般取IP的最后一组数字 innodb_flush_log_at_trx_commit=2 sync_binlog=1 log-bin=mysql-bin-200 binlog-do-db= # 同步的数据库的名称,全部可以使用 * 重启MySQL # 客户端执行命令,授权给 slave grant replication slave on *.* to \u0026#39;zhang\u0026#39;@\u0026#34;IP\u0026#34; identified by \u0026#39;123456\u0026#39;; show master status;  # slave 更改配置 server-id=201 innodb_flush_log_at_trx_commit=2 sync_binlog=1 log-bin=mysql-bin-201  # slave mysql客户端执行命令 change master to master_host=\u0026#39;10.7.152.77\u0026#39;, # 连接 master的 IP master_user=\u0026#39;zhang\u0026#39;, # master授权的用户 master_password=\u0026#39;123456\u0026#39;, # 密码 master_log_file=\u0026#39;mysql-bin-200.000002\u0026#39;, # master 的日志位置 master_log_pos=448; # master 的 Position  start salve; show slave status\\G; # 查看状态 Redis #   通过修改conf文件来配置主从, 一般都是在一台服务器上面作为专门的 redis 服务器 启动 redis-server redis.conf    # master master.conf  port 6000 requirepass 123456 # 480行 # redis-server master.conf # 测试 redis-benchmark -h IP -p Port -a password # 查看连接  # slave slave.conf 应该配置多个 slave 对master进行读取  port 6001 slaveof 127.0.0.1 6000 masterauth 123456 # 对主机的验证，也是master的密码 requirepass 123456 # master设置的密码  # redis-server slave.conf  # 配置 sentinel(哨兵,守护进程)，当master宕机时，选取 slave 作为master # 更该 sentinel.conf文件（最好将原文件复制一份进行更改）  bind IP # master-IP 即 内网 IP port 端口 sentinel monitor mymaster IP port num # master的公网IP,port,哨兵数,指当有num个哨兵同时监测到master宕机时，开始选举新的master sentinel anth-pass mymaster \u0026lt;password\u0026gt; # master的 密码 sentinel down-after-millisenconds mymaster 3000 # 开始投票的反应时间 sentinel failover-timeout mymaster 180000 # 设置返回的时间，在规定时间返回可以继续作为master  # 启动哨兵，哨兵也会宕机，应该多启动几个进行守护 redis-server sentinel.conf --sentinel MongoBD #   可以在 slave 上启动多个 salve 创建不同的目录进行保存数据，实现master执行20%的写和salve实现80%的查询操作  # master 启动 mongod --bind_ip_all --dbpath /data/master -master  # slave 启动 mongod --dbpath /data/slave -slave -source masterIP:port # master的IP和端口 PostgreSQL #  这个很多，推荐参考这篇文章 https://yq.aliyun.com/articles/59344\n"},{"id":95,"href":"/docs/15-%E9%9B%86%E6%88%90%E5%BC%80%E5%8F%91/%E5%91%BD%E4%BB%A4/","title":"命令","section":"15-集成开发","content":""},{"id":96,"href":"/docs/18-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/%E5%AE%89%E8%A3%85mariadb/","title":"安装mariaDB","section":"18-安装脚本","content":"安装MariaDB #  安装命令\nyum -y install mariadb mariadb-server 安装完成MariaDB，首先启动MariaDB\nsystemctl start mariadb 设置开机启动\nsystemctl enable mariadb 设置密码 #   mysql_secure_installation Enter current password for root:\u0026lt;–初次运行直接回车 设置密码 Set root password? [Y/n] \u0026lt;– 是否设置root用户密码，输入y并回车或直接回车 New password: \u0026lt;– 设置root用户的密码 Re-enter new password: \u0026lt;– 再输入一次你设置的密码 其他配置 Remove anonymous users? [Y/n] \u0026lt;– 是否删除匿名用户，回车 Disallow root login remotely? [Y/n] \u0026lt;–是否禁止root远程登录,回车, Remove test database and access to it? [Y/n] \u0026lt;– 是否删除test数据库，回车 Reload privilege tables now? [Y/n] \u0026lt;– 是否重新加载权限表，回车 初始化MariaDB完成，接下来测试登录 mysql -u root -p password 开启远程连接 #  在mysql数据库中的user表中可以看到默认是只能本地连接的，所有可以添加一个新的用户，该用户可以远程访问\n1. 创建用户 #  # 先使用数据库 use mysql; # 针对ip create user \u0026#39;root\u0026#39;@\u0026#39;192.168.10.10\u0026#39; identified by \u0026#39;password\u0026#39;; #全部 create user \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;password\u0026#39;; 2. 授权 #  # 给用户最大权限 grant all privileges on *.* to \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;password\u0026#39;; # 给部分权限(test 数据库) grant all privileges on test.* to \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;password\u0026#39; with grant option; # 刷新权限表 `flush privileges;`  # 查看 show grants for \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39;; 接下来就可以在远程的数据库可视化工具中直接访问该服务器中的mysql了。\n# 访问数据库 mysql -u root -p #  "},{"id":97,"href":"/docs/18-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/%E5%AE%89%E8%A3%85python3.6/","title":"安装python3","section":"18-安装脚本","content":"安装python3.6 #  在centos中，系统默认只提供python2.7的版本，但是项目我们使用的python3.6的版本。所有我们自己安装python3\n# 安装python3全部命令 root权限 yum -y groupinstall \u0026#34;Development tools\u0026#34; \u0026amp;\u0026amp; yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel \u0026amp;\u0026amp; wget https://www.python.org/ftp/python/3.6.2/Python-3.6.2.tar.xz \u0026amp;\u0026amp; tar -xvJf Python-3.6.2.tar.xz \u0026amp;\u0026amp; cd Python-3.6.2 \u0026amp;\u0026amp; ./configure --prefix=/usr/local/python3 \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; ln -s /usr/local/python3/bin/python3 /usr/bin/python3 \u0026amp;\u0026amp; ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 \u0026amp;\u0026amp; yum install python-virtualenv "},{"id":98,"href":"/docs/03-git/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"常用命令","section":"03-Git","content":""},{"id":99,"href":"/docs/21-kubernetes/%E6%8E%A2%E9%92%88/","title":"探针","section":"21-kubernetes","content":"容器探针 #  探针 是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler。有三种类型的处理程序：\n ExecAction：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。 TCPSocketAction：对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的。 HTTPGetAction：对指定的端口和路径上的容器的 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于200 且小于 400，则诊断被认为是成功的。  如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活探针; kubelet 将根据 Pod 的restartPolicy 自动执行正确的操作。\n存活探针 #   如果希望容器在探测失败时被杀死并重新启动，那么请指定一个存活探针，并指定restartPolicy 为 Always 或 OnFailure。  就绪探针 #   如果要仅在探测成功时才开始向 Pod 发送流量，请指定就绪探针。在这种情况下，就绪探针可能与存活探针相同，但是 spec 中的就绪探针的存在意味着 Pod 将在没有接收到任何流量的情况下启动，并且只有在探针探测成功后才开始接收流量。  如果希望容器能够自行维护，可以指定一个就绪探针，该探针检查与存活探针不同的端点。\n请注意，如果只想在 Pod 被删除时能够排除请求，则不一定需要使用就绪探针；在删除 Pod 时，Pod 会自动将自身置于未完成状态，无论就绪探针是否存在。当等待 Pod 中的容器停止时，Pod 仍处于未完成状态。\n存活探针示例 #  apiVersion: v1 kind: Pod metadata:  labels:  test: liveness  name: liveness-http spec:  containers:  - args:  - /server  image: gcr.io/google_containers/liveness  livenessProbe:  httpGet:  # when \u0026#34;host\u0026#34; is not defined, \u0026#34;PodIP\u0026#34; will be used  # host: my-host  # when \u0026#34;scheme\u0026#34; is not defined, \u0026#34;HTTP\u0026#34; scheme will be used. Only \u0026#34;HTTP\u0026#34; and \u0026#34;HTTPS\u0026#34; are allowed  # scheme: HTTPS  path: /healthz  port: 8080  httpHeaders:  - name: X-Custom-Header  value: Awesome  initialDelaySeconds: 15  timeoutSeconds: 1  name: liveness "},{"id":100,"href":"/docs/08-tornado/%E9%83%A8%E7%BD%B2%E6%96%B9%E6%B3%95/","title":"部署方法","section":"08-Tornado","content":"Tornado部署方法 #  因为Tornado是异步的网络框架，性能够好，可以直接放在最外层，但是为了避免阻塞问题，会开多个进程，然后使用 Nginx 做反向代理实现负载均衡。具体可以看这篇文章 Introduction to Tornado 中文翻译。\n那么这里就涉及到要开多个Tornado进程的问题，使用Supervisor来做这件事是最简单的。Supervisor 的使用方法可以看这篇文章 Python 进程管理工具 Supervisor 使用教程\n另外，如果你需要部署Django或者 Flask，则推荐 Nginx+Gunicorn+Supervisor\nNginx放在最外层，然后使用Supervisor做进程管理，使用Gunicorn启动Django或者Flask，相较于uwsgi 的方法，简单很多，而且Gunicorn可以让你使用Gevent和Tornado来为你的后端实现异步访问，性能直接飙升。\n作者：淡水\n链接：https://www.zhihu.com/question/21018409/answer/164837163\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n"}]